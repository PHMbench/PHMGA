{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-header",
   "metadata": {},
   "source": [
    "# Part 1: Foundations - Code to LaTeX Agent\n",
    "\n",
    "## ğŸ¯ Research Scenario\n",
    "You're writing a research paper and need to convert your Python algorithm implementations to publication-ready LaTeX mathematical notation. Manual conversion is tedious and error-prone - let's build an intelligent agent to automate this!\n",
    "\n",
    "## ğŸ“ What You'll Learn\n",
    "\n",
    "1. **Agent Fundamentals**: Core concepts without overwhelming complexity\n",
    "2. **Multi-Provider LLM Setup**: Support for global research accessibility\n",
    "3. **Hardcoded vs Intelligent Approaches**: When to use each method\n",
    "4. **LangGraph Basics**: Workflow orchestration for research tasks\n",
    "\n",
    "## ğŸ“‹ Prerequisites Check\n",
    "Before starting, ensure you've completed `../setup_environment.ipynb` successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Environment loaded successfully!\n",
      "ğŸ“ Working directory: /home/liqi/PHMGA/tutorials_research/Part1_Foundations\n"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Add modules to path\n",
    "current_dir = Path.cwd()\n",
    "modules_dir = current_dir / \"modules\"\n",
    "sys.path.insert(0, str(modules_dir))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(current_dir.parent / \".env\")\n",
    "\n",
    "print(\"ğŸš€ Environment loaded successfully!\")\n",
    "print(f\"ğŸ“ Working directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-header",
   "metadata": {},
   "source": [
    "# Section 1: The Research Problem (30 min)\n",
    "\n",
    "## ğŸ” Problem Analysis\n",
    "\n",
    "**Scenario**: You have this Python code in your research notebook:\n",
    "\n",
    "```python\n",
    "# Euclidean distance calculation\n",
    "distance = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "# Gaussian probability density\n",
    "pdf = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "# Linear regression cost function\n",
    "cost = (1 / (2 * m)) * np.sum((hypothesis - y)**2)\n",
    "```\n",
    "\n",
    "**Challenge**: Convert this to LaTeX for your paper:\n",
    "- Manual conversion takes 1 minutes per expression\n",
    "- Easy to make notation errors\n",
    "- Inconsistent formatting across the paper\n",
    "- Need to update when code changes\n",
    "\n",
    "**Goal**: Build an intelligent agent that converts code to publication-ready LaTeX instantly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "problem-examples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Test Cases for Code-to-LaTeX Conversion:\n",
      "==================================================\n",
      " 1. np.sqrt(x**2 + y**2)\n",
      " 2. np.sin(theta) * np.cos(phi)\n",
      " 3. np.exp(-0.5 * (x/sigma)**2)\n",
      " 4. (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
      " 5. np.mean(data) + 1.96 * np.std(data) / np.sqrt(len(data))\n",
      " 6. np.dot(A, x) + b\n",
      " 7. np.linalg.norm(gradient)\n",
      " 8. np.sum((hypothesis - y)**2) / (2 * len(y))\n",
      " 9. alpha * learning_rate * np.gradient(cost_function)\n",
      "\n",
      "ğŸ“Š Total test cases: 9\n",
      "ğŸ¯ Goal: Convert all of these to publication-ready LaTeX!\n"
     ]
    }
   ],
   "source": [
    "# Let's define our test cases for this tutorial\n",
    "research_code_examples = [\n",
    "    # Basic mathematical functions\n",
    "    \"np.sqrt(x**2 + y**2)\",\n",
    "    \"np.sin(theta) * np.cos(phi)\", \n",
    "    \"np.exp(-0.5 * (x/sigma)**2)\",\n",
    "    \n",
    "    # Statistical formulas\n",
    "    \"(1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\",\n",
    "    \"np.mean(data) + 1.96 * np.std(data) / np.sqrt(len(data))\",\n",
    "    \n",
    "    # Linear algebra\n",
    "    \"np.dot(A, x) + b\",\n",
    "    \"np.linalg.norm(gradient)\",\n",
    "    \n",
    "    # Complex expressions\n",
    "    \"np.sum((hypothesis - y)**2) / (2 * len(y))\",\n",
    "    \"alpha * learning_rate * np.gradient(cost_function)\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Test Cases for Code-to-LaTeX Conversion:\")\n",
    "print(\"=\" * 50)\n",
    "for i, code in enumerate(research_code_examples, 1):\n",
    "    print(f\"{i:2d}. {code}\")\n",
    "    \n",
    "print(f\"\\nğŸ“Š Total test cases: {len(research_code_examples)}\")\n",
    "print(\"ğŸ¯ Goal: Convert all of these to publication-ready LaTeX!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-header",
   "metadata": {},
   "source": [
    "# Section 2: Hardcoded Approach (30 min)\n",
    "\n",
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "Traditional approaches use regex patterns to match and replace code constructs. This works well for simple, predictable patterns but breaks down with complex nested expressions or unusual variable names.\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "Let's first try the traditional hardcoded approach using regex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hardcoded-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ AGENT EVOLUTION DEMONSTRATION\n",
      "==================================================\n",
      "\n",
      "1. HARDCODED APPROACH (Traditional)\n",
      "   - Fast execution\n",
      "   - Predictable patterns\n",
      "   - Limited to known cases\n",
      "   - Requires manual updates\n",
      "\n",
      "2. LLM AGENT APPROACH (Modern)\n",
      "   - Contextual understanding\n",
      "   - Handles complex cases\n",
      "   - Learns from examples\n",
      "   - API dependency\n",
      "\n",
      "3. HYBRID APPROACH (Optimal)\n",
      "   - Best of both worlds\n",
      "   - Fast for simple cases\n",
      "   - Intelligent for complex cases\n",
      "   - Graceful fallback strategy\n",
      "\n",
      "ğŸ¯ Research Application:\n",
      "Choose approach based on your specific needs:\n",
      "â€¢ Speed critical + simple patterns â†’ Hardcoded\n",
      "â€¢ Complex understanding required â†’ LLM Agent\n",
      "â€¢ Production system â†’ Hybrid\n"
     ]
    }
   ],
   "source": [
    "# Import our hardcoded processor\n",
    "from agent_basics import HardcodedMathProcessor, demonstrate_agent_evolution\n",
    "\n",
    "# Show the evolution concepts\n",
    "demonstrate_agent_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hardcoded-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ HARDCODED APPROACH TESTING\n",
      "========================================\n",
      "\n",
      "ğŸ§ª Test 1: np.sqrt(x**2 + y**2)\n",
      "âœ… Success: $\\sqrt{x^{2} + y^{2}}$\n",
      "   Confidence: 1.00\n",
      "   Time: 0.002s\n",
      "\n",
      "ğŸ§ª Test 2: np.sin(theta) * np.cos(phi)\n",
      "âœ… Success: $\\sin(theta) * \\cos(phi)$\n",
      "   Confidence: 0.67\n",
      "   Time: 0.000s\n",
      "\n",
      "ğŸ§ª Test 3: np.exp(-0.5 * (x/sigma)**2)\n",
      "âœ… Success: $e^{-0.5 * (\\frac{x}{sigma}}^2)$\n",
      "   Confidence: 1.00\n",
      "   Time: 0.000s\n",
      "\n",
      "ğŸ§ª Test 4: (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
      "âœ… Success: $(1 / (sigma * \\sqrt{2 * np.pi})) * e^{-0.5 * ((x - mu} / sigma)^2)$\n",
      "   Confidence: 1.00\n",
      "   Time: 0.000s\n",
      "\n",
      "ğŸ§ª Test 5: np.mean(data) + 1.96 * np.std(data) / np.sqrt(len(data))\n",
      "âœ… Success: $np.mean(data) + 1.96 * np.std(data) / \\sqrt{len(data})$\n",
      "   Confidence: 0.33\n",
      "   Time: 0.000s\n",
      "\n",
      "ğŸ“Š HARDCODED PERFORMANCE:\n",
      "Success Rate: 100.0%\n",
      "Average Confidence: 0.80\n",
      "Limitations: 5 known issues\n"
     ]
    }
   ],
   "source": [
    "# Create and test the hardcoded processor\n",
    "hardcoded_processor = HardcodedMathProcessor()\n",
    "\n",
    "print(\"ğŸ”§ HARDCODED APPROACH TESTING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test on our research examples\n",
    "hardcoded_results = []\n",
    "\n",
    "for i, code in enumerate(research_code_examples[:5], 1):  # Test first 5\n",
    "    print(f\"\\nğŸ§ª Test {i}: {code}\")\n",
    "    result = hardcoded_processor.process(code)\n",
    "    hardcoded_results.append(result)\n",
    "    \n",
    "    if result.success:\n",
    "        print(f\"âœ… Success: {result.output}\")\n",
    "        print(f\"   Confidence: {result.confidence:.2f}\")\n",
    "        print(f\"   Time: {result.processing_time:.3f}s\")\n",
    "    else:\n",
    "        print(f\"âŒ Failed: {result.output}\")\n",
    "\n",
    "# Calculate overall performance\n",
    "success_rate = hardcoded_processor.get_success_rate()\n",
    "avg_confidence = hardcoded_processor.get_average_confidence()\n",
    "\n",
    "print(f\"\\nğŸ“Š HARDCODED PERFORMANCE:\")\n",
    "print(f\"Success Rate: {success_rate:.1%}\")\n",
    "print(f\"Average Confidence: {avg_confidence:.2f}\")\n",
    "print(f\"Limitations: {len(hardcoded_processor.limitations)} known issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hardcoded-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” HARDCODED APPROACH ANALYSIS\n",
      "===================================\n",
      "\n",
      "âœ… STRENGTHS:\n",
      "   â€¢ Fast execution (no API calls)\n",
      "   â€¢ Predictable output format\n",
      "   â€¢ No external dependencies\n",
      "   â€¢ Works offline\n",
      "   â€¢ Deterministic results\n",
      "\n",
      "âŒ WEAKNESSES:\n",
      "   â€¢ Cannot handle nested function calls\n",
      "   â€¢ Limited to predefined patterns\n",
      "   â€¢ Struggles with complex expressions\n",
      "   â€¢ No contextual understanding\n",
      "   â€¢ Requires manual pattern updates\n",
      "\n",
      "ğŸ¯ BEST USE CASES:\n",
      "   â€¢ Simple, repetitive patterns\n",
      "   â€¢ High-volume processing where speed matters\n",
      "   â€¢ When API access is restricted\n",
      "   â€¢ Preprocessing step before LLM processing\n"
     ]
    }
   ],
   "source": [
    "# Analyze hardcoded approach strengths and weaknesses\n",
    "print(\"ğŸ” HARDCODED APPROACH ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "print(\"\\nâœ… STRENGTHS:\")\n",
    "strengths = [\n",
    "    \"Fast execution (no API calls)\",\n",
    "    \"Predictable output format\", \n",
    "    \"No external dependencies\",\n",
    "    \"Works offline\",\n",
    "    \"Deterministic results\"\n",
    "]\n",
    "for strength in strengths:\n",
    "    print(f\"   â€¢ {strength}\")\n",
    "\n",
    "print(\"\\nâŒ WEAKNESSES:\")\n",
    "for limitation in hardcoded_processor.limitations:\n",
    "    print(f\"   â€¢ {limitation}\")\n",
    "\n",
    "print(\"\\nğŸ¯ BEST USE CASES:\")\n",
    "use_cases = [\n",
    "    \"Simple, repetitive patterns\",\n",
    "    \"High-volume processing where speed matters\",\n",
    "    \"When API access is restricted\",\n",
    "    \"Preprocessing step before LLM processing\"\n",
    "]\n",
    "for use_case in use_cases:\n",
    "    print(f\"   â€¢ {use_case}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-header",
   "metadata": {},
   "source": [
    "# Section 3: Multi-Provider LLM Setup (45 min)\n",
    "\n",
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "Modern research is global - your LLM setup should support researchers worldwide with different provider preferences and access restrictions. A flexible provider system lets you switch between Google Gemini, OpenAI, DashScope, and others seamlessly.\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "Now let's set up our multi-provider LLM system for intelligent conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "llm-provider-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking Available LLM Providers...\n",
      "ğŸ” Available LLM Providers for Research:\n",
      "------------------------------------------------------------\n",
      "âŒ GOOGLE     - Google Gemini - Excellent for mathematical reasoning\n",
      "   Default: gemini-2.5-pro\n",
      "   Fast: gemini-2.5-flash\n",
      "   âš ï¸  Set GEMINI_API_KEY to enable\n",
      "\n",
      "âŒ OPENAI     - OpenAI GPT - Reliable for code understanding\n",
      "   Default: gpt-4o\n",
      "   Fast: gpt-4o-mini\n",
      "   âš ï¸  Set OPENAI_API_KEY to enable\n",
      "\n",
      "âœ… DASHSCOPE  - DashScope Qwen - Cost-effective with good performance\n",
      "   Default: qwen-plus\n",
      "   Fast: qwen-plus\n",
      "\n",
      "âœ… ZHIPUAI    - Zhipu AI GLM - Optimized for Chinese researchers\n",
      "   Default: glm-4\n",
      "   Fast: glm-4-flash\n",
      "\n",
      "ğŸ¯ Recommended: DASHSCOPE\n"
     ]
    }
   ],
   "source": [
    "# Import our LLM provider system\n",
    "from llm_providers import (\n",
    "    ResearchLLMFactory, \n",
    "    LLMProvider, \n",
    "    create_research_llm,\n",
    "    list_research_providers\n",
    ")\n",
    "\n",
    "# Check available providers\n",
    "print(\"ğŸ” Checking Available LLM Providers...\")\n",
    "list_research_providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "llm-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully created research LLM!\n",
      "   Model type: ChatOpenAI\n",
      "   Test response: LLM ready for research\n"
     ]
    }
   ],
   "source": [
    "# Create LLM instance for research\n",
    "try:\n",
    "    # Try to create a research LLM (will auto-select best available)\n",
    "    research_llm = create_research_llm(\n",
    "        # model=\"dashscope\",  # Specify model type\n",
    "        temperature=0.3,  # Low temperature for consistent mathematical output\n",
    "        fast_mode=False   # Use high-quality model for accuracy\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Successfully created research LLM!\")\n",
    "    print(f\"   Model type: {type(research_llm).__name__}\")\n",
    "    \n",
    "    # Test the LLM with a simple query\n",
    "    test_response = research_llm.invoke(\"Hello! Please respond with 'LLM ready for research'\")\n",
    "    print(f\"   Test response: {test_response.content}\")\n",
    "    \n",
    "    llm_available = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to create LLM: {e}\")\n",
    "    print(\"\\nğŸ’¡ To fix this:\")\n",
    "    print(\"1. Make sure you have API keys in your .env file\")\n",
    "    print(\"2. Check your internet connection\")\n",
    "    print(\"3. Verify API key permissions and quotas\")\n",
    "    \n",
    "    llm_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-implementation-header",
   "metadata": {},
   "source": [
    "## ğŸ¤– Building the Intelligent Agent\n",
    "\n",
    "Now let's create our LLM-based code conversion agent that can understand context and handle complex mathematical expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "agent-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Created Code-to-LaTeX Agent!\n",
      "   Capabilities: 5\n",
      "   Function mappings: 24\n",
      "   Greek letter support: 14\n"
     ]
    }
   ],
   "source": [
    "if llm_available:\n",
    "    from agent_basics import LLMAgent\n",
    "    from code_to_latex import create_research_converter, CodeLanguage, ConversionType\n",
    "    \n",
    "    # Create our specialized code-to-LaTeX converter\n",
    "    latex_converter = create_research_converter(\n",
    "        llm=research_llm,\n",
    "        language=CodeLanguage.PYTHON,\n",
    "        conversion_type=ConversionType.INLINE_MATH\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ¤– Created Code-to-LaTeX Agent!\")\n",
    "    print(f\"   Capabilities: {len(latex_converter.capabilities)}\")\n",
    "    print(f\"   Function mappings: {len(latex_converter.function_mappings)}\")\n",
    "    print(f\"   Greek letter support: {len(latex_converter.greek_mapping)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping agent creation (no LLM available)\")\n",
    "    print(\"   The concepts still apply - you can run this when LLM is configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88097800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<code_to_latex.CodeToLatexAgent at 0x7ba0405f3910>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "agent-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª TESTING LLM AGENT APPROACH\n",
      "===================================\n",
      "\n",
      "ğŸ”¬ Test 1: np.sqrt(x**2 + y**2)\n",
      "âœ… Success: $\\sqrt{x^2 + y^2}$\n",
      "   Confidence: 1.00\n",
      "   Time: 1.214s\n",
      "\n",
      "ğŸ”¬ Test 2: np.sin(theta) * np.cos(phi)\n",
      "âœ… Success: $\\sin(\\theta) \\cdot \\cos(\\phi)$\n",
      "   Confidence: 0.70\n",
      "   Time: 1.567s\n",
      "\n",
      "ğŸ”¬ Test 3: np.exp(-0.5 * (x/sigma)**2)\n",
      "âœ… Success: $e^{-0.5 \\left(\\frac{x}{\\sigma}\\right)^2}$\n",
      "   Confidence: 1.00\n",
      "   Time: 1.220s\n",
      "\n",
      "ğŸ”¬ Test 4: (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
      "âœ… Success: $\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{1}{2} \\left(\\frac{x - \\mu}{\\sigma}\\right)^2\\right)$\n",
      "   Confidence: 1.00\n",
      "   Time: 1.686s\n",
      "\n",
      "ğŸ”¬ Test 5: np.mean(data) + 1.96 * np.std(data) / np.sqrt(len(data))\n",
      "âœ… Success: $\\text{mean}(\\text{data}) + 1.96 \\cdot \\frac{\\text{std}(\\text{data})}{\\sqrt{\\text{len}(\\text{data})}}$\n",
      "   Confidence: 1.00\n",
      "   Time: 2.207s\n",
      "\n",
      "ğŸ“Š AGENT PERFORMANCE:\n",
      "Success Rate: 100.0%\n",
      "Average Confidence: 0.94\n"
     ]
    }
   ],
   "source": [
    "if llm_available:\n",
    "    print(\"ğŸ§ª TESTING LLM AGENT APPROACH\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Test on the same examples we used for hardcoded\n",
    "    agent_results = []\n",
    "    \n",
    "    for i, code in enumerate(research_code_examples[:5], 1):\n",
    "        print(f\"\\nğŸ”¬ Test {i}: {code}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = latex_converter.convert_expression(code) # convert_algorithm\n",
    "        \n",
    "        agent_results.append(result)\n",
    "        \n",
    "        if result.success:\n",
    "            print(f\"âœ… Success: {result.output}\")\n",
    "            print(f\"   Confidence: {result.confidence:.2f}\")\n",
    "            print(f\"   Time: {result.processing_time:.3f}s\")\n",
    "        else:\n",
    "            print(f\"âŒ Failed: {result.metadata.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    agent_success_rate = latex_converter.get_success_rate()\n",
    "    agent_avg_confidence = latex_converter.get_average_confidence()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š AGENT PERFORMANCE:\")\n",
    "    print(f\"Success Rate: {agent_success_rate:.1%}\")\n",
    "    print(f\"Average Confidence: {agent_avg_confidence:.2f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping agent testing (no LLM available)\")\n",
    "    print(\"\\nğŸ’¡ Expected results with LLM agent:\")\n",
    "    print(\"   â€¢ Higher success rate on complex expressions\")\n",
    "    print(\"   â€¢ Better handling of nested functions\")\n",
    "    print(\"   â€¢ Contextual understanding of mathematical notation\")\n",
    "    print(\"   â€¢ Slower execution due to API calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc18a72",
   "metadata": {},
   "source": [
    "$\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{1}{2} \\left(\\frac{x - \\mu}{\\sigma}\\right)^2\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "## ğŸ“Š Direct Comparison: Hardcoded vs Agent\n",
    "\n",
    "Let's compare both approaches side-by-side to understand when to use each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "comparison-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš”ï¸ HARDCODED vs AGENT COMPARISON\n",
      "========================================\n",
      "\n",
      "ğŸ§ª Testing HARDCODED approach...\n",
      "  Case 1: np.sqrt(x**2 + y**2)...\n",
      "  Case 2: np.sin(theta) * np.cos(phi)...\n",
      "  Case 3: np.exp(-0.5 * (x/sigma)**2)...\n",
      "  Case 4: (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 *...\n",
      "  Case 5: np.mean(data) + 1.96 * np.std(data) / np.sqrt(len(...\n",
      "    Success Rate: 100.00%\n",
      "    Avg Confidence: 0.80\n",
      "    Avg Time: 0.000s\n",
      "\n",
      "ğŸ§ª Testing LLM_AGENT approach...\n",
      "  Case 1: np.sqrt(x**2 + y**2)...\n",
      "  Case 2: np.sin(theta) * np.cos(phi)...\n",
      "  Case 3: np.exp(-0.5 * (x/sigma)**2)...\n",
      "  Case 4: (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 *...\n",
      "  Case 5: np.mean(data) + 1.96 * np.std(data) / np.sqrt(len(...\n",
      "    Success Rate: 100.00%\n",
      "    Avg Confidence: 0.94\n",
      "    Avg Time: 1.199s\n",
      "\n",
      "ğŸ§ª Testing HYBRID approach...\n",
      "  Case 1: np.sqrt(x**2 + y**2)...\n",
      "  Case 2: np.sin(theta) * np.cos(phi)...\n",
      "  Case 3: np.exp(-0.5 * (x/sigma)**2)...\n",
      "  Case 4: (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 *...\n",
      "  Case 5: np.mean(data) + 1.96 * np.std(data) / np.sqrt(len(...\n",
      "    Success Rate: 100.00%\n",
      "    Avg Confidence: 0.93\n",
      "    Avg Time: 0.637s\n",
      "\n",
      "ğŸ“Š PERFORMANCE COMPARISON:\n",
      "------------------------------------------------------------\n",
      "Approach     Success Rate Avg Confidence  Avg Time  \n",
      "------------------------------------------------------------\n",
      "Hardcoded    100.0%      0.80           0.000    s\n",
      "Llm_Agent    100.0%      0.94           1.199    s\n",
      "Hybrid       100.0%      0.93           0.637    s\n",
      "\n",
      "ğŸ¯ RECOMMENDATIONS:\n",
      "â€¢ HARDCODED: Use for simple patterns, high-volume processing\n",
      "â€¢ LLM AGENT: Use for complex expressions, varied notation\n",
      "â€¢ HYBRID: Best of both - fast for simple, intelligent for complex\n"
     ]
    }
   ],
   "source": [
    "if llm_available:\n",
    "    from agent_basics import compare_approaches\n",
    "    \n",
    "    print(\"âš”ï¸ HARDCODED vs AGENT COMPARISON\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Run comprehensive comparison\n",
    "    comparison_results = compare_approaches(\n",
    "        test_cases=research_code_examples[:5],  # Use first 5 for speed\n",
    "        llm=research_llm\n",
    "    )\n",
    "    \n",
    "    # Create comparison table\n",
    "    print(\"\\nğŸ“Š PERFORMANCE COMPARISON:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Approach':<12} {'Success Rate':<12} {'Avg Confidence':<15} {'Avg Time':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for approach, metrics in comparison_results.items():\n",
    "        print(f\"{approach.title():<12} {metrics['success_rate']:<11.1%} {metrics['avg_confidence']:<14.2f} {metrics['avg_processing_time']:<9.3f}s\")\n",
    "    \n",
    "    print(\"\\nğŸ¯ RECOMMENDATIONS:\")\n",
    "    print(\"â€¢ HARDCODED: Use for simple patterns, high-volume processing\")\n",
    "    print(\"â€¢ LLM AGENT: Use for complex expressions, varied notation\")\n",
    "    print(\"â€¢ HYBRID: Best of both - fast for simple, intelligent for complex\")\n",
    "    \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping comparison (no LLM available)\")\n",
    "    print(\"\\nğŸ“Š Expected comparison results:\")\n",
    "    print(\"Approach     Success Rate  Avg Confidence  Avg Time\")\n",
    "    print(\"Hardcoded    ~60%         ~0.4            ~0.001s\")\n",
    "    print(\"LLM Agent    ~95%         ~0.8            ~1.5s\")\n",
    "    print(\"Hybrid       ~95%         ~0.8            ~0.8s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-header",
   "metadata": {},
   "source": [
    "# Section 4: LangGraph Workflow (30 min)\n",
    "\n",
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "LangGraph provides structure to complex workflows without overwhelming complexity. For research applications, it helps organize multi-step processes like: Parse â†’ Convert â†’ Validate â†’ Format â†’ Output. This pattern is reusable across different research tasks.\n",
    "\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "Now let's organize our conversion process into a structured workflow using LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af79a2a",
   "metadata": {},
   "source": [
    "#### ğŸ“ LANGGRAPH BASICS FOR RESEARCH\n",
    "==================================================\n",
    "\n",
    "ğŸ”„ Core Concepts:\n",
    "1. STATE: Data that flows between processing steps\n",
    "2. NODES: Individual processing functions\n",
    "3. EDGES: Connections between nodes\n",
    "4. GRAPH: Complete workflow definition\n",
    "\n",
    "ğŸ“Š Research Workflow Pattern:\n",
    "   INPUT â†’ ANALYZE â†’ PROCESS â†’ VALIDATE â†’ OUTPUT\n",
    "\n",
    "ğŸ¯ Benefits for Research:\n",
    "â€¢ Reproducible workflows\n",
    "â€¢ Clear processing steps\n",
    "â€¢ Error handling and validation\n",
    "â€¢ Easy to modify and extend\n",
    "\n",
    "ğŸ’¡ When to Use LangGraph:\n",
    "â€¢ Multi-step research processes\n",
    "â€¢ Need for workflow visualization\n",
    "â€¢ Complex decision logic\n",
    "â€¢ Collaboration between different processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "simple-workflow-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ CREATING RESEARCH WORKFLOW\n",
      "===================================\n",
      "âœ… Workflow created with nodes:\n",
      "   1. INPUT\n",
      "   2. ANALYZE\n",
      "   3. PROCESS\n",
      "   4. VALIDATE\n",
      "   5. OUTPUT\n",
      "\n",
      "ğŸ”— Workflow pattern: input â†’ analyze â†’ process â†’ validate â†’ output\n"
     ]
    }
   ],
   "source": [
    "# Create and test a simple research workflow\n",
    "print(\"ğŸ”„ CREATING RESEARCH WORKFLOW\")\n",
    "print(\"=\" * 35)\n",
    "from graph_introduction import create_simple_research_workflow, ResearchTask,SimpleResearchState\n",
    "# Build the workflow\n",
    "research_workflow = create_simple_research_workflow()\n",
    "\n",
    "print(\"âœ… Workflow created with nodes:\")\n",
    "workflow_nodes = [\"input\", \"analyze\", \"process\", \"validate\", \"output\"]\n",
    "for i, node in enumerate(workflow_nodes, 1):\n",
    "    print(f\"   {i}. {node.upper()}\")\n",
    "\n",
    "print(f\"\\nğŸ”— Workflow pattern: {' â†’ '.join(workflow_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "workflow-execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ EXECUTING WORKFLOW\n",
      "=========================\n",
      "ğŸ“‹ Task: tutorial_001\n",
      "   Content: np.sqrt(x**2 + y**2)\n",
      "   Type: code_conversion\n",
      "\n",
      "ğŸ”„ Running workflow...\n",
      "\n",
      "ğŸ“¥ INPUT: Processing task 'tutorial_001'\n",
      "   Content: np.sqrt(x**2 + y**2)...\n",
      "ğŸ” ANALYZE: Analyzing task type 'code_conversion'\n",
      "âš™ï¸ PROCESS: Executing main processing for code_conversion\n",
      "âœ… VALIDATE: Checking output quality\n",
      "ğŸ“¤ OUTPUT: Finalizing results\n",
      "\n",
      "========================================\n",
      "ğŸ“Š WORKFLOW RESULTS\n",
      "========================================\n",
      "Final Stage: complete\n",
      "\n",
      "Final Output:\n",
      "RESEARCH RESULT:\\nLaTeX conversion: $\\\\sqrt(x^2 + y^2)$\\n\\nValidation: Validation passed: Output appears correct\n",
      "\n",
      "ğŸ“š Processing Steps (5):\n",
      "   1. INPUT: Started processing code_conversion task\n",
      "   2. ANALYZE: Code conversion task detected. Language: python\n",
      "   3. PROCESS: Applied code_conversion processing logic\n",
      "   4. VALIDATE: Validation passed: Output appears correct\n",
      "   5. OUTPUT: Workflow completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Run the workflow with a research task\n",
    "print(\"\\nğŸš€ EXECUTING WORKFLOW\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Create a research task\n",
    "sample_task = ResearchTask(\n",
    "    task_id=\"tutorial_001\",\n",
    "    content=\"np.sqrt(x**2 + y**2)\",\n",
    "    task_type=\"code_conversion\",\n",
    "    metadata={\"language\": \"python\", \"target\": \"latex\"}\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“‹ Task: {sample_task.task_id}\")\n",
    "print(f\"   Content: {sample_task.content}\")\n",
    "print(f\"   Type: {sample_task.task_type}\")\n",
    "\n",
    "# Initial state\n",
    "initial_state = SimpleResearchState(\n",
    "    task=sample_task,\n",
    "    current_stage=\"starting\",\n",
    "    analysis_result=\"\",\n",
    "    processed_content=\"\",\n",
    "    validation_status=\"\",\n",
    "    final_output=\"\",\n",
    "    processing_history=[],\n",
    "    error_messages=[]\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Execute the workflow\n",
    "    print(\"\\nğŸ”„ Running workflow...\\n\")\n",
    "    result = research_workflow.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"ğŸ“Š WORKFLOW RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"Final Stage: {result['current_stage']}\")\n",
    "    print(f\"\\nFinal Output:\\n{result['final_output']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“š Processing Steps ({len(result['processing_history'])}):\")\n",
    "    for i, step in enumerate(result['processing_history'], 1):\n",
    "        print(f\"   {i}. {step['stage'].upper()}: {step['details']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Workflow execution failed: {e}\")\n",
    "    print(\"ğŸ’¡ This is normal if running without full setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-workflow-header",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Advanced Workflow: Code Conversion Pipeline\n",
    "\n",
    "Let's create a more sophisticated workflow specifically for code-to-LaTeX conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "advanced-workflow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¬ ADVANCED CODE CONVERSION WORKFLOW\n",
      "========================================\n",
      "âœ… Advanced workflow created with stages:\n",
      "   1. PARSE\n",
      "   2. CONVERT\n",
      "   3. VALIDATE\n",
      "   4. FINALIZE\n",
      "\n",
      "ğŸ§ª Testing with complex expression:\n",
      "   (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
      "\n",
      "ğŸ”„ Running conversion workflow...\n",
      "\n",
      "ğŸ” PARSE: Analyzing python code\n",
      "ğŸ”„ CONVERT: Converting to inline LaTeX\n",
      "âœ… VALIDATE: Checking LaTeX formatting\n",
      "ğŸ“‹ FINALIZE: Preparing final output\n",
      "\n",
      "==================================================\n",
      "ğŸ“Š CONVERSION RESULTS\n",
      "==================================================\n",
      "Original Code: (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
      "Final LaTeX: \\texttt{(1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)}\n",
      "Confidence: 1.00\n",
      "Success: False\n"
     ]
    }
   ],
   "source": [
    "if llm_available:\n",
    "    from graph_introduction import create_code_conversion_workflow, CodeConversionState\n",
    "    \n",
    "    print(\"ğŸ”¬ ADVANCED CODE CONVERSION WORKFLOW\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create specialized workflow\n",
    "    conversion_workflow = create_code_conversion_workflow(latex_converter)\n",
    "    \n",
    "    print(\"âœ… Advanced workflow created with stages:\")\n",
    "    advanced_stages = [\"parse\", \"convert\", \"validate\", \"finalize\"]\n",
    "    for i, stage in enumerate(advanced_stages, 1):\n",
    "        print(f\"   {i}. {stage.upper()}\")\n",
    "    \n",
    "    # Test with complex expression\n",
    "    test_code = \"(1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\"\n",
    "    \n",
    "    print(f\"\\nğŸ§ª Testing with complex expression:\")\n",
    "    print(f\"   {test_code}\")\n",
    "    \n",
    "    # Initial state for conversion workflow\n",
    "    conversion_state = CodeConversionState(\n",
    "        original_code=test_code,\n",
    "        language=\"python\",\n",
    "        conversion_type=\"inline\",\n",
    "        parsed_code={},\n",
    "        latex_output=\"\",\n",
    "        validation_result={},\n",
    "        final_latex=\"\",\n",
    "        confidence_score=0.0,\n",
    "        metadata={}\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nğŸ”„ Running conversion workflow...\\n\")\n",
    "        conversion_result = conversion_workflow.invoke(conversion_state)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ“Š CONVERSION RESULTS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(f\"Original Code: {conversion_result['original_code']}\")\n",
    "        print(f\"Final LaTeX: {conversion_result['final_latex']}\")\n",
    "        print(f\"Confidence: {conversion_result['confidence_score']:.2f}\")\n",
    "        print(f\"Success: {conversion_result['metadata']['conversion_successful']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Conversion workflow failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping advanced workflow (no LLM available)\")\n",
    "    print(\"\\nğŸ’¡ Advanced workflow would provide:\")\n",
    "    print(\"   â€¢ Code parsing and analysis\")\n",
    "    print(\"   â€¢ Intelligent LaTeX conversion\")\n",
    "    print(\"   â€¢ Output validation and quality checks\")\n",
    "    print(\"   â€¢ Formatted final results with confidence scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-header",
   "metadata": {},
   "source": [
    "# Section 5: Practical Applications (15 min)\n",
    "\n",
    "## ğŸ¯ Research Workflow Integration\n",
    "\n",
    "Let's see how to integrate this into your actual research workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "practical-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ RESEARCH PAPER SCENARIO\n",
      "==============================\n",
      "ğŸ“‹ Your paper has code in multiple sections:\n",
      "\n",
      "ğŸ“– Introduction:\n",
      "   â€¢ distance = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
      "   â€¢ similarity = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
      "\n",
      "ğŸ“– Methodology:\n",
      "   â€¢ cost = (1 / (2 * m)) * np.sum((hypothesis - y)**2)\n",
      "   â€¢ gradient = (1 / m) * X.T.dot(hypothesis - y)\n",
      "\n",
      "ğŸ“– Results:\n",
      "   â€¢ accuracy = np.sum(predictions == y_test) / len(y_test)\n",
      "   â€¢ mse = np.mean((predictions - y_true)**2)\n",
      "\n",
      "ğŸ“Š Total expressions to convert: 6\n",
      "â° Manual conversion time: ~90 minutes\n",
      "ğŸ¤– Agent conversion time: ~12 minutes\n",
      "ğŸ’¡ Time saved: ~78 minutes!\n"
     ]
    }
   ],
   "source": [
    "# Simulate a real research scenario\n",
    "print(\"ğŸ“„ RESEARCH PAPER SCENARIO\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "research_paper_sections = {\n",
    "    \"Introduction\": [\n",
    "        \"distance = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\",\n",
    "        \"similarity = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\"\n",
    "    ],\n",
    "    \"Methodology\": [\n",
    "        \"cost = (1 / (2 * m)) * np.sum((hypothesis - y)**2)\",\n",
    "        \"gradient = (1 / m) * X.T.dot(hypothesis - y)\"\n",
    "    ],\n",
    "    \"Results\": [\n",
    "        \"accuracy = np.sum(predictions == y_test) / len(y_test)\",\n",
    "        \"mse = np.mean((predictions - y_true)**2)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ Your paper has code in multiple sections:\")\n",
    "total_expressions = 0\n",
    "for section, expressions in research_paper_sections.items():\n",
    "    print(f\"\\nğŸ“– {section}:\")\n",
    "    for expr in expressions:\n",
    "        print(f\"   â€¢ {expr}\")\n",
    "        total_expressions += 1\n",
    "\n",
    "print(f\"\\nğŸ“Š Total expressions to convert: {total_expressions}\")\n",
    "print(f\"â° Manual conversion time: ~{total_expressions * 15} minutes\")\n",
    "print(f\"ğŸ¤– Agent conversion time: ~{total_expressions * 2} minutes\")\n",
    "print(f\"ğŸ’¡ Time saved: ~{total_expressions * 13} minutes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "batch-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ BATCH PROCESSING DEMONSTRATION\n",
      "===================================\n",
      "ğŸ“¦ Processing 6 expressions...\n",
      "\n",
      "ğŸ“Š BATCH CONVERSION RESULTS:\n",
      "Total time: 11.3s\n",
      "Average per expression: 1.9s\n",
      "Success rate: 6/6 (100.0%)\n",
      "\n",
      "ğŸ“„ Sample conversions:\n",
      "\n",
      "1. Original: distance = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
      "   LaTeX: $ \\text{distance} = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2} $\n",
      "\n",
      "2. Original: similarity = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
      "   LaTeX: $\\text{similarity} = \\frac{v_1 \\cdot v_2}{\\|v_1\\| \\cdot \\|v_2\\|}$\n",
      "\n",
      "3. Original: cost = (1 / (2 * m)) * np.sum((hypothesis - y)**2)\n",
      "   LaTeX: $\\text{cost} = \\frac{1}{2m} \\sum (hypothesis - y)^2$\n"
     ]
    }
   ],
   "source": [
    "if llm_available:\n",
    "    print(\"\\nğŸ”„ BATCH PROCESSING DEMONSTRATION\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Collect all expressions\n",
    "    all_expressions = []\n",
    "    for section, expressions in research_paper_sections.items():\n",
    "        all_expressions.extend(expressions)\n",
    "    \n",
    "    print(f\"ğŸ“¦ Processing {len(all_expressions)} expressions...\")\n",
    "    \n",
    "    # Batch convert using our agent\n",
    "    start_time = time.time()\n",
    "    batch_results = latex_converter.batch_convert(all_expressions)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nğŸ“Š BATCH CONVERSION RESULTS:\")\n",
    "    print(f\"Total time: {total_time:.1f}s\")\n",
    "    print(f\"Average per expression: {total_time/len(all_expressions):.1f}s\")\n",
    "    \n",
    "    successful_conversions = sum(1 for r in batch_results if r.success)\n",
    "    print(f\"Success rate: {successful_conversions}/{len(all_expressions)} ({successful_conversions/len(all_expressions):.1%})\")\n",
    "    \n",
    "    print(\"\\nğŸ“„ Sample conversions:\")\n",
    "    for i, (original, result) in enumerate(zip(all_expressions[:3], batch_results[:3])):\n",
    "        print(f\"\\n{i+1}. Original: {original}\")\n",
    "        if result.success:\n",
    "            print(f\"   LaTeX: {result.output}\")\n",
    "        else:\n",
    "            print(f\"   Error: Failed to convert\")\n",
    "            \n",
    "else:\n",
    "    print(\"\\nâ­ï¸ Skipping batch processing (no LLM available)\")\n",
    "    print(\"ğŸ’¡ Batch processing would convert all expressions efficiently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integration-guidelines",
   "metadata": {},
   "source": [
    "## ğŸ’¼ Integration Guidelines\n",
    "\n",
    "### When to Use Each Approach:\n",
    "\n",
    "1. **Hardcoded Approach**:\n",
    "   - Simple, repetitive patterns\n",
    "   - High-volume processing (1000+ expressions)\n",
    "   - Offline processing requirements\n",
    "   - Preprocessing step\n",
    "\n",
    "2. **LLM Agent Approach**:\n",
    "   - Complex mathematical expressions\n",
    "   - Variable notation styles\n",
    "   - Context-dependent conversion\n",
    "   - Quality over speed priority\n",
    "\n",
    "3. **LangGraph Workflow**:\n",
    "   - Multi-step research processes\n",
    "   - Need for validation and quality control\n",
    "   - Collaborative research environments\n",
    "   - Reproducible research workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-section",
   "metadata": {},
   "source": [
    "# ğŸƒ Hands-on Exercise\n",
    "\n",
    "**Challenge**: Adapt the code converter for your specific research domain!\n",
    "\n",
    "## Exercise Tasks:\n",
    "\n",
    "1. **Customize for Your Field**: Modify the function mappings for your research area\n",
    "2. **Add New Patterns**: Extend the hardcoded processor with domain-specific patterns\n",
    "3. **Create Custom Workflow**: Design a LangGraph workflow for your research process\n",
    "4. **Test Real Examples**: Use expressions from your actual research work\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
