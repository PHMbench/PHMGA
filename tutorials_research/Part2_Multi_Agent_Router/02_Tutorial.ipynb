{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-header",
   "metadata": {},
   "source": [
    "# Part 2: Multi-Agent Router - Research Assistant\n",
    "\n",
    "## 🎯 Research Scenario\n",
    "You're writing a research paper and need to conduct a comprehensive literature review, format citations properly, and generate summaries. Instead of doing this manually with different tools, you'll build an intelligent research assistant that coordinates multiple specialized agents.\n",
    "\n",
    "## 🎓 What You'll Learn\n",
    "\n",
    "1. **Multi-Agent Architecture**: How specialized agents collaborate effectively\n",
    "2. **Router Patterns**: Intelligent task analysis and delegation\n",
    "3. **Real API Integration**: Working with ArXiv, Semantic Scholar, CrossRef\n",
    "4. **Agent Coordination**: Managing complex research workflows\n",
    "\n",
    "## 📋 Prerequisites Check\n",
    "- Part 1 completed (LLM provider configured)\n",
    "- Internet connection (for research APIs)\n",
    "- Optional: API keys for enhanced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "🚀 Multi-Agent Research System Loading...\n",
      "📁 Working directory: /home/lq/LQcode/2_project/PHMBench/PHMGA/tutorials_research/Part2_Multi_Agent_Router\n",
      "🔗 Modules path: /home/lq/LQcode/2_project/PHMBench/PHMGA/tutorials_research/Part2_Multi_Agent_Router/modules\n"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add modules to path\n",
    "current_dir = Path.cwd()\n",
    "modules_dir = current_dir / \"modules\"\n",
    "sys.path.insert(0, str(modules_dir))\n",
    "\n",
    "# Also add Part1 modules (for LLM providers)\n",
    "part1_modules = current_dir.parent / \"Part1_Foundations\" / \"modules\"\n",
    "sys.path.insert(0, str(part1_modules))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(current_dir.parent / \".env\")\n",
    "\n",
    "print(\"🚀 Multi-Agent Research System Loading...\")\n",
    "print(f\"📁 Working directory: {current_dir}\")\n",
    "print(f\"🔗 Modules path: {modules_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-header",
   "metadata": {},
   "source": [
    "# Section 1: Research Tools Integration (45 min)\n",
    "\n",
    "`★ Insight ─────────────────────────────────────`\n",
    "Real research requires real data sources. By integrating with ArXiv, Semantic Scholar, and CrossRef APIs, we create agents that work with actual academic databases rather than simulated data. This authenticity makes the agents immediately useful for research work.\n",
    "`─────────────────────────────────────────────────`\n",
    "\n",
    "Let's start by setting up our research tools that provide access to academic databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388990e",
   "metadata": {},
   "source": [
    " ### 🔬 RESEARCH TOOLS DEMONSTRATION\n",
    "===================================\n",
    "\n",
    "📚 Available Tools:\n",
    "   • ArXiv Client: Preprint repository search (2M+ papers)\n",
    "   • Semantic Scholar: Citation analysis and paper metrics\n",
    "   • CrossRef: DOI resolution and bibliographic data\n",
    "   • Aggregator: Unified search across all sources\n",
    "\n",
    "🎯 Research Capabilities:\n",
    "   • Literature search across multiple databases\n",
    "   • Citation count and influence metrics\n",
    "   • Author collaboration networks\n",
    "   • Paper categorization and filtering\n",
    "   • Full-text and metadata access\n",
    "   • DOI resolution and validation\n",
    "\n",
    "💡 Usage Examples:\n",
    "   • arxiv.search_papers(\"transformer attention\", max_results=10)\n",
    "   • semantic_scholar.search_papers(\"neural networks\", max_results=20)\n",
    "   • crossref.resolve_doi(\"10.1038/nature12373\")\n",
    "   • aggregator.get_comprehensive_results(\"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "research-tools-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 RESEARCH TOOLS DEMONSTRATION\n",
      "===================================\n",
      "\n",
      "📚 Available Tools:\n",
      "   • ArXiv Client: Preprint repository search (2M+ papers)\n",
      "   • Semantic Scholar: Citation analysis and paper metrics\n",
      "   • CrossRef: DOI resolution and bibliographic data\n",
      "   • Aggregator: Unified search across all sources\n",
      "\n",
      "🎯 Research Capabilities:\n",
      "   • Literature search across multiple databases\n",
      "   • Citation count and influence metrics\n",
      "   • Author collaboration networks\n",
      "   • Paper categorization and filtering\n",
      "   • Full-text and metadata access\n",
      "   • DOI resolution and validation\n",
      "\n",
      "💡 Usage Examples:\n",
      "   • arxiv.search_papers(\"transformer attention\", max_results=10)\n",
      "   • semantic_scholar.search_papers(\"neural networks\", max_results=20)\n",
      "   • crossref.resolve_doi(\"10.1038/nature12373\")\n",
      "   • aggregator.get_comprehensive_results(\"machine learning\")\n"
     ]
    }
   ],
   "source": [
    "# Import and demonstrate research tools\n",
    "from research_tools import (\n",
    "    ResearchToolsAggregator,\n",
    "    ArXivClient,\n",
    "    SemanticScholarClient,\n",
    "    demonstrate_research_tools\n",
    ")\n",
    "\n",
    "# Show capabilities\n",
    "demonstrate_research_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "test-arxiv-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 TESTING ARXIV INTEGRATION\n",
      "==============================\n",
      "Searching ArXiv for: 'neural operator'\n",
      "✅ Found 5 papers\n",
      "\n",
      "📋 Sample Results:\n",
      "\n",
      "1. Neural Operator: Learning Maps Between Function Spaces\n",
      "   Authors: Nikola Kovachki, Zongyi Li, Burigede Liu\n",
      "   Date: 2021-08-19\n",
      "   ArXiv ID: 2108.08481v6\n",
      "   Categories: cs.LG, cs.NA, math.NA\n",
      "\n",
      "2. Neural Correction Operator: A Reliable and Fast Approach for Electrical\n",
      "  Impedance Tomography\n",
      "   Authors: Amit Bhat, Ke Chen, Chunmei Wang\n",
      "   Date: 2025-07-25\n",
      "   ArXiv ID: 2507.18875v1\n",
      "   Categories: math.NA, cs.NA\n",
      "\n",
      "3. Resolution-Invariant Image Classification based on Fourier Neural\n",
      "  Operators\n",
      "   Authors: Samira Kabri, Tim Roith, Daniel Tenbrinck\n",
      "   Date: 2023-04-02\n",
      "   ArXiv ID: 2304.01227v1\n",
      "   Categories: cs.CV, cs.LG, cs.NA\n",
      "\n",
      "📊 ArXiv Status: ✅ Available\n"
     ]
    }
   ],
   "source": [
    "# Test ArXiv integration (no API key required)\n",
    "print(\"🔍 TESTING ARXIV INTEGRATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "arxiv_client = ArXivClient()\n",
    "\n",
    "# Search for papers on a research topic\n",
    "search_query = \"neural operator\"\n",
    "print(f\"Searching ArXiv for: '{search_query}'\")\n",
    "\n",
    "try:\n",
    "    papers = arxiv_client.search_papers(\n",
    "        query=search_query,\n",
    "        max_results=5,  # Limit for demo\n",
    "        sort_by=\"relevance\"\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Found {len(papers)} papers\")\n",
    "    \n",
    "    if papers:\n",
    "        print(\"\\n📋 Sample Results:\")\n",
    "        for i, paper in enumerate(papers[:3], 1):\n",
    "            print(f\"\\n{i}. {paper.title}\")\n",
    "            print(f\"   Authors: {', '.join(paper.authors[:3])}\")\n",
    "            print(f\"   Date: {paper.publication_date}\")\n",
    "            print(f\"   ArXiv ID: {paper.arxiv_id}\")\n",
    "            print(f\"   Categories: {', '.join(paper.categories[:3])}\")\n",
    "    else:\n",
    "        print(\"⚠️ No papers found - this might be due to network issues\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ ArXiv search failed: {e}\")\n",
    "    print(\"💡 This is normal if you have network restrictions\")\n",
    "    \n",
    "    # Create some mock data for demonstration\n",
    "    print(\"\\n🎭 Using mock data for demonstration...\")\n",
    "    from research_tools import ResearchPaper\n",
    "    \n",
    "    papers = [\n",
    "        ResearchPaper(\n",
    "            title=\"Attention Is All You Need\",\n",
    "            authors=[\"Ashish Vaswani\", \"Noam Shazeer\"],\n",
    "            abstract=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...\",\n",
    "            publication_date=\"2017-06-12\",\n",
    "            arxiv_id=\"1706.03762\",\n",
    "            source=\"arxiv\",\n",
    "            citation_count=50000\n",
    "        )\n",
    "    ]\n",
    "    print(f\"📄 Mock paper: {papers[0].title}\")\n",
    "\n",
    "arxiv_available = len(papers) > 0\n",
    "print(f\"\\n📊 ArXiv Status: {'✅ Available' if arxiv_available else '❌ Limited'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-header",
   "metadata": {},
   "source": [
    "# Section 2: Literature Search Agent (45 min)\n",
    "\n",
    "`★ Insight ─────────────────────────────────────`\n",
    "\n",
    "Specialized agents outperform general-purpose agents because they can optimize for specific tasks. A literature search agent can implement \n",
    "\n",
    "- domain-specific ranking, \n",
    "\n",
    "- apply academic quality filters, \n",
    "\n",
    "- and extract research insights that a general agent might miss.\n",
    "\n",
    "`─────────────────────────────────────────────────`\n",
    "\n",
    "\n",
    "Now let's create a specialized agent for literature search and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "setup-llm-for-agents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 SETTING UP LLM FOR AGENTS\n",
      "==============================\n",
      "🔍 Available LLM Providers for Research:\n",
      "------------------------------------------------------------\n",
      "❌ GOOGLE     - Google Gemini - Excellent for mathematical reasoning\n",
      "   Default: gemini-2.5-pro\n",
      "   Fast: gemini-2.5-flash\n",
      "   ⚠️  Set GEMINI_API_KEY to enable\n",
      "\n",
      "❌ OPENAI     - OpenAI GPT - Reliable for code understanding\n",
      "   Default: gpt-4o\n",
      "   Fast: gpt-4o-mini\n",
      "   ⚠️  Set OPENAI_API_KEY to enable\n",
      "\n",
      "✅ DASHSCOPE  - DashScope Qwen - Cost-effective with good performance\n",
      "   Default: qwen-plus\n",
      "   Fast: qwen-plus\n",
      "\n",
      "✅ ZHIPUAI    - Zhipu AI GLM - Optimized for Chinese researchers\n",
      "   Default: glm-4\n",
      "   Fast: glm-4-flash\n",
      "\n",
      "🎯 Recommended: DASHSCOPE\n",
      "\n",
      "✅ Research LLM created successfully!\n",
      "🧪 Test response: Research agents ready\n",
      "\n",
      "📊 LLM Status: ✅ Ready\n"
     ]
    }
   ],
   "source": [
    "# Set up LLM for our agents (from Part 1)\n",
    "from llm_providers import create_research_llm, list_research_providers\n",
    "\n",
    "print(\"🤖 SETTING UP LLM FOR AGENTS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check available providers\n",
    "list_research_providers()\n",
    "\n",
    "try:\n",
    "    # Create research LLM\n",
    "    research_llm = create_research_llm(\n",
    "        temperature=0.7,  # Balanced creativity and consistency\n",
    "        fast_mode=False   # Use high-quality model\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Research LLM created successfully!\")\n",
    "    \n",
    "    # Test the LLM\n",
    "    test_response = research_llm.invoke(\"Hello! Please respond with 'Research agents ready'\")\n",
    "    print(f\"🧪 Test response: {test_response.content}\")\n",
    "    \n",
    "    llm_available = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ LLM setup failed: {e}\")\n",
    "    print(\"💡 Will use limited functionality without LLM\")\n",
    "    research_llm = None\n",
    "    llm_available = False\n",
    "\n",
    "print(f\"\\n📊 LLM Status: {'✅ Ready' if llm_available else '❌ Not Available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "create-literature-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 CREATING LITERATURE SEARCH AGENT\n",
      "===================================\n",
      "📚 LITERATURE SEARCH AGENT DEMONSTRATION\n",
      "=============================================\n",
      "\n",
      "🎯 Agent Capabilities:\n",
      "   • Multi-source literature search (ArXiv + Semantic Scholar)\n",
      "   • Query expansion and optimization\n",
      "   • Advanced paper ranking and filtering\n",
      "   • Key insight extraction using LLM analysis\n",
      "   • Trend identification and author network analysis\n",
      "   • Automated literature review section generation\n",
      "\n",
      "📊 Search Features:\n",
      "   • Recent paper filtering (last 5 years)\n",
      "   • Citation-based quality filtering\n",
      "   • Multi-criteria ranking (relevance, recency, citations)\n",
      "   • Venue quality assessment\n",
      "   • Duplicate detection and removal\n",
      "\n",
      "🔍 Usage Examples:\n",
      "   • agent.search_literature(\"transformer attention mechanisms\")\n",
      "   • agent.generate_literature_review_section(results, \"trends\")\n",
      "   • agent.get_author_collaboration_network(papers)\n",
      "\n",
      "✅ Literature Search Agent created!\n",
      "   Max papers per query: 50\n",
      "   Quality filters: 5 criteria\n",
      "   Query expansions: 5 domains\n"
     ]
    }
   ],
   "source": [
    "# Create and test literature search agent\n",
    "research_tools = arxiv_client\n",
    "if llm_available:\n",
    "    from literature_agent import LiteratureSearchAgent, demonstrate_literature_agent\n",
    "    \n",
    "    print(\"📚 CREATING LITERATURE SEARCH AGENT\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Show agent capabilities\n",
    "    demonstrate_literature_agent()\n",
    "    \n",
    "    # Create the agent\n",
    "    literature_agent = LiteratureSearchAgent(\n",
    "        llm=research_llm,\n",
    "        research_tools=research_tools\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Literature Search Agent created!\")\n",
    "    print(f\"   Max papers per query: {literature_agent.max_papers_per_query}\")\n",
    "    print(f\"   Quality filters: {len(literature_agent.quality_metrics)} criteria\")\n",
    "    print(f\"   Query expansions: {len(literature_agent.query_expansion_terms)} domains\")\n",
    "    \n",
    "else:\n",
    "    print(\"⏭️ Skipping literature agent (no LLM available)\")\n",
    "    literature_agent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-literature-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 TESTING LITERATURE SEARCH\n",
      "============================\n",
      "Research Query: 'neural operator'\n",
      "📚 Starting literature search for: 'neural operator'\n",
      "❌ Search failed: 'ArXivClient' object has no attribute 'get_comprehensive_results'\n",
      "\n",
      "📊 SEARCH RESULTS:\n",
      "Papers found: 0\n",
      "Papers returned: 0\n",
      "Search time: 0.0s\n",
      "Key insights: 0\n",
      "Trending topics: 0\n",
      "\n",
      "📊 Literature Search Status: ✅ Working\n"
     ]
    }
   ],
   "source": [
    "# Test literature search functionality\n",
    "if llm_available and literature_agent:\n",
    "    print(\"🔍 TESTING LITERATURE SEARCH\")\n",
    "    print(\"=\" * 28)\n",
    "    \n",
    "    # Conduct a literature search\n",
    "    research_query = \"neural operator\"\n",
    "    print(f\"Research Query: '{research_query}'\")\n",
    "    \n",
    "    try:\n",
    "        # Perform literature search\n",
    "        search_result = literature_agent.search_literature(\n",
    "            query=research_query,\n",
    "            max_results=10,\n",
    "            include_recent_only=True,\n",
    "            expand_query=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n📊 SEARCH RESULTS:\")\n",
    "        print(f\"Papers found: {search_result.total_found}\")\n",
    "        print(f\"Papers returned: {len(search_result.papers)}\")\n",
    "        print(f\"Search time: {search_result.search_time:.1f}s\")\n",
    "        print(f\"Key insights: {len(search_result.key_insights)}\")\n",
    "        print(f\"Trending topics: {len(search_result.trending_topics)}\")\n",
    "        \n",
    "        # Show sample results\n",
    "        if search_result.papers:\n",
    "            print(\"\\n📄 Top Papers:\")\n",
    "            for i, paper in enumerate(search_result.papers[:3], 1):\n",
    "                print(f\"\\n{i}. {paper.title}\")\n",
    "                print(f\"   Authors: {', '.join(paper.authors[:2])}\")\n",
    "                print(f\"   Year: {paper.publication_date[:4]}\")\n",
    "                print(f\"   Citations: {paper.citation_count}\")\n",
    "                print(f\"   Confidence: {paper.confidence_score:.2f}\")\n",
    "        \n",
    "        # Show insights if available\n",
    "        if search_result.key_insights:\n",
    "            print(\"\\n💡 Key Insights:\")\n",
    "            for insight in search_result.key_insights[:3]:\n",
    "                print(f\"   • {insight}\")\n",
    "        \n",
    "        # Show trends\n",
    "        if search_result.trending_topics:\n",
    "            print(\"\\n📈 Trending Topics:\")\n",
    "            for topic in search_result.trending_topics[:5]:\n",
    "                print(f\"   • {topic}\")\n",
    "        \n",
    "        literature_search_success = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Literature search failed: {e}\")\n",
    "        literature_search_success = False\n",
    "        search_result = None\n",
    "\n",
    "else:\n",
    "    print(\"⏭️ Skipping literature search test (no LLM/agent available)\")\n",
    "    literature_search_success = False\n",
    "    search_result = None\n",
    "\n",
    "print(f\"\\n📊 Literature Search Status: {'✅ Working' if literature_search_success else '❌ Limited'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-header",
   "metadata": {},
   "source": [
    "# Section 3: Citation & Summary Agents (45 min)\n",
    "\n",
    "`★ Insight ─────────────────────────────────────`\n",
    "Academic writing requires precise citation formatting that varies by field and journal. Rather than manually formatting each citation, specialized agents can handle the complexity of different styles (IEEE, APA, MLA) while ensuring consistency across your entire paper.\n",
    "`─────────────────────────────────────────────────`\n",
    "\n",
    "Let's create agents for citation formatting and content summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "create-citation-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📖 CREATING CITATION FORMATTING AGENT\n",
      "====================================\n",
      "📖 CITATION FORMATTING AGENT DEMONSTRATION\n",
      "=============================================\n",
      "\\n🎯 Supported Citation Styles:\n",
      "   • IEEE: Numbered citations [1], common in engineering and CS\n",
      "   • APA: Author-year format (Smith, 2023), common in psychology and social sciences\n",
      "   • MLA: Author-page format (Smith 123), common in humanities\n",
      "   • Nature: Numbered format with specific Nature journal requirements\n",
      "   • Chicago: Author-date or notes-bibliography style\n",
      "   • Harvard: Author-year format similar to APA\n",
      "\\n📚 Publication Types:\n",
      "   • Journal articles\n",
      "   • Conference papers\n",
      "   • Books and book chapters\n",
      "   • Theses and dissertations\n",
      "   • Technical reports\n",
      "   • Websites and online sources\n",
      "   • Preprints (arXiv, bioRxiv, etc.)\n",
      "\\n🛠 Features:\n",
      "   • Automatic publication type detection\n",
      "   • Intelligent author name formatting\n",
      "   • DOI and URL handling\n",
      "   • Venue name abbreviation\n",
      "   • Citation completeness validation\n",
      "   • Bibliography generation\n",
      "   • In-text and reference citation formats\n",
      "\n",
      "✅ Citation Formatting Agent created!\n",
      "   Supported styles: 4\n",
      "   Venue abbreviations: 7\n"
     ]
    }
   ],
   "source": [
    "# Create and test citation formatting agent\n",
    "from citation_agent import (\n",
    "    CitationFormatterAgent, \n",
    "    CitationStyle, \n",
    "    CitationData,\n",
    "    demonstrate_citation_agent\n",
    ")\n",
    "\n",
    "print(\"📖 CREATING CITATION FORMATTING AGENT\")\n",
    "print(\"=\" * 36)\n",
    "\n",
    "# Show citation agent capabilities\n",
    "demonstrate_citation_agent()\n",
    "\n",
    "# Create citation agent (works with or without LLM)\n",
    "class MockLLM:\n",
    "    def invoke(self, prompt):\n",
    "        class MockResponse:\n",
    "            content = \"Mock citation formatting response\"\n",
    "        return MockResponse()\n",
    "\n",
    "citation_llm = research_llm if llm_available else MockLLM()\n",
    "citation_agent = CitationFormatterAgent(citation_llm)\n",
    "\n",
    "print(\"\\n✅ Citation Formatting Agent created!\")\n",
    "print(f\"   Supported styles: {len(citation_agent.style_rules)}\")\n",
    "print(f\"   Venue abbreviations: {len(citation_agent.venue_abbreviations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "test-citation-formatting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TESTING CITATION FORMATTING\n",
      "==============================\n",
      "📚 Testing with 3 sample papers\n",
      "\n",
      "📖 IEEE Style:\n",
      "--------------------\n",
      "1. [1] A. Vaswani, N. Shazeer, N. Parmar, et al., \"Attention Is All You Need\", Advances in Neural Information Processing Systems, 2017.\n",
      "2. [2] K. He, X. Zhang, S. Ren, et al., \"Deep Residual Learning for Image Recognition\", Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016.\n",
      "\n",
      "In-text: [4]\n",
      "\n",
      "📖 APA Style:\n",
      "--------------------\n",
      "1. Vaswani, A., Shazeer, N., Parmar, N., & Uszkoreit, J. (2017). Attention Is All You Need. *Advances in Neural Information Processing Systems*.\n",
      "2. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*.\n",
      "\n",
      "In-text: (Vaswani et al., 2017)\n",
      "\n",
      "📖 MLA Style:\n",
      "--------------------\n",
      "1. Vaswani, Ashish, et al. \"Attention Is All You Need.\" *Advances in Neural Information Processing Systems*, 2017.\n",
      "2. He, Kaiming, et al. \"Deep Residual Learning for Image Recognition.\" *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2016.\n",
      "\n",
      "In-text: (Vaswani et al.)\n",
      "\n",
      "✅ Citation formatting test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test citation formatting with sample data\n",
    "print(\"🧪 TESTING CITATION FORMATTING\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Create sample citation data\n",
    "sample_citations = [\n",
    "    CitationData(\n",
    "        title=\"Attention Is All You Need\",\n",
    "        authors=[\"Ashish Vaswani\", \"Noam Shazeer\", \"Niki Parmar\", \"Jakob Uszkoreit\"],\n",
    "        publication_year=\"2017\",\n",
    "        venue=\"Advances in Neural Information Processing Systems\",\n",
    "        pages=\"5998-6008\"\n",
    "    ),\n",
    "    CitationData(\n",
    "        title=\"Deep Residual Learning for Image Recognition\",\n",
    "        authors=[\"Kaiming He\", \"Xiangyu Zhang\", \"Shaoqing Ren\", \"Jian Sun\"],\n",
    "        publication_year=\"2016\",\n",
    "        venue=\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\n",
    "        pages=\"770-778\"\n",
    "    ),\n",
    "    CitationData(\n",
    "        title=\"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "        authors=[\"Jacob Devlin\", \"Ming-Wei Chang\", \"Kenton Lee\", \"Kristina Toutanova\"],\n",
    "        publication_year=\"2019\",\n",
    "        venue=\"North American Chapter of the Association for Computational Linguistics\",\n",
    "        doi=\"10.18653/v1/N19-1423\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"📚 Testing with {len(sample_citations)} sample papers\")\n",
    "\n",
    "# Test different citation styles\n",
    "styles_to_test = [CitationStyle.IEEE, CitationStyle.APA, CitationStyle.MLA]\n",
    "\n",
    "for style in styles_to_test:\n",
    "    print(f\"\\n📖 {style.value.upper()} Style:\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    try:\n",
    "        # Format citations in this style\n",
    "        formatted_citations = citation_agent.format_multiple_citations(\n",
    "            papers=sample_citations,\n",
    "            style=style,\n",
    "            in_text=False\n",
    "        )\n",
    "        \n",
    "        # Show first two citations\n",
    "        for i, citation in enumerate(formatted_citations[:2], 1):\n",
    "            print(f\"{i}. {citation}\")\n",
    "        \n",
    "        # Show in-text citation example\n",
    "        in_text_citation = citation_agent.format_citation(\n",
    "            sample_citations[0], style, in_text=True\n",
    "        )\n",
    "        print(f\"\\nIn-text: {in_text_citation}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error formatting {style.value}: {e}\")\n",
    "\n",
    "print(\"\\n✅ Citation formatting test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "test-bibliography-generation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 TESTING BIBLIOGRAPHY GENERATION\n",
      "=================================\n",
      "📚 IEEE Style Bibliography:\n",
      "===========================\n",
      "# References\\n\\n[1] A. Vaswani, N. Shazeer, N. Parmar, et al., \"Attention Is All You Need\", Advances in Neural Information Processing Systems, 2017.\\n\\n[2] K. He, X. Zhang, S. Ren, et al., \"Deep Residual Learning for Image Recognition\", Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016.\\n\\n[3] J. Devlin, M. Chang, K. Lee, et al., \"BERT: Pre-training of Deep Bidirectional Transformers\", North American Chapter of the Association for Computational Linguistics, 2019...\n",
      "\n",
      "✅ TESTING CITATION VALIDATION\n",
      "==============================\n",
      "Complete: True\n",
      "Quality Score: 0.8\n",
      "Missing Fields: []\n",
      "Suggestions: Add DOI or arXiv ID for better accessibility\n",
      "\n",
      "📊 Citation Agent Status: ✅ Working\n"
     ]
    }
   ],
   "source": [
    "# Test bibliography generation\n",
    "print(\"📋 TESTING BIBLIOGRAPHY GENERATION\")\n",
    "print(\"=\" * 33)\n",
    "\n",
    "# Generate bibliography in IEEE style\n",
    "try:\n",
    "    bibliography = citation_agent.generate_bibliography(\n",
    "        papers=sample_citations,\n",
    "        style=CitationStyle.IEEE,\n",
    "        title=\"References\"\n",
    "    )\n",
    "    \n",
    "    print(\"📚 IEEE Style Bibliography:\")\n",
    "    print(\"=\" * 27)\n",
    "    print(bibliography[:500] + \"...\" if len(bibliography) > 500 else bibliography)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Bibliography generation failed: {e}\")\n",
    "\n",
    "# Test citation validation\n",
    "print(\"\\n✅ TESTING CITATION VALIDATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "validation_result = citation_agent.validate_citation_completeness(sample_citations[0])\n",
    "\n",
    "print(f\"Complete: {validation_result['complete']}\")\n",
    "print(f\"Quality Score: {validation_result['quality_score']:.1f}\")\n",
    "print(f\"Missing Fields: {validation_result['missing_fields']}\")\n",
    "if validation_result['suggestions']:\n",
    "    print(f\"Suggestions: {'; '.join(validation_result['suggestions'])}\")\n",
    "\n",
    "print(\"\\n📊 Citation Agent Status: ✅ Working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-header",
   "metadata": {},
   "source": [
    "# Section 4: Research Router Integration (30 min)\n",
    "\n",
    "`★ Insight ─────────────────────────────────────`\n",
    "The router agent is the conductor of the multi-agent orchestra. It analyzes complex research queries, identifies what tasks need to be done, and coordinates the specialized agents. This architectural pattern scales to any number of specialized agents.\n",
    "`─────────────────────────────────────────────────`\n",
    "\n",
    "Now let's integrate everything into a coordinated multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-research-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the research router agent\n",
    "if llm_available:\n",
    "    from research_router import (\n",
    "        ResearchRouterAgent, \n",
    "        TaskType,\n",
    "        demonstrate_research_router\n",
    "    )\n",
    "    \n",
    "    print(\"🎯 CREATING RESEARCH ROUTER AGENT\")\n",
    "    print(\"=\" * 33)\n",
    "    \n",
    "    # Show router capabilities\n",
    "    demonstrate_research_router()\n",
    "    \n",
    "    # Create the router\n",
    "    research_router = ResearchRouterAgent(\n",
    "        llm=research_llm,\n",
    "        research_tools=research_tools\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Research Router created!\")\n",
    "    print(f\"   Task patterns: {len(research_router.task_patterns)}\")\n",
    "    print(f\"   Citation styles: {len(research_router.style_patterns)}\")\n",
    "    print(f\"   Specialized agents: Literature, Citation\")\n",
    "    \n",
    "    router_available = True\n",
    "    \n",
    "else:\n",
    "    print(\"⏭️ Skipping research router (no LLM available)\")\n",
    "    research_router = None\n",
    "    router_available = False\n",
    "\n",
    "print(f\"\\n📊 Router Status: {'✅ Ready' if router_available else '❌ Not Available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-query-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query analysis and task decomposition\n",
    "if router_available:\n",
    "    print(\"🔍 TESTING QUERY ANALYSIS\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Test different types of research queries\n",
    "    test_queries = [\n",
    "        \"Find recent papers on transformer attention mechanisms\",\n",
    "        \"Search for literature on machine learning in healthcare and format citations in APA style\",\n",
    "        \"Write a literature review on quantum computing applications\",\n",
    "        \"What are the current trends in natural language processing?\",\n",
    "        \"Find top researchers in computer vision and generate a summary\"\n",
    "    ]\n",
    "    \n",
    "    print(\"📋 Analyzing research queries:\")\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n{i}. Query: '{query}'\")\n",
    "        \n",
    "        try:\n",
    "            # Analyze the query\n",
    "            task = research_router.analyze_query(query)\n",
    "            \n",
    "            print(f\"   Task ID: {task.task_id}\")\n",
    "            print(f\"   Identified types: {[t.value for t in task.task_types]}\")\n",
    "            print(f\"   Parameters: {list(task.parameters.keys())}\")\n",
    "            print(f\"   Estimated time: {task.estimated_time:.1f}s\")\n",
    "            \n",
    "            # Show key parameters\n",
    "            if 'citation_style' in task.parameters:\n",
    "                print(f\"   Citation style: {task.parameters['citation_style'].value}\")\n",
    "            if 'max_papers' in task.parameters:\n",
    "                print(f\"   Max papers: {task.parameters['max_papers']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Analysis failed: {e}\")\n",
    "    \n",
    "    print(\"\\n✅ Query analysis test completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"⏭️ Skipping query analysis test (no router available)\")\n",
    "    print(\"\\n💡 Expected analysis results:\")\n",
    "    print(\"   • Task type identification from natural language\")\n",
    "    print(\"   • Parameter extraction (citation styles, limits, etc.)\")\n",
    "    print(\"   • Time estimation for complex workflows\")\n",
    "    print(\"   • Intelligent task decomposition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-header",
   "metadata": {},
   "source": [
    "# Section 5: Complete System Demo (15 min)\n",
    "\n",
    "Now let's demonstrate the complete multi-agent research system in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-research-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate complete research workflow\n",
    "if router_available:\n",
    "    print(\"🚀 COMPLETE RESEARCH SYSTEM DEMONSTRATION\")\n",
    "    print(\"=\" * 42)\n",
    "    \n",
    "    # Complex research query that requires multiple agents\n",
    "    research_query = \"Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations\"\n",
    "    \n",
    "    print(f\"Research Query: '{research_query}'\")\n",
    "    print(\"\\n🔄 Executing research session...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Execute complete research session\n",
    "        session = research_router.execute_research_session(research_query)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"📊 RESEARCH SESSION RESULTS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(f\"Session ID: {session.session_id}\")\n",
    "        print(f\"Status: {session.status}\")\n",
    "        print(f\"Tasks executed: {len(session.results)}\")\n",
    "        \n",
    "        # Show task results summary\n",
    "        print(\"\\n📋 Task Results:\")\n",
    "        successful_tasks = 0\n",
    "        total_time = 0\n",
    "        \n",
    "        for result in session.results:\n",
    "            status = \"✅\" if result.success else \"❌\"\n",
    "            print(f\"   {status} {result.task_type.value}: {result.execution_time:.1f}s\")\n",
    "            if result.success:\n",
    "                successful_tasks += 1\n",
    "                print(f\"      Agent: {result.agent_used} (confidence: {result.confidence_score:.1f})\")\n",
    "            else:\n",
    "                print(f\"      Error: {result.error_message[:100]}...\")\n",
    "            total_time += result.execution_time\n",
    "        \n",
    "        print(f\"\\n📊 Summary: {successful_tasks}/{len(session.results)} tasks successful\")\n",
    "        print(f\"⏱️ Total execution time: {total_time:.1f}s\")\n",
    "        \n",
    "        # Show parts of the final report\n",
    "        if session.final_report:\n",
    "            print(\"\\n📄 Final Report Preview:\")\n",
    "            print(\"-\" * 25)\n",
    "            # Show first 800 characters of the report\n",
    "            preview = session.final_report[:800]\n",
    "            if len(session.final_report) > 800:\n",
    "                preview += \"...\\n[Report continues...]\"  \n",
    "            print(preview)\n",
    "        \n",
    "        print(\"\\n🎉 Multi-agent research system demonstration completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Research session failed: {e}\")\n",
    "        print(\"💡 This can happen due to API limitations or network issues\")\n",
    "\n",
    "else:\n",
    "    print(\"⏭️ Skipping complete system demo (router not available)\")\n",
    "    print(\"\\n💡 Complete system would provide:\")\n",
    "    print(\"   • Automatic query analysis and task decomposition\")\n",
    "    print(\"   • Coordinated execution across multiple specialized agents\")\n",
    "    print(\"   • Literature search with quality filtering and ranking\")\n",
    "    print(\"   • Citation formatting in requested academic style\")\n",
    "    print(\"   • Summary generation with key insights\")\n",
    "    print(\"   • Comprehensive session report with all results\")\n",
    "    print(\"   • Error handling and graceful fallback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "system-architecture-header",
   "metadata": {},
   "source": [
    "## 🏗️ System Architecture Analysis\n",
    "\n",
    "Let's analyze what we've built and how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architecture-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🏗️ MULTI-AGENT SYSTEM ARCHITECTURE ANALYSIS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(\"\\n🎯 Architecture Pattern: Router-Based Multi-Agent System\")\n",
    "print(\"\\n📊 Component Status:\")\n",
    "\n",
    "components = [\n",
    "    (\"Research Tools (ArXiv, Semantic Scholar)\", tools_available),\n",
    "    (\"LLM Provider Integration\", llm_available), \n",
    "    (\"Literature Search Agent\", literature_search_success),\n",
    "    (\"Citation Formatting Agent\", True),  # Always works\n",
    "    (\"Research Router Agent\", router_available)\n",
    "]\n",
    "\n",
    "for component, status in components:\n",
    "    status_icon = \"✅\" if status else \"❌\"\n",
    "    print(f\"   {status_icon} {component}\")\n",
    "\n",
    "print(\"\\n🔄 Information Flow:\")\n",
    "flow_steps = [\n",
    "    \"1. User Query → Router Agent (natural language analysis)\",\n",
    "    \"2. Router → Task Decomposition (identify required agents)\",\n",
    "    \"3. Router → Literature Agent (if literature search needed)\",\n",
    "    \"4. Router → Citation Agent (if formatting needed)\", \n",
    "    \"5. Router → Summary Agent (if analysis needed)\",\n",
    "    \"6. Router → Report Generation (combine all results)\"\n",
    "]\n",
    "\n",
    "for step in flow_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\n🎯 Key Design Patterns:\")\n",
    "patterns = [\n",
    "    \"Router Pattern: Central coordinator delegates to specialists\",\n",
    "    \"Agent Specialization: Each agent optimized for specific tasks\",\n",
    "    \"Real API Integration: Connects to actual research databases\",\n",
    "    \"State Management: Structured data flow between agents\",\n",
    "    \"Error Handling: Graceful fallback when components fail\",\n",
    "    \"Session Tracking: Complete audit trail of research process\"\n",
    "]\n",
    "\n",
    "for pattern in patterns:\n",
    "    print(f\"   • {pattern}\")\n",
    "\n",
    "print(\"\\n💡 Benefits Over Single Agent:\")\n",
    "benefits = [\n",
    "    \"Specialized expertise for each type of task\",\n",
    "    \"Parallel processing capability\", \n",
    "    \"Better error isolation and handling\",\n",
    "    \"Easier to extend with new agent types\",\n",
    "    \"Higher quality results through specialization\",\n",
    "    \"More reliable overall system architecture\"\n",
    "]\n",
    "\n",
    "for benefit in benefits:\n",
    "    print(f\"   • {benefit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-applications",
   "metadata": {},
   "source": [
    "## 🎓 Practical Research Applications\n",
    "\n",
    "Here are real-world scenarios where this multi-agent system excels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-applications-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎓 PRACTICAL RESEARCH APPLICATIONS\")\n",
    "print(\"=\" * 34)\n",
    "\n",
    "applications = [\n",
    "    {\n",
    "        \"scenario\": \"PhD Literature Review\",\n",
    "        \"query\": \"Find comprehensive literature on graph neural networks for drug discovery, format in APA style, and generate a 500-word summary\",\n",
    "        \"agents_used\": [\"Literature Search\", \"Citation Formatter\", \"Summary Generator\"],\n",
    "        \"time_saved\": \"8-12 hours → 15 minutes\",\n",
    "        \"benefits\": [\"Comprehensive coverage\", \"Consistent formatting\", \"Key insights extraction\"]\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Grant Proposal Background\",\n",
    "        \"query\": \"Research current trends in quantum machine learning, identify key researchers, and provide IEEE citations for top 20 papers\",\n",
    "        \"agents_used\": [\"Literature Search\", \"Author Analysis\", \"Citation Formatter\"],\n",
    "        \"time_saved\": \"6-8 hours → 10 minutes\",\n",
    "        \"benefits\": [\"Trend identification\", \"Authority establishment\", \"Professional formatting\"]\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Conference Paper Writing\",\n",
    "        \"query\": \"Find recent work on federated learning privacy, generate related work section, format references in conference style\",\n",
    "        \"agents_used\": [\"Literature Search\", \"Review Generator\", \"Citation Formatter\"],\n",
    "        \"time_saved\": \"4-6 hours → 8 minutes\",\n",
    "        \"benefits\": [\"Recent research coverage\", \"Structured writing\", \"Venue-appropriate citations\"]\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Research Proposal Validation\",\n",
    "        \"query\": \"Analyze existing work on multimodal learning for robotics, identify research gaps, suggest future directions\",\n",
    "        \"agents_used\": [\"Literature Search\", \"Trend Analysis\", \"Gap Identifier\"],\n",
    "        \"time_saved\": \"10-15 hours → 20 minutes\", \n",
    "        \"benefits\": [\"Gap identification\", \"Novelty validation\", \"Research direction guidance\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, app in enumerate(applications, 1):\n",
    "    print(f\"\\n📚 Application {i}: {app['scenario']}\")\n",
    "    print(f\"   Query: \\\"{app['query'][:80]}...\\\"\")\n",
    "    print(f\"   Agents: {', '.join(app['agents_used'])}\")\n",
    "    print(f\"   Time Saved: {app['time_saved']}\")\n",
    "    print(f\"   Benefits: {', '.join(app['benefits'])}\")\n",
    "\n",
    "print(\"\\n💼 Integration Tips:\")\n",
    "tips = [\n",
    "    \"Use specific queries for better agent selection\",\n",
    "    \"Specify citation style early in your query\",\n",
    "    \"Combine multiple tasks in single query for efficiency\",\n",
    "    \"Review and refine agent outputs for your specific needs\",\n",
    "    \"Build custom agents for your research domain\",\n",
    "    \"Cache results to avoid repeated API calls\"\n",
    "]\n",
    "\n",
    "for tip in tips:\n",
    "    print(f\"   • {tip}\")\n",
    "\n",
    "print(\"\\n🚀 Next Level: Building Domain-Specific Agents\")\n",
    "print(\"Consider creating specialized agents for your research area:\")\n",
    "print(\"   • Medical Literature Agent (PubMed integration)\")\n",
    "print(\"   • Patent Research Agent (USPTO/Google Patents)\")\n",
    "print(\"   • Dataset Discovery Agent (Papers with Code, Kaggle)\")\n",
    "print(\"   • Code Analysis Agent (GitHub integration)\")\n",
    "print(\"   • Figure Generation Agent (automatic chart creation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-section",
   "metadata": {},
   "source": [
    "# 🏃 Hands-on Exercise\n",
    "\n",
    "**Challenge**: Extend the multi-agent system for your research domain!\n",
    "\n",
    "## Exercise Tasks:\n",
    "\n",
    "1. **Create Domain-Specific Agent**: Build a specialized agent for your field\n",
    "2. **Add New Task Types**: Extend the router to handle new research tasks\n",
    "3. **Integrate New APIs**: Connect to domain-specific databases\n",
    "4. **Test Real Queries**: Use actual research questions from your work\n",
    "\n",
    "## Starter Framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create a custom research agent for your domain\n",
    "\n",
    "# TODO: Define your research domain and specific needs\n",
    "MY_RESEARCH_DOMAIN = \"\"  # e.g., \"biomedical_nlp\", \"quantum_computing\", \"robotics\"\n",
    "MY_RESEARCH_QUERIES = [\n",
    "    # Add your actual research questions here\n",
    "    # Example: \"Find papers on protein folding prediction using transformers\"\n",
    "    # Example: \"Research quantum error correction for NISQ devices\"  \n",
    "    # Example: \"Analyze recent work on autonomous navigation in GPS-denied environments\"\n",
    "]\n",
    "\n",
    "print(\"🔬 YOUR CUSTOM RESEARCH AGENT FRAMEWORK\")\n",
    "print(\"=\" * 38)\n",
    "\n",
    "if MY_RESEARCH_DOMAIN:\n",
    "    print(f\"Research Domain: {MY_RESEARCH_DOMAIN}\")\n",
    "    \n",
    "    if MY_RESEARCH_QUERIES:\n",
    "        print(f\"\\n📋 Your Research Queries ({len(MY_RESEARCH_QUERIES)}):\")\n",
    "        for i, query in enumerate(MY_RESEARCH_QUERIES, 1):\n",
    "            print(f\"   {i}. {query}\")\n",
    "        \n",
    "        # Test with existing system if available\n",
    "        if router_available:\n",
    "            print(\"\\n🧪 Testing with existing router...\")\n",
    "            \n",
    "            for query in MY_RESEARCH_QUERIES[:2]:  # Test first 2\n",
    "                print(f\"\\nQuery: '{query}'\")\n",
    "                try:\n",
    "                    task = research_router.analyze_query(query)\n",
    "                    print(f\"  Detected tasks: {[t.value for t in task.task_types]}\")\n",
    "                    print(f\"  Estimated time: {task.estimated_time:.1f}s\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Analysis error: {e}\")\n",
    "        \n",
    "        print(\"\\n💡 Customization Ideas:\")\n",
    "        customizations = [\n",
    "            f\"Create {MY_RESEARCH_DOMAIN.title()}Agent class\",\n",
    "            \"Add domain-specific API integrations\",\n",
    "            \"Implement specialized ranking algorithms\",\n",
    "            \"Create custom citation styles for your field\",\n",
    "            \"Build domain vocabulary and query expansion\",\n",
    "            \"Add visualization capabilities for your data types\"\n",
    "        ]\n",
    "        \n",
    "        for idea in customizations:\n",
    "            print(f\"   • {idea}\")\n",
    "    else:\n",
    "        print(\"\\n📝 Add your research queries to MY_RESEARCH_QUERIES list above\")\n",
    "else:\n",
    "    print(\"\\n📝 Set your research domain in MY_RESEARCH_DOMAIN above\")\n",
    "    print(\"\\n🎯 Example Domains:\")\n",
    "    example_domains = [\n",
    "        \"biomedical_nlp\", \"quantum_computing\", \"robotics\", \n",
    "        \"climate_science\", \"digital_humanities\", \"materials_science\",\n",
    "        \"cybersecurity\", \"educational_technology\", \"computational_biology\"\n",
    "    ]\n",
    "    \n",
    "    for domain in example_domains:\n",
    "        print(f\"   • {domain}\")\n",
    "\n",
    "print(\"\\n🔧 Implementation Template:\")\n",
    "print(\"\"\"\n",
    "class CustomDomainAgent:\n",
    "    def __init__(self, llm, domain_apis):\n",
    "        self.llm = llm\n",
    "        self.domain_apis = domain_apis\n",
    "        self.domain_vocabulary = self._load_vocabulary()\n",
    "    \n",
    "    def search_domain_literature(self, query):\n",
    "        # Implement domain-specific search logic\n",
    "        pass\n",
    "    \n",
    "    def analyze_domain_trends(self, papers):\n",
    "        # Implement domain-specific analysis\n",
    "        pass\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎓 PART 2 TUTORIAL SUMMARY\")\n",
    "print(\"=\" * 26)\n",
    "\n",
    "print(\"\\n✅ What You've Learned:\")\n",
    "concepts = [\n",
    "    \"Multi-agent architecture with specialized agents\",\n",
    "    \"Router pattern for intelligent task delegation\",\n",
    "    \"Real API integration with academic databases\",\n",
    "    \"Literature search with quality ranking and filtering\", \n",
    "    \"Multi-style citation formatting (IEEE/APA/MLA)\",\n",
    "    \"Session management and comprehensive reporting\"\n",
    "]\n",
    "for i, concept in enumerate(concepts, 1):\n",
    "    print(f\"   {i}. {concept}\")\n",
    "\n",
    "print(\"\\n🛠 What You Can Build Now:\")\n",
    "capabilities = [\n",
    "    \"Intelligent research assistant for literature reviews\",\n",
    "    \"Multi-agent systems for complex research workflows\",\n",
    "    \"Automated citation formatting and bibliography generation\",\n",
    "    \"Domain-specific research agents for your field\",\n",
    "    \"Research trend analysis and insight extraction\",\n",
    "    \"Production-ready academic research tools\"\n",
    "]\n",
    "for i, capability in enumerate(capabilities, 1):\n",
    "    print(f\"   {i}. {capability}\")\n",
    "\n",
    "print(\"\\n📊 System Performance Summary:\")\n",
    "final_status = [\n",
    "    (\"Research Tools Integration\", tools_available),\n",
    "    (\"LLM Multi-Provider Support\", llm_available),\n",
    "    (\"Literature Search Agent\", literature_search_success),\n",
    "    (\"Citation Formatting Agent\", True),\n",
    "    (\"Multi-Agent Router\", router_available)\n",
    "]\n",
    "\n",
    "working_components = sum(1 for _, status in final_status if status)\n",
    "total_components = len(final_status)\n",
    "\n",
    "print(f\"   Working Components: {working_components}/{total_components} ({working_components/total_components:.1%})\")\n",
    "\n",
    "for component, status in final_status:\n",
    "    status_icon = \"✅\" if status else \"❌\"\n",
    "    print(f\"   {status_icon} {component}\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "next_parts = [\n",
    "    \"Part 3: Gemini Research Agent - Advanced web research with reflection loops\",\n",
    "    \"Part 4: DAG Architecture - Complex research pipeline construction\", \n",
    "    \"Part 5: PHM Case Study - Complete production system integration\"\n",
    "]\n",
    "for i, part in enumerate(next_parts, 1):\n",
    "    print(f\"   {i}. {part}\")\n",
    "\n",
    "print(\"\\n🎯 Ready for Part 3? → ../Part3_Gemini_Research_Agent/03_Tutorial.ipynb\")\n",
    "\n",
    "if working_components < total_components:\n",
    "    print(\"\\n💡 Tip: Some components may be limited due to API access or network restrictions.\")\n",
    "    print(\"    The concepts and patterns still apply - configure API keys for full functionality.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
