{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-header",
   "metadata": {},
   "source": [
    "# Part 2: Multi-Agent Router - Research Assistant\n",
    "\n",
    "## ðŸŽ¯ Research Scenario\n",
    "You're writing a research paper and need to conduct a comprehensive literature review, format citations properly, and generate summaries. Instead of doing this manually with different tools, you'll build an intelligent research assistant that coordinates multiple specialized agents.\n",
    "\n",
    "## ðŸŽ“ What You'll Learn\n",
    "\n",
    "1. **Multi-Agent Architecture**: How specialized agents collaborate effectively\n",
    "2. **Router Patterns**: Intelligent task analysis and delegation\n",
    "3. **Real API Integration**: Working with ArXiv, Semantic Scholar, CrossRef\n",
    "4. **Agent Coordination**: Managing complex research workflows\n",
    "\n",
    "## ðŸ“‹ Prerequisites Check\n",
    "- Part 1 completed (LLM provider configured)\n",
    "- Internet connection (for research APIs)\n",
    "- Optional: API keys for enhanced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Multi-Agent Research System Loading...\n",
      "ðŸ“ Working directory: /home/liqi/PHMGA/tutorials_research/Part2_Multi_Agent_Router\n",
      "ðŸ”— Modules path: /home/liqi/PHMGA/tutorials_research/Part2_Multi_Agent_Router/modules\n"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add modules to path\n",
    "current_dir = Path.cwd()\n",
    "modules_dir = current_dir / \"modules\"\n",
    "sys.path.insert(0, str(modules_dir))\n",
    "\n",
    "# Also add Part1 modules (for LLM providers)\n",
    "part1_modules = current_dir.parent / \"Part1_Foundations\" / \"modules\"\n",
    "sys.path.insert(0, str(part1_modules))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(current_dir.parent / \".env\")\n",
    "\n",
    "print(\"ðŸš€ Multi-Agent Research System Loading...\")\n",
    "print(f\"ðŸ“ Working directory: {current_dir}\")\n",
    "print(f\"ðŸ”— Modules path: {modules_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-header",
   "metadata": {},
   "source": [
    "# Section 1: Research Tools Integration (45 min)\n",
    "\n",
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "Real research requires real data sources. By integrating with ArXiv, Semantic Scholar, and CrossRef APIs, we create agents that work with actual academic databases rather than simulated data. This authenticity makes the agents immediately useful for research work.\n",
    "\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "Let's start by setting up our research tools that provide access to academic databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388990e",
   "metadata": {},
   "source": [
    " ### ðŸ”¬ RESEARCH TOOLS DEMONSTRATION\n",
    "===================================\n",
    "\n",
    "ðŸ“š Available Tools:\n",
    "   â€¢ ArXiv Client: Preprint repository search (2M+ papers)\n",
    "   â€¢ Semantic Scholar: Citation analysis and paper metrics\n",
    "   â€¢ CrossRef: DOI resolution and bibliographic data\n",
    "   â€¢ Aggregator: Unified search across all sources\n",
    "\n",
    "ðŸŽ¯ Research Capabilities:\n",
    "   â€¢ Literature search across multiple databases\n",
    "   â€¢ Citation count and influence metrics\n",
    "   â€¢ Author collaboration networks\n",
    "   â€¢ Paper categorization and filtering\n",
    "   â€¢ Full-text and metadata access\n",
    "   â€¢ DOI resolution and validation\n",
    "\n",
    "ðŸ’¡ Usage Examples:\n",
    "   â€¢ arxiv.search_papers(\"transformer attention\", max_results=10)\n",
    "   â€¢ semantic_scholar.search_papers(\"neural networks\", max_results=20)\n",
    "   â€¢ crossref.resolve_doi(\"10.1038/nature12373\")\n",
    "   â€¢ aggregator.get_comprehensive_results(\"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "research-tools-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ RESEARCH TOOLS DEMONSTRATION\n",
      "===================================\n",
      "\n",
      "ðŸ“š Available Tools:\n",
      "   â€¢ ArXiv Client: Preprint repository search (2M+ papers)\n",
      "   â€¢ Semantic Scholar: Citation analysis and paper metrics\n",
      "   â€¢ CrossRef: DOI resolution and bibliographic data\n",
      "   â€¢ Aggregator: Unified search across all sources\n",
      "\n",
      "ðŸŽ¯ Research Capabilities:\n",
      "   â€¢ Literature search across multiple databases\n",
      "   â€¢ Citation count and influence metrics\n",
      "   â€¢ Author collaboration networks\n",
      "   â€¢ Paper categorization and filtering\n",
      "   â€¢ Full-text and metadata access\n",
      "   â€¢ DOI resolution and validation\n",
      "\n",
      "ðŸ’¡ Usage Examples:\n",
      "   â€¢ arxiv.search_papers(\"transformer attention\", max_results=10)\n",
      "   â€¢ semantic_scholar.search_papers(\"neural networks\", max_results=20)\n",
      "   â€¢ crossref.resolve_doi(\"10.1038/nature12373\")\n",
      "   â€¢ aggregator.get_comprehensive_results(\"machine learning\")\n"
     ]
    }
   ],
   "source": [
    "# Import and demonstrate research tools\n",
    "from research_tools import (\n",
    "    ResearchToolsAggregator,\n",
    "    ArXivClient,\n",
    "    SemanticScholarClient,\n",
    "    demonstrate_research_tools\n",
    ")\n",
    "\n",
    "# Show capabilities\n",
    "demonstrate_research_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "test-arxiv-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” TESTING ARXIV INTEGRATION\n",
      "==============================\n",
      "Searching ArXiv for: 'neural operator'\n",
      "âœ… Found 5 papers\n",
      "\n",
      "ðŸ“‹ Sample Results:\n",
      "\n",
      "1. Neural Operator: Learning Maps Between Function Spaces\n",
      "   Authors: Nikola Kovachki, Zongyi Li, Burigede Liu\n",
      "   Date: 2021-08-19\n",
      "   ArXiv ID: 2108.08481v6\n",
      "   Categories: cs.LG, cs.NA, math.NA\n",
      "\n",
      "2. Neural Correction Operator: A Reliable and Fast Approach for Electrical\n",
      "  Impedance Tomography\n",
      "   Authors: Amit Bhat, Ke Chen, Chunmei Wang\n",
      "   Date: 2025-07-25\n",
      "   ArXiv ID: 2507.18875v1\n",
      "   Categories: math.NA, cs.NA\n",
      "\n",
      "3. Resolution-Invariant Image Classification based on Fourier Neural\n",
      "  Operators\n",
      "   Authors: Samira Kabri, Tim Roith, Daniel Tenbrinck\n",
      "   Date: 2023-04-02\n",
      "   ArXiv ID: 2304.01227v1\n",
      "   Categories: cs.CV, cs.LG, cs.NA\n",
      "\n",
      "ðŸ“Š ArXiv Status: âœ… Available\n"
     ]
    }
   ],
   "source": [
    "# Test ArXiv integration (no API key required)\n",
    "print(\"ðŸ” TESTING ARXIV INTEGRATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "arxiv_client = ArXivClient()\n",
    "\n",
    "# Search for papers on a research topic\n",
    "search_query = \"neural operator\"\n",
    "print(f\"Searching ArXiv for: '{search_query}'\")\n",
    "\n",
    "try:\n",
    "    papers = arxiv_client.search_papers(\n",
    "        query=search_query,\n",
    "        max_results=5,  # Limit for demo\n",
    "        sort_by=\"relevance\"\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Found {len(papers)} papers\")\n",
    "    \n",
    "    if papers:\n",
    "        print(\"\\nðŸ“‹ Sample Results:\")\n",
    "        for i, paper in enumerate(papers[:3], 1):\n",
    "            print(f\"\\n{i}. {paper.title}\")\n",
    "            print(f\"   Authors: {', '.join(paper.authors[:3])}\")\n",
    "            print(f\"   Date: {paper.publication_date}\")\n",
    "            print(f\"   ArXiv ID: {paper.arxiv_id}\")\n",
    "            print(f\"   Categories: {', '.join(paper.categories[:3])}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No papers found - this might be due to network issues\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ArXiv search failed: {e}\")\n",
    "    print(\"ðŸ’¡ This is normal if you have network restrictions\")\n",
    "    \n",
    "    # Create some mock data for demonstration\n",
    "    print(\"\\nðŸŽ­ Using mock data for demonstration...\")\n",
    "    from research_tools import ResearchPaper\n",
    "    \n",
    "    papers = [\n",
    "        ResearchPaper(\n",
    "            title=\"Attention Is All You Need\",\n",
    "            authors=[\"Ashish Vaswani\", \"Noam Shazeer\"],\n",
    "            abstract=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...\",\n",
    "            publication_date=\"2017-06-12\",\n",
    "            arxiv_id=\"1706.03762\",\n",
    "            source=\"arxiv\",\n",
    "            citation_count=50000\n",
    "        )\n",
    "    ]\n",
    "    print(f\"ðŸ“„ Mock paper: {papers[0].title}\")\n",
    "\n",
    "arxiv_available = len(papers) > 0\n",
    "print(f\"\\nðŸ“Š ArXiv Status: {'âœ… Available' if arxiv_available else 'âŒ Limited'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-header",
   "metadata": {},
   "source": [
    "# Section 2: Literature Search Agent (45 min)\n",
    "\n",
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "Specialized agents outperform general-purpose agents because they can optimize for specific tasks. A literature search agent can implement \n",
    "\n",
    "- domain-specific ranking, \n",
    "\n",
    "- apply academic quality filters, \n",
    "\n",
    "- and extract research insights that a general agent might miss.\n",
    "\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "\n",
    "Now let's create a specialized agent for literature search and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "setup-llm-for-agents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– SETTING UP LLM FOR AGENTS\n",
      "==============================\n",
      "ðŸ” Available LLM Providers for Research:\n",
      "------------------------------------------------------------\n",
      "âŒ GOOGLE     - Google Gemini - Excellent for mathematical reasoning\n",
      "   Default: gemini-2.5-pro\n",
      "   Fast: gemini-2.5-flash\n",
      "   âš ï¸  Set GEMINI_API_KEY to enable\n",
      "\n",
      "âŒ OPENAI     - OpenAI GPT - Reliable for code understanding\n",
      "   Default: gpt-4o\n",
      "   Fast: gpt-4o-mini\n",
      "   âš ï¸  Set OPENAI_API_KEY to enable\n",
      "\n",
      "âœ… DASHSCOPE  - DashScope Qwen - Cost-effective with good performance\n",
      "   Default: qwen-plus\n",
      "   Fast: qwen-plus\n",
      "\n",
      "âœ… ZHIPUAI    - Zhipu AI GLM - Optimized for Chinese researchers\n",
      "   Default: glm-4\n",
      "   Fast: glm-4-flash\n",
      "\n",
      "ðŸŽ¯ Recommended: DASHSCOPE\n",
      "\n",
      "âœ… Research LLM created successfully!\n",
      "ðŸ§ª Test response: Research agents ready\n",
      "\n",
      "ðŸ“Š LLM Status: âœ… Ready\n"
     ]
    }
   ],
   "source": [
    "# Set up LLM for our agents (from Part 1)\n",
    "from llm_providers import create_research_llm, list_research_providers\n",
    "\n",
    "print(\"ðŸ¤– SETTING UP LLM FOR AGENTS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check available providers\n",
    "list_research_providers()\n",
    "\n",
    "try:\n",
    "    # Create research LLM\n",
    "    research_llm = create_research_llm(\n",
    "        temperature=0.7,  # Balanced creativity and consistency\n",
    "        fast_mode=False   # Use high-quality model\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Research LLM created successfully!\")\n",
    "    \n",
    "    # Test the LLM\n",
    "    test_response = research_llm.invoke(\"Hello! Please respond with 'Research agents ready'\")\n",
    "    print(f\"ðŸ§ª Test response: {test_response.content}\")\n",
    "    \n",
    "    llm_available = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ LLM setup failed: {e}\")\n",
    "    print(\"ðŸ’¡ Will use limited functionality without LLM\")\n",
    "    research_llm = None\n",
    "    llm_available = False\n",
    "\n",
    "print(f\"\\nðŸ“Š LLM Status: {'âœ… Ready' if llm_available else 'âŒ Not Available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "create-literature-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š CREATING LITERATURE SEARCH AGENT\n",
      "===================================\n",
      "ðŸ“š LITERATURE SEARCH AGENT DEMONSTRATION\n",
      "=============================================\n",
      "\n",
      "ðŸŽ¯ Agent Capabilities:\n",
      "   â€¢ Multi-source literature search (ArXiv + Semantic Scholar)\n",
      "   â€¢ Query expansion and optimization\n",
      "   â€¢ Advanced paper ranking and filtering\n",
      "   â€¢ Key insight extraction using LLM analysis\n",
      "   â€¢ Trend identification and author network analysis\n",
      "   â€¢ Automated literature review section generation\n",
      "\n",
      "ðŸ“Š Search Features:\n",
      "   â€¢ Recent paper filtering (last 5 years)\n",
      "   â€¢ Citation-based quality filtering\n",
      "   â€¢ Multi-criteria ranking (relevance, recency, citations)\n",
      "   â€¢ Venue quality assessment\n",
      "   â€¢ Duplicate detection and removal\n",
      "\n",
      "ðŸ” Usage Examples:\n",
      "   â€¢ agent.search_literature(\"transformer attention mechanisms\")\n",
      "   â€¢ agent.generate_literature_review_section(results, \"trends\")\n",
      "   â€¢ agent.get_author_collaboration_network(papers)\n",
      "\n",
      "âœ… Literature Search Agent created!\n",
      "   Max papers per query: 50\n",
      "   Quality filters: 5 criteria\n",
      "   Query expansions: 5 domains\n"
     ]
    }
   ],
   "source": [
    "# Create and test literature search agent\n",
    "research_tools = ResearchToolsAggregator() # arxiv\n",
    "if llm_available:\n",
    "    from literature_agent import LiteratureSearchAgent, demonstrate_literature_agent\n",
    "    \n",
    "    print(\"ðŸ“š CREATING LITERATURE SEARCH AGENT\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Show agent capabilities\n",
    "    demonstrate_literature_agent()\n",
    "    \n",
    "    # Create the agent\n",
    "    literature_agent = LiteratureSearchAgent(\n",
    "        llm=research_llm,\n",
    "        research_tools=research_tools\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Literature Search Agent created!\")\n",
    "    print(f\"   Max papers per query: {literature_agent.max_papers_per_query}\")\n",
    "    print(f\"   Quality filters: {len(literature_agent.quality_metrics)} criteria\")\n",
    "    print(f\"   Query expansions: {len(literature_agent.query_expansion_terms)} domains\")\n",
    "    \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping literature agent (no LLM available)\")\n",
    "    literature_agent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-literature-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” TESTING LITERATURE SEARCH\n",
      "============================\n",
      "Research Query: 'neural operator'\n",
      "ðŸ“š Starting literature search for: 'neural operator'\n",
      "ðŸ” Searching ArXiv for: neural operator\n",
      "   Found 10 papers from all sources\n",
      "   Selected top 10 papers\n",
      "âœ… Literature search completed in 23.6s\n",
      "\n",
      "ðŸ“Š SEARCH RESULTS:\n",
      "Papers found: 10\n",
      "Papers returned: 10\n",
      "Search time: 23.6s\n",
      "Key insights: 2818\n",
      "Trending topics: 3\n",
      "\n",
      "ðŸ“„ Top Papers:\n",
      "\n",
      "1. Residual-Based Error Corrector Operator to Enhance Accuracy and\n",
      "  Reliability of Neural Operator Surrogates of Nonlinear Variational\n",
      "  Boundary-Value Problems\n",
      "   Authors: Prashant K. Jha\n",
      "   Year: 2023\n",
      "   Citations: 0\n",
      "   Confidence: 0.21\n",
      "\n",
      "2. MODNO: Multi Operator Learning With Distributed Neural Operators\n",
      "   Authors: Zecheng Zhang\n",
      "   Year: 2024\n",
      "   Citations: 0\n",
      "   Confidence: 0.21\n",
      "\n",
      "3. Representation Equivalent Neural Operators: a Framework for Alias-free\n",
      "  Operator Learning\n",
      "   Authors: Francesca Bartolucci, Emmanuel de BÃ©zenac\n",
      "   Year: 2023\n",
      "   Citations: 0\n",
      "   Confidence: 0.21\n",
      "\n",
      "ðŸ’¡ Key Insights:\n",
      "   â€¢ #\n",
      "   â€¢ #\n",
      "   â€¢ #\n",
      "\n",
      "ðŸ“ˆ Trending Topics:\n",
      "   â€¢ Cs.Lg (9 papers)\n",
      "   â€¢ Math.Na (5 papers)\n",
      "   â€¢ Cs.Na (5 papers)\n",
      "\n",
      "ðŸ“Š Literature Search Status: âœ… Working\n"
     ]
    }
   ],
   "source": [
    "# Test literature search functionality\n",
    "if llm_available and literature_agent:\n",
    "    print(\"ðŸ” TESTING LITERATURE SEARCH\")\n",
    "    print(\"=\" * 28)\n",
    "    \n",
    "    # Conduct a literature search\n",
    "    research_query = \"neural operator\"\n",
    "    print(f\"Research Query: '{research_query}'\")\n",
    "    \n",
    "    try:\n",
    "        # Perform literature search\n",
    "        search_result = literature_agent.search_literature(\n",
    "            query=research_query,\n",
    "            max_results=10,\n",
    "            include_recent_only=True,\n",
    "            expand_query=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nðŸ“Š SEARCH RESULTS:\")\n",
    "        print(f\"Papers found: {search_result.total_found}\")\n",
    "        print(f\"Papers returned: {len(search_result.papers)}\")\n",
    "        print(f\"Search time: {search_result.search_time:.1f}s\")\n",
    "        print(f\"Key insights: {len(search_result.key_insights)}\")\n",
    "        print(f\"Trending topics: {len(search_result.trending_topics)}\")\n",
    "        \n",
    "        # Show sample results\n",
    "        if search_result.papers:\n",
    "            print(\"\\nðŸ“„ Top Papers:\")\n",
    "            for i, paper in enumerate(search_result.papers[:3], 1):\n",
    "                print(f\"\\n{i}. {paper.title}\")\n",
    "                print(f\"   Authors: {', '.join(paper.authors[:2])}\")\n",
    "                print(f\"   Year: {paper.publication_date[:4]}\")\n",
    "                print(f\"   Citations: {paper.citation_count}\")\n",
    "                print(f\"   Confidence: {paper.confidence_score:.2f}\")\n",
    "        \n",
    "        # Show insights if available\n",
    "        if search_result.key_insights:\n",
    "            print(\"\\nðŸ’¡ Key Insights:\")\n",
    "            for insight in search_result.key_insights: # [:3]\n",
    "                print(f\"   â€¢ {insight}\")\n",
    "        \n",
    "        # Show trends\n",
    "        if search_result.trending_topics:\n",
    "            print(\"\\nðŸ“ˆ Trending Topics:\")\n",
    "            for topic in search_result.trending_topics[:5]:\n",
    "                print(f\"   â€¢ {topic}\")\n",
    "        \n",
    "        literature_search_success = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Literature search failed: {e}\")\n",
    "        literature_search_success = False\n",
    "        search_result = None\n",
    "\n",
    "else:\n",
    "    print(\"â­ï¸ Skipping literature search test (no LLM/agent available)\")\n",
    "    literature_search_success = False\n",
    "    search_result = None\n",
    "\n",
    "print(f\"\\nðŸ“Š Literature Search Status: {'âœ… Working' if literature_search_success else 'âŒ Limited'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86c4a329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. Main Research Trends and Directions  \n",
      "- **Operator learning** is a growing field focused on training neural networks to approximate mappings between **infinite-dimensional function spaces**, particularly for solving **parametric PDEs** and other scientific computing tasks.  \n",
      "- There is a shift from **single-operator learning (SOL)** to **multi-operator learning**, aiming to generalize foundation models across multiple operators and tasks.  \n",
      "- Increasing emphasis on **discretization-invariant models**, such as **Fourier Neural Operators (FNOs)**, to improve generalization across resolutions and grid structures.  \n",
      "\n",
      "---\n",
      "\n",
      "### 2. Most Influential Authors and Institutions  \n",
      "- **Zongyi Li**, **Nikola Kovachki**, and **George Em Karniadakis** are frequently associated with foundational neural operator work.  \n",
      "- Research groups at **Caltech**, **Brown University**, and **MIT** are prominent in advancing neural operator theory and applications in scientific machine learning.  \n",
      "- Emerging contributors like **Prashant K. Jha**, **Amit Bhat**, and **Pengzhan Jin** are exploring error correction, multi-input operators, and reliability improvements.  \n",
      "\n",
      "---\n",
      "\n",
      "### 3. Emerging Methodologies or Approaches  \n",
      "- **Fourier Neural Operators (FNOs)** are gaining traction due to their ability to model global dependencies and maintain performance across resolutions.  \n",
      "- **Residual-based error correctors** and **neural correction operators** are being introduced to enhance accuracy and reliability of surrogate models in ill-posed problems like EIT.  \n",
      "- **Operational Neural Networks (ONNs)** and **Steklov Neural Networks** offer alternative architectures that generalize convolution and integral-based transformations for structured data.  \n",
      "\n",
      "---\n",
      "\n",
      "### 4. Gaps or Future Research Opportunities  \n",
      "- **Theoretical understanding of convergence and generalization** in neural operators remains underexplored, especially in relation to Neural Tangent Kernels (NTK).  \n",
      "- There is a need for **benchmarking frameworks and standardized datasets** to compare different neural operator architectures fairly.  \n",
      "- **Integration with physics constraints** and uncertainty quantification is a promising area for improving robustness in real-world applications.  \n",
      "\n",
      "---\n",
      "\n",
      "### 5. Practical Applications and Impact  \n",
      "- Neural operators are being applied to **nonlinear PDEs**, **medical imaging (EIT)**, and **image classification**, offering faster and more flexible surrogates than classical solvers.  \n",
      "- They enable **real-time simulations and inverse problems**, such as reconstructing conductivity fields or predicting fluid dynamics, with potential in engineering and healthcare.  \n",
      "- Open-source libraries like **FastONN** and growing tooling around FNOs suggest increasing adoption in both **academic and industrial settings**.\n"
     ]
    }
   ],
   "source": [
    "print(search_result.key_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-header",
   "metadata": {},
   "source": [
    "# Section 3: Citation & Summary Agents (45 min)\n",
    "\n",
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "Academic writing requires precise citation formatting that varies by field and journal. Rather than manually formatting each citation, specialized agents can handle the complexity of different styles (IEEE, APA, MLA) while ensuring consistency across your entire paper.\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "Let's create agents for citation formatting and content summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "create-citation-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“– CREATING CITATION FORMATTING AGENT\n",
      "====================================\n",
      "ðŸ“– CITATION FORMATTING AGENT DEMONSTRATION\n",
      "=============================================\n",
      "\\nðŸŽ¯ Supported Citation Styles:\n",
      "   â€¢ IEEE: Numbered citations [1], common in engineering and CS\n",
      "   â€¢ APA: Author-year format (Smith, 2023), common in psychology and social sciences\n",
      "   â€¢ MLA: Author-page format (Smith 123), common in humanities\n",
      "   â€¢ Nature: Numbered format with specific Nature journal requirements\n",
      "   â€¢ Chicago: Author-date or notes-bibliography style\n",
      "   â€¢ Harvard: Author-year format similar to APA\n",
      "\\nðŸ“š Publication Types:\n",
      "   â€¢ Journal articles\n",
      "   â€¢ Conference papers\n",
      "   â€¢ Books and book chapters\n",
      "   â€¢ Theses and dissertations\n",
      "   â€¢ Technical reports\n",
      "   â€¢ Websites and online sources\n",
      "   â€¢ Preprints (arXiv, bioRxiv, etc.)\n",
      "\\nðŸ›  Features:\n",
      "   â€¢ Automatic publication type detection\n",
      "   â€¢ Intelligent author name formatting\n",
      "   â€¢ DOI and URL handling\n",
      "   â€¢ Venue name abbreviation\n",
      "   â€¢ Citation completeness validation\n",
      "   â€¢ Bibliography generation\n",
      "   â€¢ In-text and reference citation formats\n",
      "\n",
      "âœ… Citation Formatting Agent created!\n",
      "   Supported styles: 4\n",
      "   Venue abbreviations: 7\n"
     ]
    }
   ],
   "source": [
    "# Create and test citation formatting agent\n",
    "from citation_agent import (\n",
    "    CitationFormatterAgent, \n",
    "    CitationStyle, \n",
    "    CitationData,\n",
    "    demonstrate_citation_agent\n",
    ")\n",
    "\n",
    "print(\"ðŸ“– CREATING CITATION FORMATTING AGENT\")\n",
    "print(\"=\" * 36)\n",
    "\n",
    "# Show citation agent capabilities\n",
    "demonstrate_citation_agent()\n",
    "\n",
    "# Create citation agent (works with or without LLM)\n",
    "class MockLLM:\n",
    "    def invoke(self, prompt):\n",
    "        class MockResponse:\n",
    "            content = \"Mock citation formatting response\"\n",
    "        return MockResponse()\n",
    "\n",
    "citation_llm = research_llm if llm_available else MockLLM()\n",
    "citation_agent = CitationFormatterAgent(citation_llm)\n",
    "\n",
    "print(\"\\nâœ… Citation Formatting Agent created!\")\n",
    "print(f\"   Supported styles: {len(citation_agent.style_rules)}\")\n",
    "print(f\"   Venue abbreviations: {len(citation_agent.venue_abbreviations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "test-citation-formatting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª TESTING CITATION FORMATTING\n",
      "==============================\n",
      "ðŸ“š Testing with 3 sample papers\n",
      "\n",
      "ðŸ“– IEEE Style:\n",
      "--------------------\n",
      "1. [1] A. Vaswani, N. Shazeer, N. Parmar, et al., \"Attention Is All You Need\", Advances in Neural Information Processing Systems, 2017.\n",
      "2. [2] K. He, X. Zhang, S. Ren, et al., \"Deep Residual Learning for Image Recognition\", Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016.\n",
      "\n",
      "In-text: [4]\n",
      "\n",
      "ðŸ“– APA Style:\n",
      "--------------------\n",
      "1. Vaswani, A., Shazeer, N., Parmar, N., & Uszkoreit, J. (2017). Attention Is All You Need. *Advances in Neural Information Processing Systems*.\n",
      "2. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*.\n",
      "\n",
      "In-text: (Vaswani et al., 2017)\n",
      "\n",
      "ðŸ“– MLA Style:\n",
      "--------------------\n",
      "1. Vaswani, Ashish, et al. \"Attention Is All You Need.\" *Advances in Neural Information Processing Systems*, 2017.\n",
      "2. He, Kaiming, et al. \"Deep Residual Learning for Image Recognition.\" *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*, 2016.\n",
      "\n",
      "In-text: (Vaswani et al.)\n",
      "\n",
      "âœ… Citation formatting test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test citation formatting with sample data\n",
    "print(\"ðŸ§ª TESTING CITATION FORMATTING\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Create sample citation data\n",
    "sample_citations = [\n",
    "    CitationData(\n",
    "        title=\"Attention Is All You Need\",\n",
    "        authors=[\"Ashish Vaswani\", \"Noam Shazeer\", \"Niki Parmar\", \"Jakob Uszkoreit\"],\n",
    "        publication_year=\"2017\",\n",
    "        venue=\"Advances in Neural Information Processing Systems\",\n",
    "        pages=\"5998-6008\"\n",
    "    ),\n",
    "    CitationData(\n",
    "        title=\"Deep Residual Learning for Image Recognition\",\n",
    "        authors=[\"Kaiming He\", \"Xiangyu Zhang\", \"Shaoqing Ren\", \"Jian Sun\"],\n",
    "        publication_year=\"2016\",\n",
    "        venue=\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\n",
    "        pages=\"770-778\"\n",
    "    ),\n",
    "    CitationData(\n",
    "        title=\"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "        authors=[\"Jacob Devlin\", \"Ming-Wei Chang\", \"Kenton Lee\", \"Kristina Toutanova\"],\n",
    "        publication_year=\"2019\",\n",
    "        venue=\"North American Chapter of the Association for Computational Linguistics\",\n",
    "        doi=\"10.18653/v1/N19-1423\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"ðŸ“š Testing with {len(sample_citations)} sample papers\")\n",
    "\n",
    "# Test different citation styles\n",
    "styles_to_test = [CitationStyle.IEEE, CitationStyle.APA, CitationStyle.MLA]\n",
    "\n",
    "for style in styles_to_test:\n",
    "    print(f\"\\nðŸ“– {style.value.upper()} Style:\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    try:\n",
    "        # Format citations in this style\n",
    "        formatted_citations = citation_agent.format_multiple_citations(\n",
    "            papers=sample_citations,\n",
    "            style=style,\n",
    "            in_text=False\n",
    "        )\n",
    "        \n",
    "        # Show first two citations\n",
    "        for i, citation in enumerate(formatted_citations[:2], 1):\n",
    "            print(f\"{i}. {citation}\")\n",
    "        \n",
    "        # Show in-text citation example\n",
    "        in_text_citation = citation_agent.format_citation(\n",
    "            sample_citations[0], style, in_text=True\n",
    "        )\n",
    "        print(f\"\\nIn-text: {in_text_citation}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error formatting {style.value}: {e}\")\n",
    "\n",
    "print(\"\\nâœ… Citation formatting test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "test-bibliography-generation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ TESTING BIBLIOGRAPHY GENERATION\n",
      "=================================\n",
      "ðŸ“š IEEE Style Bibliography:\n",
      "===========================\n",
      "# References\\n\\n[1] A. Vaswani, N. Shazeer, N. Parmar, et al., \"Attention Is All You Need\", Advances in Neural Information Processing Systems, 2017.\\n\\n[2] K. He, X. Zhang, S. Ren, et al., \"Deep Residual Learning for Image Recognition\", Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016.\\n\\n[3] J. Devlin, M. Chang, K. Lee, et al., \"BERT: Pre-training of Deep Bidirectional Transformers\", North American Chapter of the Association for Computational Linguistics, 2019...\n",
      "\n",
      "âœ… TESTING CITATION VALIDATION\n",
      "==============================\n",
      "Complete: True\n",
      "Quality Score: 0.8\n",
      "Missing Fields: []\n",
      "Suggestions: Add DOI or arXiv ID for better accessibility\n",
      "\n",
      "ðŸ“Š Citation Agent Status: âœ… Working\n"
     ]
    }
   ],
   "source": [
    "# Test bibliography generation\n",
    "print(\"ðŸ“‹ TESTING BIBLIOGRAPHY GENERATION\")\n",
    "print(\"=\" * 33)\n",
    "\n",
    "# Generate bibliography in IEEE style\n",
    "try:\n",
    "    bibliography = citation_agent.generate_bibliography(\n",
    "        papers=sample_citations,\n",
    "        style=CitationStyle.IEEE,\n",
    "        title=\"References\"\n",
    "    )\n",
    "    \n",
    "    print(\"ðŸ“š IEEE Style Bibliography:\")\n",
    "    print(\"=\" * 27)\n",
    "    print(bibliography[:500] + \"...\" if len(bibliography) > 500 else bibliography)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Bibliography generation failed: {e}\")\n",
    "\n",
    "# Test citation validation\n",
    "print(\"\\nâœ… TESTING CITATION VALIDATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "validation_result = citation_agent.validate_citation_completeness(sample_citations[0])\n",
    "\n",
    "print(f\"Complete: {validation_result['complete']}\")\n",
    "print(f\"Quality Score: {validation_result['quality_score']:.1f}\")\n",
    "print(f\"Missing Fields: {validation_result['missing_fields']}\")\n",
    "if validation_result['suggestions']:\n",
    "    print(f\"Suggestions: {'; '.join(validation_result['suggestions'])}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Citation Agent Status: âœ… Working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-header",
   "metadata": {},
   "source": [
    "# Section 4: Research Router Integration (30 min)\n",
    "\n",
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "The router agent is the conductor of the multi-agent orchestra. It analyzes complex research queries, identifies what tasks need to be done, and coordinates the specialized agents. This architectural pattern scales to any number of specialized agents.\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "\n",
    "Now let's integrate everything into a coordinated multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "create-research-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ CREATING RESEARCH ROUTER AGENT\n",
      "=================================\n",
      "ðŸŽ¯ RESEARCH ROUTER AGENT DEMONSTRATION\n",
      "==========================================\n",
      "\\nðŸ”„ Router Capabilities:\n",
      "   â€¢ Query analysis and task decomposition\n",
      "   â€¢ Intelligent agent selection and delegation\n",
      "   â€¢ Multi-task workflow orchestration\n",
      "   â€¢ Session management and result tracking\n",
      "   â€¢ Comprehensive report generation\n",
      "   â€¢ Error handling and fallback strategies\n",
      "\\nðŸ“‹ Supported Task Types:\n",
      "   â€¢ Literature Search: Find and analyze relevant research papers\n",
      "   â€¢ Citation Formatting: Format citations in academic styles\n",
      "   â€¢ Summary Generation: Create research area overviews\n",
      "   â€¢ Trend Analysis: Identify emerging research directions\n",
      "   â€¢ Review Generation: Write literature review sections\n",
      "   â€¢ Author Analysis: Analyze researcher networks and influence\n",
      "\\nðŸ¤– Agent Coordination:\n",
      "   â€¢ Automatic task type detection from natural language\n",
      "   â€¢ Parameter extraction and optimization\n",
      "   â€¢ Sequential and parallel task execution\n",
      "   â€¢ Result aggregation and synthesis\n",
      "   â€¢ Quality assessment and validation\n",
      "\\nðŸ’¡ Example Queries:\n",
      "   â€¢ \"Find recent papers on transformer attention mechanisms and format citations in IEEE style\"\n",
      "   â€¢ \"Write a literature review on machine learning in healthcare\"\n",
      "   â€¢ \"What are the current trends in quantum computing research?\"\n",
      "   â€¢ \"Analyze collaboration networks in natural language processing\"\n",
      "\n",
      "âœ… Research Router created!\n",
      "   Task patterns: 6\n",
      "   Citation styles: 4\n",
      "   Specialized agents: Literature, Citation\n",
      "\n",
      "ðŸ“Š Router Status: âœ… Ready\n"
     ]
    }
   ],
   "source": [
    "# Create the research router agent\n",
    "if llm_available:\n",
    "    from research_router import (\n",
    "        ResearchRouterAgent, \n",
    "        TaskType,\n",
    "        demonstrate_research_router\n",
    "    )\n",
    "    \n",
    "    print(\"ðŸŽ¯ CREATING RESEARCH ROUTER AGENT\")\n",
    "    print(\"=\" * 33)\n",
    "    \n",
    "    # Show router capabilities\n",
    "    demonstrate_research_router()\n",
    "    \n",
    "    # Create the router\n",
    "    research_router = ResearchRouterAgent(\n",
    "        llm=research_llm,\n",
    "        research_tools=research_tools\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Research Router created!\")\n",
    "    print(f\"   Task patterns: {len(research_router.task_patterns)}\")\n",
    "    print(f\"   Citation styles: {len(research_router.style_patterns)}\")\n",
    "    print(f\"   Specialized agents: Literature, Citation\")\n",
    "    \n",
    "    router_available = True\n",
    "    \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping research router (no LLM available)\")\n",
    "    research_router = None\n",
    "    router_available = False\n",
    "\n",
    "print(f\"\\nðŸ“Š Router Status: {'âœ… Ready' if router_available else 'âŒ Not Available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "test-query-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” TESTING QUERY ANALYSIS\n",
      "=========================\n",
      "ðŸ“‹ Analyzing research queries:\n",
      "\n",
      "1. Query: 'Find recent papers on transformer attention mechanisms'\n",
      "   Task ID: task_1_105402\n",
      "   Identified types: ['literature_search']\n",
      "   Parameters: ['max_papers', 'topic']\n",
      "   Estimated time: 30.0s\n",
      "   Max papers: 20\n",
      "\n",
      "2. Query: 'Search for literature on machine learning in healthcare and format citations in APA style'\n",
      "   Task ID: task_2_105402\n",
      "   Identified types: ['literature_search', 'citation_format']\n",
      "   Parameters: ['citation_style', 'max_papers', 'topic']\n",
      "   Estimated time: 35.0s\n",
      "   Citation style: apa\n",
      "   Max papers: 20\n",
      "\n",
      "3. Query: 'Write a literature review on quantum computing applications'\n",
      "   Task ID: task_3_105402\n",
      "   Identified types: ['literature_search', 'review_generation']\n",
      "   Parameters: ['max_papers', 'topic']\n",
      "   Estimated time: 75.0s\n",
      "   Max papers: 20\n",
      "\n",
      "4. Query: 'What are the current trends in natural language processing?'\n",
      "   Task ID: task_4_105402\n",
      "   Identified types: ['literature_search']\n",
      "   Parameters: ['max_papers', 'topic']\n",
      "   Estimated time: 30.0s\n",
      "   Max papers: 20\n",
      "\n",
      "5. Query: 'Find top researchers in computer vision and generate a summary'\n",
      "   Task ID: task_5_105402\n",
      "   Identified types: ['literature_search']\n",
      "   Parameters: ['max_papers', 'topic']\n",
      "   Estimated time: 30.0s\n",
      "   Max papers: 20\n",
      "\n",
      "âœ… Query analysis test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test query analysis and task decomposition\n",
    "if router_available:\n",
    "    print(\"ðŸ” TESTING QUERY ANALYSIS\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Test different types of research queries\n",
    "    test_queries = [\n",
    "        \"Find recent papers on transformer attention mechanisms\",\n",
    "        \"Search for literature on machine learning in healthcare and format citations in APA style\",\n",
    "        \"Write a literature review on quantum computing applications\",\n",
    "        \"What are the current trends in natural language processing?\",\n",
    "        \"Find top researchers in computer vision and generate a summary\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ðŸ“‹ Analyzing research queries:\")\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n{i}. Query: '{query}'\")\n",
    "        \n",
    "        try:\n",
    "            # Analyze the query\n",
    "            task = research_router.analyze_query(query)\n",
    "            \n",
    "            print(f\"   Task ID: {task.task_id}\")\n",
    "            print(f\"   Identified types: {[t.value for t in task.task_types]}\")\n",
    "            print(f\"   Parameters: {list(task.parameters.keys())}\")\n",
    "            print(f\"   Estimated time: {task.estimated_time:.1f}s\")\n",
    "            \n",
    "            # Show key parameters\n",
    "            if 'citation_style' in task.parameters:\n",
    "                print(f\"   Citation style: {task.parameters['citation_style'].value}\")\n",
    "            if 'max_papers' in task.parameters:\n",
    "                print(f\"   Max papers: {task.parameters['max_papers']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Analysis failed: {e}\")\n",
    "    \n",
    "    print(\"\\nâœ… Query analysis test completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping query analysis test (no router available)\")\n",
    "    print(\"\\nðŸ’¡ Expected analysis results:\")\n",
    "    print(\"   â€¢ Task type identification from natural language\")\n",
    "    print(\"   â€¢ Parameter extraction (citation styles, limits, etc.)\")\n",
    "    print(\"   â€¢ Time estimation for complex workflows\")\n",
    "    print(\"   â€¢ Intelligent task decomposition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-header",
   "metadata": {},
   "source": [
    "# Section 5: Complete System Demo (15 min)\n",
    "\n",
    "Now let's demonstrate the complete multi-agent research system in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-research-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ COMPLETE RESEARCH SYSTEM DEMONSTRATION\n",
      "==========================================\n",
      "Research Query: 'Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations'\n",
      "\n",
      "ðŸ”„ Executing research session...\n",
      "\n",
      "ðŸš€ Starting research session: session_1\n",
      "Query: 'Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations'\n",
      "ðŸ“‹ Identified task types: ['literature_search']\n",
      "   ðŸ”„ Executing literature_search...\n",
      "ðŸ“š Starting literature search for: 'Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations'\n",
      "   Expanded to: 'Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations OR attention mechanism OR BERT'\n",
      "ðŸ” Searching ArXiv for: Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations OR attention mechanism OR BERT\n",
      "   Found 10 papers from all sources\n",
      "   Selected top 10 papers\n",
      "âœ… Literature search completed in 14.1s\n",
      "âœ… Research session completed: session_1\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š RESEARCH SESSION RESULTS\n",
      "==================================================\n",
      "Session ID: session_1\n",
      "Status: completed\n",
      "Tasks executed: 1\n",
      "\n",
      "ðŸ“‹ Task Results:\n",
      "   âœ… literature_search: 14.1s\n",
      "      Agent: LiteratureSearchAgent (confidence: 0.8)\n",
      "\n",
      "ðŸ“Š Summary: 1/1 tasks successful\n",
      "â±ï¸ Total execution time: 14.1s\n",
      "\n",
      "ðŸ“„ Final Report Preview:\n",
      "-------------------------\n",
      "# Research Session Report\\n\\n**Session ID:** session_1\\n**Query:** Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations\\n**Date:** 2025-08-27\\n**Tasks Completed:** 1\\n\\n## Executive Summary\\n\\nSuccessfully completed 1 of 1 tasks. Total execution time: 14.1 seconds.\\n\\n## Results by Task\\n\\n### Literature Search\\n\\n**Status:** âœ… Completed successfully\\n**Agent:** LiteratureSearchAgent\\n**Execution Time:** 14.1s\\n**Confidence:** 0.8\\n\\n**Result:**\\nLiterature Search: 'Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations'\\nFound 10 papers in 14.1s\\n\\nTop Papers:\\n1. The Topological BERT: Transforming Attention into Topology for Natural\n",
      "  Language Processing\\n   Authors: Ilan Perez, Raphael Reinauer\\n   Cit...\n",
      "[Report continues...]\n",
      "\n",
      "ðŸŽ‰ Multi-agent research system demonstration completed!\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate complete research workflow\n",
    "if router_available:\n",
    "    print(\"ðŸš€ COMPLETE RESEARCH SYSTEM DEMONSTRATION\")\n",
    "    print(\"=\" * 42)\n",
    "    \n",
    "    # Complex research query that requires multiple agents\n",
    "    research_query = \"Find recent papers on transformer attention mechanisms and provide a summary with IEEE citations\"\n",
    "    \n",
    "    print(f\"Research Query: '{research_query}'\")\n",
    "    print(\"\\nðŸ”„ Executing research session...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Execute complete research session\n",
    "        session = research_router.execute_research_session(research_query)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ðŸ“Š RESEARCH SESSION RESULTS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(f\"Session ID: {session.session_id}\")\n",
    "        print(f\"Status: {session.status}\")\n",
    "        print(f\"Tasks executed: {len(session.results)}\")\n",
    "        \n",
    "        # Show task results summary\n",
    "        print(\"\\nðŸ“‹ Task Results:\")\n",
    "        successful_tasks = 0\n",
    "        total_time = 0\n",
    "        \n",
    "        for result in session.results:\n",
    "            status = \"âœ…\" if result.success else \"âŒ\"\n",
    "            print(f\"   {status} {result.task_type.value}: {result.execution_time:.1f}s\")\n",
    "            if result.success:\n",
    "                successful_tasks += 1\n",
    "                print(f\"      Agent: {result.agent_used} (confidence: {result.confidence_score:.1f})\")\n",
    "            else:\n",
    "                print(f\"      Error: {result.error_message[:100]}...\")\n",
    "            total_time += result.execution_time\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Summary: {successful_tasks}/{len(session.results)} tasks successful\")\n",
    "        print(f\"â±ï¸ Total execution time: {total_time:.1f}s\")\n",
    "        \n",
    "        # Show parts of the final report\n",
    "        if session.final_report:\n",
    "            print(\"\\nðŸ“„ Final Report Preview:\")\n",
    "            print(\"-\" * 25)\n",
    "            # Show first 800 characters of the report\n",
    "            preview = session.final_report[:800]\n",
    "            if len(session.final_report) > 800:\n",
    "                preview += \"...\\n[Report continues...]\"  \n",
    "            print(preview)\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ Multi-agent research system demonstration completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Research session failed: {e}\")\n",
    "        print(\"ðŸ’¡ This can happen due to API limitations or network issues\")\n",
    "\n",
    "else:\n",
    "    print(\"â­ï¸ Skipping complete system demo (router not available)\")\n",
    "    print(\"\\nðŸ’¡ Complete system would provide:\")\n",
    "    print(\"   â€¢ Automatic query analysis and task decomposition\")\n",
    "    print(\"   â€¢ Coordinated execution across multiple specialized agents\")\n",
    "    print(\"   â€¢ Literature search with quality filtering and ranking\")\n",
    "    print(\"   â€¢ Citation formatting in requested academic style\")\n",
    "    print(\"   â€¢ Summary generation with key insights\")\n",
    "    print(\"   â€¢ Comprehensive session report with all results\")\n",
    "    print(\"   â€¢ Error handling and graceful fallback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "system-architecture-header",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ System Architecture Analysis\n",
    "\n",
    "Let's analyze what we've built and how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architecture-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ—ï¸ MULTI-AGENT SYSTEM ARCHITECTURE ANALYSIS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Architecture Pattern: Router-Based Multi-Agent System\")\n",
    "print(\"\\nðŸ“Š Component Status:\")\n",
    "\n",
    "components = [\n",
    "    (\"Research Tools (ArXiv, Semantic Scholar)\", tools_available),\n",
    "    (\"LLM Provider Integration\", llm_available), \n",
    "    (\"Literature Search Agent\", literature_search_success),\n",
    "    (\"Citation Formatting Agent\", True),  # Always works\n",
    "    (\"Research Router Agent\", router_available)\n",
    "]\n",
    "\n",
    "for component, status in components:\n",
    "    status_icon = \"âœ…\" if status else \"âŒ\"\n",
    "    print(f\"   {status_icon} {component}\")\n",
    "\n",
    "print(\"\\nðŸ”„ Information Flow:\")\n",
    "flow_steps = [\n",
    "    \"1. User Query â†’ Router Agent (natural language analysis)\",\n",
    "    \"2. Router â†’ Task Decomposition (identify required agents)\",\n",
    "    \"3. Router â†’ Literature Agent (if literature search needed)\",\n",
    "    \"4. Router â†’ Citation Agent (if formatting needed)\", \n",
    "    \"5. Router â†’ Summary Agent (if analysis needed)\",\n",
    "    \"6. Router â†’ Report Generation (combine all results)\"\n",
    "]\n",
    "\n",
    "for step in flow_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Design Patterns:\")\n",
    "patterns = [\n",
    "    \"Router Pattern: Central coordinator delegates to specialists\",\n",
    "    \"Agent Specialization: Each agent optimized for specific tasks\",\n",
    "    \"Real API Integration: Connects to actual research databases\",\n",
    "    \"State Management: Structured data flow between agents\",\n",
    "    \"Error Handling: Graceful fallback when components fail\",\n",
    "    \"Session Tracking: Complete audit trail of research process\"\n",
    "]\n",
    "\n",
    "for pattern in patterns:\n",
    "    print(f\"   â€¢ {pattern}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Benefits Over Single Agent:\")\n",
    "benefits = [\n",
    "    \"Specialized expertise for each type of task\",\n",
    "    \"Parallel processing capability\", \n",
    "    \"Better error isolation and handling\",\n",
    "    \"Easier to extend with new agent types\",\n",
    "    \"Higher quality results through specialization\",\n",
    "    \"More reliable overall system architecture\"\n",
    "]\n",
    "\n",
    "for benefit in benefits:\n",
    "    print(f\"   â€¢ {benefit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-applications",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Practical Research Applications\n",
    "\n",
    "Here are real-world scenarios where this multi-agent system excels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "practical-applications-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ“ PRACTICAL RESEARCH APPLICATIONS\n",
      "==================================\n",
      "\n",
      "ðŸ“š Application 1: PhD Literature Review\n",
      "   Query: \"Find comprehensive literature on graph neural networks for drug discovery, forma...\"\n",
      "   Agents: Literature Search, Citation Formatter, Summary Generator\n",
      "   Time Saved: 8-12 hours â†’ 15 minutes\n",
      "   Benefits: Comprehensive coverage, Consistent formatting, Key insights extraction\n",
      "\n",
      "ðŸ“š Application 2: Grant Proposal Background\n",
      "   Query: \"Research current trends in quantum machine learning, identify key researchers, a...\"\n",
      "   Agents: Literature Search, Author Analysis, Citation Formatter\n",
      "   Time Saved: 6-8 hours â†’ 10 minutes\n",
      "   Benefits: Trend identification, Authority establishment, Professional formatting\n",
      "\n",
      "ðŸ“š Application 3: Conference Paper Writing\n",
      "   Query: \"Find recent work on federated learning privacy, generate related work section, f...\"\n",
      "   Agents: Literature Search, Review Generator, Citation Formatter\n",
      "   Time Saved: 4-6 hours â†’ 8 minutes\n",
      "   Benefits: Recent research coverage, Structured writing, Venue-appropriate citations\n",
      "\n",
      "ðŸ“š Application 4: Research Proposal Validation\n",
      "   Query: \"Analyze existing work on multimodal learning for robotics, identify research gap...\"\n",
      "   Agents: Literature Search, Trend Analysis, Gap Identifier\n",
      "   Time Saved: 10-15 hours â†’ 20 minutes\n",
      "   Benefits: Gap identification, Novelty validation, Research direction guidance\n",
      "\n",
      "ðŸ’¼ Integration Tips:\n",
      "   â€¢ Use specific queries for better agent selection\n",
      "   â€¢ Specify citation style early in your query\n",
      "   â€¢ Combine multiple tasks in single query for efficiency\n",
      "   â€¢ Review and refine agent outputs for your specific needs\n",
      "   â€¢ Build custom agents for your research domain\n",
      "   â€¢ Cache results to avoid repeated API calls\n",
      "\n",
      "ðŸš€ Next Level: Building Domain-Specific Agents\n",
      "Consider creating specialized agents for your research area:\n",
      "   â€¢ Medical Literature Agent (PubMed integration)\n",
      "   â€¢ Patent Research Agent (USPTO/Google Patents)\n",
      "   â€¢ Dataset Discovery Agent (Papers with Code, Kaggle)\n",
      "   â€¢ Code Analysis Agent (GitHub integration)\n",
      "   â€¢ Figure Generation Agent (automatic chart creation)\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸŽ“ PRACTICAL RESEARCH APPLICATIONS\")\n",
    "print(\"=\" * 34)\n",
    "\n",
    "applications = [\n",
    "    {\n",
    "        \"scenario\": \"PhD Literature Review\",\n",
    "        \"query\": \"Find comprehensive literature on graph neural networks for drug discovery, format in APA style, and generate a 500-word summary\",\n",
    "        \"agents_used\": [\"Literature Search\", \"Citation Formatter\", \"Summary Generator\"],\n",
    "        \"time_saved\": \"8-12 hours â†’ 15 minutes\",\n",
    "        \"benefits\": [\"Comprehensive coverage\", \"Consistent formatting\", \"Key insights extraction\"]\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Grant Proposal Background\",\n",
    "        \"query\": \"Research current trends in quantum machine learning, identify key researchers, and provide IEEE citations for top 20 papers\",\n",
    "        \"agents_used\": [\"Literature Search\", \"Author Analysis\", \"Citation Formatter\"],\n",
    "        \"time_saved\": \"6-8 hours â†’ 10 minutes\",\n",
    "        \"benefits\": [\"Trend identification\", \"Authority establishment\", \"Professional formatting\"]\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Conference Paper Writing\",\n",
    "        \"query\": \"Find recent work on federated learning privacy, generate related work section, format references in conference style\",\n",
    "        \"agents_used\": [\"Literature Search\", \"Review Generator\", \"Citation Formatter\"],\n",
    "        \"time_saved\": \"4-6 hours â†’ 8 minutes\",\n",
    "        \"benefits\": [\"Recent research coverage\", \"Structured writing\", \"Venue-appropriate citations\"]\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Research Proposal Validation\",\n",
    "        \"query\": \"Analyze existing work on multimodal learning for robotics, identify research gaps, suggest future directions\",\n",
    "        \"agents_used\": [\"Literature Search\", \"Trend Analysis\", \"Gap Identifier\"],\n",
    "        \"time_saved\": \"10-15 hours â†’ 20 minutes\", \n",
    "        \"benefits\": [\"Gap identification\", \"Novelty validation\", \"Research direction guidance\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, app in enumerate(applications, 1):\n",
    "    print(f\"\\nðŸ“š Application {i}: {app['scenario']}\")\n",
    "    print(f\"   Query: \\\"{app['query'][:80]}...\\\"\")\n",
    "    print(f\"   Agents: {', '.join(app['agents_used'])}\")\n",
    "    print(f\"   Time Saved: {app['time_saved']}\")\n",
    "    print(f\"   Benefits: {', '.join(app['benefits'])}\")\n",
    "\n",
    "print(\"\\nðŸ’¼ Integration Tips:\")\n",
    "tips = [\n",
    "    \"Use specific queries for better agent selection\",\n",
    "    \"Specify citation style early in your query\",\n",
    "    \"Combine multiple tasks in single query for efficiency\",\n",
    "    \"Review and refine agent outputs for your specific needs\",\n",
    "    \"Build custom agents for your research domain\",\n",
    "    \"Cache results to avoid repeated API calls\"\n",
    "]\n",
    "\n",
    "for tip in tips:\n",
    "    print(f\"   â€¢ {tip}\")\n",
    "\n",
    "print(\"\\nðŸš€ Next Level: Building Domain-Specific Agents\")\n",
    "print(\"Consider creating specialized agents for your research area:\")\n",
    "print(\"   â€¢ Medical Literature Agent (PubMed integration)\")\n",
    "print(\"   â€¢ Patent Research Agent (USPTO/Google Patents)\")\n",
    "print(\"   â€¢ Dataset Discovery Agent (Papers with Code, Kaggle)\")\n",
    "print(\"   â€¢ Code Analysis Agent (GitHub integration)\")\n",
    "print(\"   â€¢ Figure Generation Agent (automatic chart creation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-section",
   "metadata": {},
   "source": [
    "# ðŸƒ Hands-on Exercise\n",
    "\n",
    "**Challenge**: Extend the multi-agent system for your research domain!\n",
    "\n",
    "## Exercise Tasks:\n",
    "\n",
    "1. **Create Domain-Specific Agent**: Build a specialized agent for your field\n",
    "2. **Add New Task Types**: Extend the router to handle new research tasks\n",
    "3. **Integrate New APIs**: Connect to domain-specific databases\n",
    "4. **Test Real Queries**: Use actual research questions from your work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
