{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "# üîß Research Tutorial Environment Setup\n",
    "\n",
    "This notebook helps you set up and verify your environment for the **Research-Oriented PHMGA Tutorial Series**.\n",
    "\n",
    "## üìã What This Notebook Does\n",
    "\n",
    "1. **Verify Dependencies**: Check if all required packages are installed\n",
    "2. **Test LLM Providers**: Validate API keys and connections\n",
    "3. **Check Research Tools**: Verify access to ArXiv, Semantic Scholar, etc.\n",
    "4. **Environment Diagnostics**: Troubleshoot common issues\n",
    "\n",
    "## üöÄ Getting Started\n",
    "\n",
    "**Before running this notebook:**\n",
    "1. Install dependencies: `pip install -r requirements.txt`\n",
    "2. Create `.env` file with your API keys (see template below)\n",
    "3. Run cells sequentially to verify your setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-template",
   "metadata": {},
   "source": [
    "## üìù Environment Variables Template\n",
    "\n",
    "Create a `.env` file in the `tutorials_research/` directory with the following template:\n",
    "\n",
    "```bash\n",
    "# LLM Provider API Keys (you need at least one)\n",
    "GEMINI_API_KEY=your_gemini_api_key_here\n",
    "OPENAI_API_KEY=your_openai_api_key_here  \n",
    "DASHSCOPE_API_KEY=your_dashscope_api_key_here\n",
    "ZHIPUAI_API_KEY=your_zhipuai_api_key_here\n",
    "\n",
    "# Research Tools (optional but recommended)\n",
    "SEMANTIC_SCHOLAR_API_KEY=your_semantic_scholar_key_here\n",
    "CROSSREF_MAILTO=your_email@domain.com\n",
    "\n",
    "# Configuration\n",
    "LLM_PROVIDER=google  # or openai, dashscope, zhipuai\n",
    "LLM_MODEL=gemini-2.5-pro  # or gpt-4o, qwen-plus, glm-4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import and Dependency Check\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üêç Python Version:\", sys.version)\n",
    "print(\"üìÅ Current Directory:\", os.getcwd())\n",
    "print(\"\" + \"=\"*50)\n",
    "\n",
    "# Check critical imports\n",
    "required_packages = [\n",
    "    'langchain',\n",
    "    'langgraph', \n",
    "    'langchain_google_genai',\n",
    "    'langchain_openai',\n",
    "    'langchain_community',\n",
    "    'pydantic',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'matplotlib'\n",
    "]\n",
    "\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úÖ {package}: OK\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package}: MISSING\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n‚ö†Ô∏è Missing packages: {missing_packages}\")\n",
    "    print(\"Run: pip install -r requirements.txt\")\n",
    "else:\n",
    "    print(\"\\nüéâ All required packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Environment Variables Check\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "env_file = Path('.env')\n",
    "if env_file.exists():\n",
    "    load_dotenv(env_file)\n",
    "    print(\"‚úÖ .env file loaded\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No .env file found. Create one using the template above.\")\n",
    "\n",
    "# Check API keys\n",
    "api_keys = {\n",
    "    'Google Gemini': os.getenv('GEMINI_API_KEY'),\n",
    "    'OpenAI': os.getenv('OPENAI_API_KEY'),\n",
    "    'DashScope': os.getenv('DASHSCOPE_API_KEY'),\n",
    "    'Zhipu AI': os.getenv('ZHIPUAI_API_KEY')\n",
    "}\n",
    "\n",
    "available_providers = []\n",
    "print(\"\\nüîë API Key Status:\")\n",
    "for provider, key in api_keys.items():\n",
    "    if key and len(key) > 10:  # Basic key validation\n",
    "        print(f\"‚úÖ {provider}: Available\")\n",
    "        available_providers.append(provider)\n",
    "    else:\n",
    "        print(f\"‚ùå {provider}: Not configured\")\n",
    "\n",
    "if not available_providers:\n",
    "    print(\"\\n‚ö†Ô∏è No API keys configured. You need at least one LLM provider.\")\n",
    "else:\n",
    "    print(f\"\\nüéâ {len(available_providers)} provider(s) available: {', '.join(available_providers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. LLM Provider Connection Test\n",
    "def test_llm_provider(provider_name, create_llm_func):\n",
    "    \"\"\"Test LLM provider connection with a simple query\"\"\"\n",
    "    try:\n",
    "        llm = create_llm_func()\n",
    "        response = llm.invoke(\"Hello! Please respond with 'Connection successful'\")\n",
    "        print(f\"‚úÖ {provider_name}: {response.content[:100]}...\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {provider_name}: {str(e)[:100]}...\")\n",
    "        return False\n",
    "\n",
    "# Test available providers\n",
    "working_providers = []\n",
    "\n",
    "print(\"üß™ Testing LLM Provider Connections:\")\n",
    "\n",
    "# Google Gemini\n",
    "if os.getenv('GEMINI_API_KEY'):\n",
    "    def create_gemini():\n",
    "        from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "        return ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            api_key=os.getenv('GEMINI_API_KEY'),\n",
    "            temperature=0\n",
    "        )\n",
    "    if test_llm_provider(\"Google Gemini\", create_gemini):\n",
    "        working_providers.append(\"gemini\")\n",
    "\n",
    "# OpenAI\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    def create_openai():\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        return ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            api_key=os.getenv('OPENAI_API_KEY'),\n",
    "            temperature=0\n",
    "        )\n",
    "    if test_llm_provider(\"OpenAI\", create_openai):\n",
    "        working_providers.append(\"openai\")\n",
    "\n",
    "# DashScope\n",
    "if os.getenv('DASHSCOPE_API_KEY'):\n",
    "    def create_dashscope():\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        return ChatOpenAI(\n",
    "            model=\"qwen-plus\",\n",
    "            api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "            base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "            temperature=0\n",
    "        )\n",
    "    if test_llm_provider(\"DashScope\", create_dashscope):\n",
    "        working_providers.append(\"dashscope\")\n",
    "\n",
    "print(f\"\\nüéâ Working providers: {working_providers}\")\n",
    "if not working_providers:\n",
    "    print(\"‚ö†Ô∏è No working LLM providers. Check your API keys and internet connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "langgraph-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. LangGraph Basic Test\n",
    "if working_providers:\n",
    "    try:\n",
    "        from langgraph.graph import StateGraph, START, END\n",
    "        from typing_extensions import TypedDict\n",
    "        \n",
    "        print(\"üß™ Testing LangGraph functionality...\")\n",
    "        \n",
    "        # Simple state definition\n",
    "        class SimpleState(TypedDict):\n",
    "            message: str\n",
    "            count: int\n",
    "        \n",
    "        # Simple node function\n",
    "        def simple_node(state: SimpleState):\n",
    "            return {\"message\": \"LangGraph working!\", \"count\": state[\"count\"] + 1}\n",
    "        \n",
    "        # Build simple graph\n",
    "        builder = StateGraph(SimpleState)\n",
    "        builder.add_node(\"simple\", simple_node)\n",
    "        builder.add_edge(START, \"simple\")\n",
    "        builder.add_edge(\"simple\", END)\n",
    "        \n",
    "        graph = builder.compile()\n",
    "        \n",
    "        # Test execution\n",
    "        result = graph.invoke({\"message\": \"test\", \"count\": 0})\n",
    "        print(f\"‚úÖ LangGraph: {result['message']} (count: {result['count']})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LangGraph test failed: {str(e)}\")\nelse:\n",
    "    print(\"‚è≠Ô∏è Skipping LangGraph test (no working LLM providers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "research-tools-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Research Tools Test\n",
    "print(\"üî¨ Testing Research Tools:\")\n",
    "\n",
    "# ArXiv API test\n",
    "try:\n",
    "    import arxiv\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(\n",
    "        query=\"transformer architecture\",\n",
    "        max_results=1,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    paper = next(client.results(search))\n",
    "    print(f\"‚úÖ ArXiv API: Found paper '{paper.title[:50]}...'\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå ArXiv API: {str(e)[:100]}...\")\n",
    "\n",
    "# Web requests test\n",
    "try:\n",
    "    import requests\n",
    "    response = requests.get(\"https://httpbin.org/get\", timeout=10)\n",
    "    print(f\"‚úÖ Web Requests: HTTP {response.status_code}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Web Requests: {str(e)[:100]}...\")\n",
    "\n",
    "# JSON processing test\n",
    "try:\n",
    "    import json\n",
    "    test_data = {\"type\": \"research_tutorial\", \"status\": \"setup_complete\"}\n",
    "    json_str = json.dumps(test_data)\n",
    "    parsed = json.loads(json_str)\n",
    "    print(f\"‚úÖ JSON Processing: {parsed['status']}\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå JSON Processing: {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-readiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Tutorial Readiness Check\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TUTORIAL READINESS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "readiness_score = 0\n",
    "max_score = 5\n",
    "\n",
    "# Check 1: Dependencies\n",
    "if not missing_packages:\n",
    "    print(\"‚úÖ Dependencies: All required packages installed\")\n",
    "    readiness_score += 1\nelse:\n",
    "    print(f\"‚ùå Dependencies: Missing {len(missing_packages)} packages\")\n",
    "\n",
    "# Check 2: API Keys\n",
    "if available_providers:\n",
    "    print(f\"‚úÖ API Keys: {len(available_providers)} provider(s) configured\")\n",
    "    readiness_score += 1\nelse:\n",
    "    print(\"‚ùå API Keys: No providers configured\")\n",
    "\n",
    "# Check 3: LLM Connections\n",
    "if working_providers:\n",
    "    print(f\"‚úÖ LLM Connections: {len(working_providers)} provider(s) working\")\n",
    "    readiness_score += 1\nelse:\n",
    "    print(\"‚ùå LLM Connections: No working providers\")\n",
    "\n",
    "# Check 4: LangGraph\n",
    "try:\n",
    "    from langgraph.graph import StateGraph\n",
    "    print(\"‚úÖ LangGraph: Ready for multi-agent workflows\")\n",
    "    readiness_score += 1\nexcept:\n",
    "    print(\"‚ùå LangGraph: Not properly configured\")\n",
    "\n",
    "# Check 5: Research Tools\n",
    "research_tools_ready = True\ntry:\n",
    "    import arxiv, requests\nexcept:\n",
    "    research_tools_ready = False\n",
    "\n",
    "if research_tools_ready:\n",
    "    print(\"‚úÖ Research Tools: ArXiv and web access ready\")\n",
    "    readiness_score += 1\nelse:\n",
    "    print(\"‚ùå Research Tools: Some tools not available\")\n",
    "\n",
    "# Final assessment\n",
    "percentage = (readiness_score / max_score) * 100\nprint(f\"\\nüéØ Readiness Score: {readiness_score}/{max_score} ({percentage:.0f}%)\")\n",
    "\n",
    "if readiness_score == max_score:\n",
    "    print(\"\\nüéâ EXCELLENT! Your environment is fully ready.\")\n",
    "    print(\"üöÄ You can proceed to Part1_Foundations/01_Tutorial.ipynb\")\nelif readiness_score >= 3:\n",
    "    print(\"\\n‚úÖ GOOD! Your environment is mostly ready.\")\n",
    "    print(\"üîß Address the remaining issues for the best experience.\")\nelse:\n",
    "    print(\"\\n‚ö†Ô∏è NEEDS ATTENTION! Several setup issues detected.\")\n",
    "    print(\"üõ†Ô∏è Please fix the issues above before proceeding.\")\n",
    "\n",
    "# Next steps\n",
    "print(\"\\nüìö RECOMMENDED LEARNING PATH:\")\nprint(\"1. Part1_Foundations - Code to LaTeX Agent (2 hours)\")\nprint(\"2. Part2_Multi_Agent_Router - Research Assistant (3 hours)\")\nprint(\"3. Part3_Gemini_Research_Agent - Web Research (2.5 hours)\")\nprint(\"4. Part4_DAG_Architecture - Research Pipelines (3 hours)\")\nprint(\"5. Part5_PHM_Case_Study - Complete System (4 hours)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "troubleshooting",
   "metadata": {},
   "source": [
    "## üõ† Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### 1. Missing Packages\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "# or update existing packages\n",
    "pip install -r requirements.txt --upgrade\n",
    "```\n",
    "\n",
    "#### 2. API Key Issues\n",
    "- Verify your API keys are correct\n",
    "- Check for extra spaces or quotes in `.env` file\n",
    "- Ensure you have sufficient API quota\n",
    "\n",
    "#### 3. Import Errors\n",
    "```bash\n",
    "# For Google Gemini\n",
    "pip install langchain-google-genai google-generativeai\n",
    "\n",
    "# For OpenAI\n",
    "pip install langchain-openai openai\n",
    "\n",
    "# For DashScope\n",
    "pip install dashscope\n",
    "\n",
    "# For Zhipu AI\n",
    "pip install zhipuai\n",
    "```\n",
    "\n",
    "#### 4. Network Issues\n",
    "- Check your internet connection\n",
    "- Verify you can access external APIs\n",
    "- Consider firewall or proxy settings\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "If you're still having issues:\n",
    "1. Check the individual tutorial README files\n",
    "2. Review the main project documentation\n",
    "3. Create an issue in the repository with your error logs\n",
    "\n",
    "### Ready to Start?\n",
    "\n",
    "If your readiness score is 3 or higher, you're ready to begin!\n",
    "\n",
    "**Next Step**: [Part1_Foundations/01_Tutorial.ipynb](Part1_Foundations/01_Tutorial.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}