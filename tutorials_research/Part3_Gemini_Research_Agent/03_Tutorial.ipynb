{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Gemini Research Agent - Reflection-Based Research Workflows\n",
    "\n",
    "This tutorial demonstrates how to build an **intelligent research agent** that uses **reflection loops** to conduct comprehensive research on academic topics. We'll adapt Google's Gemini research pattern to work with **any LLM provider** from Part 1.\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will understand:\n",
    "1. **Reflection-based research**: How agents can evaluate their own work and iterate\n",
    "2. **Multi-step workflows**: Building complex research pipelines with LangGraph\n",
    "3. **Knowledge gap identification**: Teaching agents to recognize what they don't know\n",
    "4. **Dynamic query generation**: Creating targeted search strategies\n",
    "5. **Research synthesis**: Combining multiple sources into coherent insights\n",
    "\n",
    "## ğŸ“š Academic Research Scenario\n",
    "\n",
    "**Use Case**: You're writing a literature review section for your paper and need to research: *\"What are the recent advances in quantum error correction for fault-tolerant quantum computing?\"*\n",
    "\n",
    "Instead of manually searching and synthesizing papers, we'll build an agent that:\n",
    "- Generates diverse search queries\n",
    "- Conducts parallel web searches\n",
    "- Reflects on research completeness\n",
    "- Identifies knowledge gaps\n",
    "- Iteratively improves research coverage\n",
    "- Synthesizes final comprehensive insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Environment Setup\n",
    "\n",
    "First, let's set up our environment and imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Add paths for our modules\n",
    "sys.path.append('../Part1_Foundations/modules')\n",
    "sys.path.append('modules')\n",
    "\n",
    "# Import our foundational LLM system\n",
    "from llm_providers import create_research_llm, LLMProvider\n",
    "\n",
    "# Import research agent modules\n",
    "from state_schemas import (\n",
    "    ResearchConfiguration, \n",
    "    create_initial_research_state,\n",
    "    OverallResearchState\n",
    ")\n",
    "from query_generator import ResearchQueryGenerator\n",
    "from web_searcher import ResearchWebSearcher\n",
    "from reflection_agent import ResearchReflectionAgent\n",
    "from research_graph import ResearchWorkflowGraph\n",
    "\n",
    "print(\"ğŸ“š Research Agent Tutorial Environment Ready!\")\n",
    "print(f\"ğŸ•’ Session started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Part 3.1: Understanding Reflection in AI Systems\n",
    "\n",
    "**Reflection** is a meta-cognitive process where an AI system evaluates its own reasoning and outputs. In research workflows, this means:\n",
    "\n",
    "1. **Self-Assessment**: \"Is my research complete enough?\"\n",
    "2. **Gap Identification**: \"What important aspects am I missing?\"\n",
    "3. **Strategy Adaptation**: \"How should I search next?\"\n",
    "4. **Quality Control**: \"Are my sources credible and diverse?\"\n",
    "\n",
    "Let's start by creating a configured research system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure our research system\n",
    "research_config = ResearchConfiguration.for_academic_research()\n",
    "print(\"ğŸ”¬ Academic Research Configuration:\")\n",
    "print(f\"   â€¢ Initial queries: {research_config.initial_query_count}\")\n",
    "print(f\"   â€¢ Max research loops: {research_config.max_research_loops}\")\n",
    "print(f\"   â€¢ Minimum sources: {research_config.minimum_sources}\")\n",
    "print(f\"   â€¢ Coverage threshold: {research_config.coverage_threshold}\")\n",
    "print(f\"   â€¢ Academic focus: {research_config.academic_focus}\")\n",
    "\n",
    "# Create LLM instance using Part 1's provider system\n",
    "print(\"\\nğŸ¤– Initializing LLM Provider...\")\n",
    "research_llm = create_research_llm(\n",
    "    provider=LLMProvider.AUTO,  # Auto-select best available\n",
    "    temperature=0.3,  # Lower temperature for research consistency\n",
    ")\n",
    "print(f\"âœ… LLM Provider ready: {research_llm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Part 3.2: Intelligent Query Generation\n",
    "\n",
    "The first step in research is generating **diverse and targeted queries**. Our query generator uses both LLM reasoning and template-based approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize query generator\n",
    "query_generator = ResearchQueryGenerator(research_llm, research_config)\n",
    "\n",
    "# Our research question for this demo\n",
    "research_question = \"What are recent advances in quantum error correction for fault-tolerant quantum computing?\"\n",
    "\n",
    "print(f\"ğŸ” Research Question: {research_question}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Generate initial queries\n",
    "print(\"ğŸ§  Generating research queries...\")\n",
    "query_result = query_generator.generate_initial_queries(research_question)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Generated {len(query_result.queries)} search queries:\")\n",
    "for i, query in enumerate(query_result.queries, 1):\n",
    "    print(f\"   {i}. {query}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Strategy: {query_result.research_strategy}\")\n",
    "print(f\"\\nğŸ“ Rationale: {query_result.rationale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "- **Intelligent Query Diversification**: The system generates queries targeting different aspects (theory, applications, recent work) to ensure comprehensive coverage\n",
    "- **Multi-Modal Generation**: Combines LLM reasoning with template-based approaches for robustness - if LLM fails, templates provide fallback\n",
    "- **Domain-Aware Optimization**: Recognizes quantum computing domain and adapts terminology and focus areas accordingly\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ Part 3.3: Web Search Integration\n",
    "\n",
    "Next, we execute searches using Google Custom Search API. Our system handles parallel execution and result processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize web searcher\n",
    "web_searcher = ResearchWebSearcher(research_config)\n",
    "\n",
    "# Execute searches for our generated queries\n",
    "print(\"ğŸŒ Executing web searches...\")\n",
    "search_start_time = time.time()\n",
    "\n",
    "# Execute searches in parallel for efficiency\n",
    "search_results = []\n",
    "for i, query in enumerate(query_result.queries[:2]):  # Limit for demo\n",
    "    print(f\"   ğŸ” Searching: {query[:50]}...\")\n",
    "    \n",
    "    try:\n",
    "        results = web_searcher.execute_search(query, max_results=3)\n",
    "        search_results.extend(results)\n",
    "        print(f\"     âœ… Found {len(results)} results\")\n",
    "    except Exception as e:\n",
    "        print(f\"     âš ï¸ Search failed: {e}\")\n",
    "        # Add demo results for tutorial purposes\n",
    "        demo_results = web_searcher._create_demo_results(query)\n",
    "        search_results.extend(demo_results)\n",
    "        print(f\"     ğŸ“š Using demo results: {len(demo_results)} sources\")\n",
    "\n",
    "search_time = time.time() - search_start_time\n",
    "print(f\"\\nâ±ï¸ Search completed in {search_time:.2f} seconds\")\n",
    "print(f\"ğŸ“Š Total sources found: {len(search_results)}\")\n",
    "\n",
    "# Display some results\n",
    "print(\"\\nğŸ“š Sample Search Results:\")\n",
    "for i, result in enumerate(search_results[:3], 1):\n",
    "    print(f\"\\n{i}. {result.get('title', 'N/A')}\")\n",
    "    print(f\"   ğŸ”— {result.get('url', 'N/A')}\")\n",
    "    print(f\"   ğŸ“ {result.get('snippet', 'N/A')[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Part 3.4: Reflection and Gap Analysis\n",
    "\n",
    "Now comes the **key innovation**: the reflection agent analyzes our research results and identifies what's missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize reflection agent\n",
    "reflection_agent = ResearchReflectionAgent(research_llm, research_config)\n",
    "\n",
    "# Extract findings from search results\n",
    "findings = []\n",
    "for result in search_results:\n",
    "    if result.get('snippet'):\n",
    "        findings.append(result['snippet'])\n",
    "\n",
    "print(f\"ğŸ” Analyzing {len(findings)} research findings...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Perform reflection analysis\n",
    "reflection_result = reflection_agent.analyze_research_completeness(\n",
    "    original_question=research_question,\n",
    "    current_findings=findings,\n",
    "    current_sources=search_results,\n",
    "    research_iteration=1\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  Reflection Analysis Results:\")\n",
    "print(f\"\\nğŸ“Š Research Sufficient: {'âœ… Yes' if reflection_result.is_sufficient else 'âŒ No'}\")\n",
    "print(f\"ğŸ¯ Confidence Score: {reflection_result.confidence_score:.2f}/1.0\")\n",
    "\n",
    "print(f\"\\nğŸ” Knowledge Gap Identified:\")\n",
    "print(f\"   {reflection_result.knowledge_gap}\")\n",
    "\n",
    "if reflection_result.missing_aspects:\n",
    "    print(f\"\\nğŸ“‹ Missing Aspects ({len(reflection_result.missing_aspects)}):\")\n",
    "    for i, aspect in enumerate(reflection_result.missing_aspects, 1):\n",
    "        print(f\"   {i}. {aspect}\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Follow-up Queries ({len(reflection_result.follow_up_queries)}):\")\n",
    "for i, query in enumerate(reflection_result.follow_up_queries, 1):\n",
    "    print(f\"   {i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "- **Meta-Cognitive Assessment**: The reflection agent acts as a \"research supervisor\" evaluating the quality and completeness of findings\n",
    "- **Gap-Driven Iteration**: Instead of random additional searches, the system identifies specific knowledge gaps and generates targeted follow-up queries\n",
    "- **Confidence Quantification**: Provides measurable confidence scores to guide decision-making about when to stop researching\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Part 3.5: Iterative Research Loops\n",
    "\n",
    "If research is insufficient, we generate **follow-up queries** and conduct additional searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate follow-up query generation\n",
    "if not reflection_result.is_sufficient and reflection_result.follow_up_queries:\n",
    "    print(\"ğŸ”„ Conducting follow-up research...\")\n",
    "    \n",
    "    # Generate additional targeted queries\n",
    "    follow_up_queries = query_generator.generate_follow_up_queries(\n",
    "        original_question=research_question,\n",
    "        current_findings=findings[:5],  # Limit for demo\n",
    "        knowledge_gaps=reflection_result.missing_aspects\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Generated {len(follow_up_queries)} follow-up queries:\")\n",
    "    for i, query in enumerate(follow_up_queries, 1):\n",
    "        print(f\"   {i}. {query}\")\n",
    "    \n",
    "    # Execute one follow-up search (demo)\n",
    "    if follow_up_queries:\n",
    "        print(f\"\\nğŸ” Executing follow-up search: {follow_up_queries[0][:50]}...\")\n",
    "        try:\n",
    "            follow_up_results = web_searcher.execute_search(follow_up_queries[0], max_results=2)\n",
    "            print(f\"   âœ… Found {len(follow_up_results)} additional sources\")\n",
    "            \n",
    "            # Show improvement\n",
    "            total_sources = len(search_results) + len(follow_up_results)\n",
    "            print(f\"\\nğŸ“ˆ Research Progress:\")\n",
    "            print(f\"   Initial sources: {len(search_results)}\")\n",
    "            print(f\"   Follow-up sources: {len(follow_up_results)}\")\n",
    "            print(f\"   Total coverage: {total_sources} sources\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ Follow-up search failed: {e}\")\n",
    "            print(f\"   ğŸ“š In production, this would continue with more iterations\")\n",
    "else:\n",
    "    print(\"âœ… Research appears sufficient - no follow-up needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Part 3.6: Complete Research Workflow with LangGraph\n",
    "\n",
    "Now let's see the **complete research workflow** using LangGraph to orchestrate all components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the complete research workflow graph\n",
    "research_graph = ResearchWorkflowGraph(research_llm, research_config)\n",
    "\n",
    "print(\"ğŸ•¸ï¸ Research Workflow Graph initialized\")\n",
    "print(\"\\nğŸ“‹ Workflow Structure:\")\n",
    "workflow_steps = [\n",
    "    \"1. ğŸ¯ generate_queries: Create diverse search queries\",\n",
    "    \"2. ğŸŒ execute_search: Conduct parallel web searches\", \n",
    "    \"3. ğŸ§  reflect_on_research: Analyze completeness and gaps\",\n",
    "    \"4. ğŸ”„ Decision: Continue research or synthesize results\",\n",
    "    \"5. ğŸ“ synthesize_answer: Generate final comprehensive response\"\n",
    "]\n",
    "\n",
    "for step in workflow_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ Running complete research workflow...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Execute the complete workflow\n",
    "workflow_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Run the research workflow\n",
    "    research_result = research_graph.conduct_research(research_question)\n",
    "    \n",
    "    workflow_time = time.time() - workflow_start_time\n",
    "    \n",
    "    print(f\"\\nâ±ï¸ Complete workflow finished in {workflow_time:.2f} seconds\")\n",
    "    print(f\"\\nğŸ“Š Research Summary:\")\n",
    "    print(f\"   â€¢ Research iterations: {research_result.get('iterations_completed', 'N/A')}\")\n",
    "    print(f\"   â€¢ Total sources: {research_result.get('total_sources_found', 'N/A')}\")\n",
    "    print(f\"   â€¢ Final confidence: {research_result.get('confidence_score', 0):.2f}\")\n",
    "    \n",
    "    # Display final synthesized answer\n",
    "    if 'final_answer' in research_result:\n",
    "        print(f\"\\nğŸ“ Final Research Answer:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(research_result['final_answer'][:500] + \"...\" if len(research_result['final_answer']) > 500 else research_result['final_answer'])\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Workflow execution failed: {e}\")\n",
    "    print(\"\\nğŸ“š In this tutorial environment, some APIs may not be available.\")\n",
    "    print(\"The system includes demo modes for learning purposes.\")\n",
    "    \n",
    "    # Show demo workflow structure instead\n",
    "    print(\"\\nğŸ¯ Demo Workflow Execution:\")\n",
    "    demo_state = create_initial_research_state(research_question, research_config)\n",
    "    print(f\"   âœ… Initial state created: {demo_state['session_id']}\")\n",
    "    print(f\"   âœ… Max loops configured: {demo_state['max_research_loops']}\")\n",
    "    print(f\"   âœ… Ready for {demo_state['initial_search_query_count']} initial queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "- **State-Driven Workflow**: LangGraph manages complex state transitions between research phases, ensuring consistency and recoverability\n",
    "- **Conditional Logic**: The workflow automatically decides whether to continue researching or synthesize based on reflection results\n",
    "- **Scalable Architecture**: This pattern can handle any research complexity by adjusting iteration limits and quality thresholds\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Part 3.7: Comparing Approaches: Manual vs Agent-Based Research\n",
    "\n",
    "Let's compare traditional manual research with our agent-based approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š RESEARCH APPROACH COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_data = {\n",
    "    \"Manual Research\": {\n",
    "        \"Time per topic\": \"2-4 hours\",\n",
    "        \"Query diversity\": \"Limited by researcher bias\",\n",
    "        \"Completeness check\": \"Manual, subjective\",\n",
    "        \"Iteration strategy\": \"Ad-hoc follow-ups\",\n",
    "        \"Scalability\": \"Poor (human bottleneck)\",\n",
    "        \"Consistency\": \"Varies by researcher\",\n",
    "        \"Gap identification\": \"Relies on expertise\"\n",
    "    },\n",
    "    \"Agent-Based Research\": {\n",
    "        \"Time per topic\": \"5-15 minutes\",\n",
    "        \"Query diversity\": \"Multi-perspective, systematic\",\n",
    "        \"Completeness check\": \"Automated with confidence scores\",\n",
    "        \"Iteration strategy\": \"Gap-driven, targeted follow-ups\",\n",
    "        \"Scalability\": \"Excellent (parallel processing)\",\n",
    "        \"Consistency\": \"Reproducible methodology\",\n",
    "        \"Gap identification\": \"Systematic reflection analysis\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for approach, characteristics in comparison_data.items():\n",
    "    print(f\"\\nğŸ“‹ {approach}:\")\n",
    "    for aspect, value in characteristics.items():\n",
    "        print(f\"   â€¢ {aspect}: {value}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Key Advantages of Agent-Based Research:\")\n",
    "advantages = [\n",
    "    \"Systematic coverage of multiple perspectives\",\n",
    "    \"Objective gap identification and follow-up\",\n",
    "    \"Consistent methodology across research topics\",\n",
    "    \"Scalable to handle multiple research questions\",\n",
    "    \"Quantifiable confidence in research completeness\",\n",
    "    \"Traceable decision-making process\"\n",
    "]\n",
    "\n",
    "for i, advantage in enumerate(advantages, 1):\n",
    "    print(f\"   {i}. {advantage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Part 3.8: Key Takeaways and Next Steps\n",
    "\n",
    "This tutorial demonstrated the power of **reflection-based research agents**. Here are the key concepts we covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ PART 3 KEY TAKEAWAYS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "key_concepts = {\n",
    "    \"ğŸ§  Reflection in AI\": [\n",
    "        \"Meta-cognitive self-assessment capabilities\",\n",
    "        \"Systematic gap identification and follow-up\",\n",
    "        \"Confidence quantification for decision-making\"\n",
    "    ],\n",
    "    \"ğŸ”„ Iterative Workflows\": [\n",
    "        \"LangGraph state management for complex processes\",\n",
    "        \"Conditional logic for adaptive research strategies\",\n",
    "        \"Quality-driven stopping criteria\"\n",
    "    ],\n",
    "    \"ğŸŒ Research Integration\": [\n",
    "        \"Multi-provider LLM compatibility (from Part 1)\",\n",
    "        \"Real API integration with fallback strategies\",\n",
    "        \"Parallel processing for efficiency\"\n",
    "    ],\n",
    "    \"ğŸ“Š Quality Assurance\": [\n",
    "        \"Systematic completeness evaluation\",\n",
    "        \"Source diversity and credibility assessment\",\n",
    "        \"Measurable research quality metrics\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for concept, details in key_concepts.items():\n",
    "    print(f\"\\n{concept}:\")\n",
    "    for detail in details:\n",
    "        print(f\"   â€¢ {detail}\")\n",
    "\n",
    "print(\"\\nğŸš€ Ready for Part 4: DAG Architecture!\")\n",
    "print(\"\\nIn the next tutorial, we'll explore how to build\")\n",
    "print(\"complex decision trees and directed acyclic graphs\")\n",
    "print(\"for advanced research workflows and PHMGA integration.\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Tutorial completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Exercises for Practice\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "### Exercise 1: Custom Research Domain\n",
    "Modify the `query_generator.py` to add a new domain pattern for your research area (e.g., \"materials_science\", \"biomedical_engineering\"). Test with domain-specific research questions.\n",
    "\n",
    "### Exercise 2: Advanced Reflection Criteria\n",
    "Extend the `reflection_agent.py` to include:\n",
    "- Source recency requirements (e.g., only papers from last 2 years)\n",
    "- Citation count thresholds for credibility\n",
    "- Geographic diversity of research sources\n",
    "\n",
    "### Exercise 3: Multi-Language Research\n",
    "Adapt the system to conduct research in multiple languages by:\n",
    "- Generating queries in different languages\n",
    "- Using translation APIs for source processing\n",
    "- Implementing cross-language result synthesis\n",
    "\n",
    "### Exercise 4: Research Workflow Optimization\n",
    "Implement performance optimizations:\n",
    "- Caching of search results to avoid redundant API calls\n",
    "- Async/await patterns for truly parallel processing\n",
    "- Result ranking and filtering strategies\n",
    "\n",
    "### Exercise 5: Integration with Academic Databases\n",
    "Extend the web searcher to integrate with:\n",
    "- ArXiv API for preprints\n",
    "- PubMed for biomedical literature\n",
    "- IEEE Xplore for engineering papers\n",
    "\n",
    "## ğŸ“š Further Reading\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Google Research: Reflection and Self-Improvement in AI](https://research.google/)\n",
    "- [Meta-Learning and Few-Shot Learning Survey](https://arxiv.org/)\n",
    "- [Information Retrieval and Knowledge Discovery](https://link.springer.com/)\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: [Part 4: DAG Architecture](../Part4_DAG_Architecture/04_Tutorial.ipynb) - Building Complex Decision Trees and Graph-Based Workflows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}