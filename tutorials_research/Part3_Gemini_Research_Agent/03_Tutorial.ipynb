{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Gemini Research Agent - Reflection-Based Research Workflows\n",
    "\n",
    "This tutorial demonstrates how to build an **intelligent research agent** that uses **reflection loops** to conduct comprehensive research on academic topics. We'll adapt Google's Gemini research pattern to work with **any LLM provider** from Part 1.\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will understand:\n",
    "1. **Reflection-based research**: How agents can evaluate their own work and iterate\n",
    "2. **Multi-step workflows**: Building complex research pipelines with LangGraph\n",
    "3. **Knowledge gap identification**: Teaching agents to recognize what they don't know\n",
    "4. **Dynamic query generation**: Creating targeted search strategies\n",
    "5. **Research synthesis**: Combining multiple sources into coherent insights\n",
    "\n",
    "## ğŸ“š Academic Research Scenario\n",
    "\n",
    "**Use Case**: You're writing a literature review section for your paper and need to research: *\"What are the recent advances in quantum error correction for fault-tolerant quantum computing?\"*\n",
    "\n",
    "Instead of manually searching and synthesizing papers, we'll build an agent that:\n",
    "- Generates diverse search queries\n",
    "- Conducts parallel web searches\n",
    "- Reflects on research completeness\n",
    "- Identifies knowledge gaps\n",
    "- Iteratively improves research coverage\n",
    "- Synthesizes final comprehensive insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Environment Setup\n",
    "\n",
    "First, let's set up our environment and imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport json\nimport time\nfrom typing import Dict, List, Any\nfrom datetime import datetime\n\n# Add paths for our modules\nsys.path.append('../Part1_Foundations/modules')\nsys.path.append('modules')\n\n# Import our foundational LLM system\nfrom llm_providers import create_research_llm, LLMProvider\n\n# Import research agent modules\nfrom state_schemas import (\n    ResearchConfiguration, \n    create_initial_research_state,\n    OverallResearchState\n)\nfrom query_generator import ResearchQueryGenerator\nfrom web_searcher import WebSearchExecutor\nfrom reflection_agent import ResearchReflectionAgent\nfrom research_graph import ResearchWorkflowGraph\n\nprint(\"ğŸ“š Research Agent Tutorial Environment Ready!\")\nprint(f\"ğŸ•’ Session started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Verify available LLM providers\nfrom llm_providers import list_research_providers\n\nprint(\"ğŸ” Available LLM Providers:\")\nlist_research_providers()\n\n# Create a research-optimized LLM instance\ntry:\n    llm = create_research_llm(\n        provider_name=None,  # Auto-select best available\n        temperature=0.7,\n        fast_mode=False\n    )\n    print(f\"\\nâœ… LLM created successfully: {type(llm).__name__}\")\n    print(f\"ğŸ¯ Ready for multi-provider research workflow\")\n    \nexcept Exception as e:\n    print(f\"\\nâŒ Error creating LLM: {e}\")\n    print(\"ğŸ’¡ Please check your API keys in .env file\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create research configuration using new system\nfrom configuration import Configuration\n\nprint(\"âš™ï¸ Research Configuration Options:\")\n\n# Show different configuration profiles\nconfigs = {\n    \"Academic Research\": Configuration.for_academic_research(),\n    \"Quick Research\": Configuration.for_quick_research(),\n    \"Comprehensive\": Configuration.for_comprehensive_research()\n}\n\nfor name, config in configs.items():\n    print(f\"\\nğŸ“‹ {name} Profile:\")\n    summary = config.get_summary()\n    for key, value in summary.items():\n        print(f\"   â€¢ {key}: {value}\")\n\n# Use academic configuration for our example\nresearch_config = Configuration.for_academic_research()\n\n# Validate configuration\nwarnings = research_config.validate_configuration()\nif warnings:\n    print(f\"\\nâš ï¸ Configuration warnings:\")\n    for warning in warnings:\n        print(f\"   â€¢ {warning}\")\nelse:\n    print(f\"\\nâœ… Configuration validated successfully\")\n\nprint(f\"\\nğŸ¯ Using: {research_config.get_summary()['search_strategy']} search strategy\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# NEW: Function-based approach (recommended)\nfrom research_graph import conduct_research\n\n# Define research question\nresearch_question = \"What are recent advances in quantum error correction for fault-tolerant quantum computing?\"\n\nprint(\"ğŸ”¬ MULTI-PROVIDER RESEARCH WORKFLOW\")\nprint(\"=\" * 42)\nprint(f\"Research Question: {research_question}\")\nprint()\n\n# Execute complete research workflow\nresults = conduct_research(research_question, research_config)\n\n# Display results\nif results[\"success\"]:\n    print(\"âœ… RESEARCH COMPLETED SUCCESSFULLY!\")\n    print(f\"ğŸ“Š Research Statistics:\")\n    print(f\"   â€¢ Total Sources: {results['total_sources']}\")\n    print(f\"   â€¢ Research Loops: {results['research_loops']}\")\n    print(f\"   â€¢ Configuration: {results['configuration']['search_strategy']}\")\n    \n    print(f\"\\nğŸ“ Final Answer:\")\n    print(\"-\" * 50)\n    final_answer = results[\"final_answer\"]\n    # Display first 500 characters\n    print(final_answer[:500] + \"...\" if len(final_answer) > 500 else final_answer)\n    print(\"-\" * 50)\n    \n    print(f\"\\nğŸ“š Sample Sources:\")\n    for i, source in enumerate(results[\"sources\"][:3], 1):\n        print(f\"{i}. {source.get('title', 'N/A')}\")\n        print(f\"   ğŸ”— {source.get('url', 'N/A')}\")\n        print()\n        \nelse:\n    print(\"âŒ RESEARCH FAILED!\")\n    print(f\"Error: {results.get('error', 'Unknown error')}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize query generator\n",
    "query_generator = ResearchQueryGenerator(research_llm, research_config)\n",
    "\n",
    "# Our research question for this demo\n",
    "research_question = \"What are recent advances in quantum error correction for fault-tolerant quantum computing?\"\n",
    "\n",
    "print(f\"ğŸ” Research Question: {research_question}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Generate initial queries\n",
    "print(\"ğŸ§  Generating research queries...\")\n",
    "query_result = query_generator.generate_initial_queries(research_question)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Generated {len(query_result.queries)} search queries:\")\n",
    "for i, query in enumerate(query_result.queries, 1):\n",
    "    print(f\"   {i}. {query}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Strategy: {query_result.research_strategy}\")\n",
    "print(f\"\\nğŸ“ Rationale: {query_result.rationale}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# LEGACY: Class-based approach (for compatibility with existing code)\nfrom research_graph import create_research_workflow\n\nprint(\"ğŸ”„ LEGACY COMPATIBILITY DEMONSTRATION\")\nprint(\"=\" * 38)\n\n# Create workflow using legacy approach (still works!)\nworkflow = create_research_workflow(llm, research_config)\n\n# Execute research using legacy method\nlegacy_results = workflow.conduct_research(\n    \"What are the latest developments in quantum machine learning?\",\n    session_id=\"demo_session\"\n)\n\n# Display legacy results format\nif legacy_results[\"success\"]:\n    print(\"âœ… Legacy workflow executed successfully!\")\n    print(f\"ğŸ“Š Legacy Results:\")\n    print(f\"   â€¢ Final Answer Length: {len(legacy_results['final_answer'])} chars\")\n    print(f\"   â€¢ Iterations: {legacy_results.get('iterations_completed', 0)}\")\n    print(f\"   â€¢ Sources Found: {legacy_results.get('total_sources_found', 0)}\")\n    print(f\"   â€¢ Confidence: {legacy_results.get('confidence_score', 0):.2f}\")\n    \n    print(f\"\\nğŸ“ Sample of Legacy Answer:\")\n    sample = legacy_results[\"final_answer\"][:300]\n    print(f\"   {sample}...\")\n    \nelse:\n    print(\"âŒ Legacy workflow failed!\")\n    print(f\"Error: {legacy_results.get('error', 'Unknown error')}\")\n\nprint(f\"\\nğŸ’¡ Both approaches work - use the function-based approach for new projects!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ¯ Tutorial Summary: Multi-Provider Research Agent\n\n### âœ… What We've Accomplished\n\nThis tutorial has demonstrated a **production-ready research agent** that combines:\n\n1. **Google's Reference Architecture**: Function-based LangGraph nodes with proper Send operations\n2. **Multi-Provider LLM Support**: Works with Google, OpenAI, DashScope, ZhipuAI via Part 1 system  \n3. **Intelligent Search Strategy**: Auto-detects and uses Google native search when available, graceful fallbacks\n4. **Structured Output**: Reliable JSON parsing with Pydantic models\n5. **Legacy Compatibility**: Existing tutorial code still works while you migrate\n\n### ğŸš€ Key Architectural Improvements\n\n| Component | Old Approach | New Approach | Benefits |\n|-----------|--------------|--------------|----------|\n| **Nodes** | Class-based components | Function-based nodes | Matches Google reference, cleaner |\n| **State** | Complex Pydantic models | Simple TypedDict patterns | Better performance, easier debugging |\n| **Search** | Single web search strategy | Multi-provider with auto-detection | Works everywhere, no API lock-in |\n| **LLM** | Hardcoded provider | Auto-select from Part 1 system | Provider flexibility, cost optimization |\n| **Config** | Basic settings | Rich configuration with profiles | Production-ready, environment-aware |\n\n### ğŸŒ Multi-Provider Benefits\n\n- **No Vendor Lock-in**: Switch between Google, OpenAI, etc. seamlessly\n- **Global Accessibility**: Works in regions where certain APIs are restricted\n- **Cost Optimization**: Use fast/cheap models for simple tasks, premium for complex analysis\n- **Fallback Resilience**: Auto-fallback when primary provider unavailable\n- **Provider Strengths**: Leverage each provider's unique capabilities\n\n### ğŸ“ Usage Patterns\n\n```python\n# ğŸ¯ Recommended: Function-based approach\nfrom research_graph import conduct_research\nfrom configuration import Configuration\n\nconfig = Configuration.for_academic_research()\nresult = conduct_research(\"Your research question\", config)\n\n# ğŸ”„ Compatible: Legacy approach\nworkflow = create_research_workflow(llm, config)  \nresult = workflow.conduct_research(\"Your research question\")\n```\n\n### ğŸ“ Learning Outcomes\n\nBy completing this tutorial, you've learned:\n\n1. **Production LangGraph Patterns**: How Google structures real-world research agents\n2. **Multi-Provider Architecture**: Building LLM-agnostic systems that work anywhere  \n3. **Search Strategy Design**: Intelligent fallbacks and provider-specific optimizations\n4. **State Management**: Efficient TypedDict patterns vs heavy Pydantic models\n5. **Configuration Systems**: Environment-aware, profile-based configuration\n6. **Legacy Migration**: How to evolve systems while maintaining compatibility\n\n### ğŸš€ Next Steps\n\n- **Customize**: Adapt the configuration for your specific research domain\n- **Extend**: Add new search providers or specialized research tools  \n- **Deploy**: Use the production patterns for real-world applications\n- **Optimize**: Fine-tune prompts and strategies for your LLM provider\n- **Scale**: Apply these patterns to other multi-agent workflows\n\n**Congratulations! You now have a production-ready, multi-provider research agent!** ğŸ‰",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "- **Intelligent Query Diversification**: The system generates queries targeting different aspects (theory, applications, recent work) to ensure comprehensive coverage\n",
    "- **Multi-Modal Generation**: Combines LLM reasoning with template-based approaches for robustness - if LLM fails, templates provide fallback\n",
    "- **Domain-Aware Optimization**: Recognizes quantum computing domain and adapts terminology and focus areas accordingly\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ Part 3.3: Web Search Integration\n",
    "\n",
    "Next, we execute searches using Google Custom Search API. Our system handles parallel execution and result processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize web searcher\nweb_searcher = WebSearchExecutor(research_config)\n\n# Execute searches for our generated queries\nprint(\"ğŸŒ Executing web searches...\")\nsearch_start_time = time.time()\n\n# Execute searches in parallel for efficiency\nsearch_results = []\nfor i, query in enumerate(query_result.queries[:2]):  # Limit for demo\n    print(f\"   ğŸ” Searching: {query[:50]}...\")\n    \n    try:\n        results = web_searcher.execute_search(query, max_results=3)\n        search_results.extend(results)\n        print(f\"     âœ… Found {len(results)} results\")\n    except Exception as e:\n        print(f\"     âš ï¸ Search failed: {e}\")\n        # Add demo results for tutorial purposes\n        demo_results = web_searcher._create_demo_results(query)\n        search_results.extend(demo_results)\n        print(f\"     ğŸ“š Using demo results: {len(demo_results)} sources\")\n\nsearch_time = time.time() - search_start_time\nprint(f\"\\nâ±ï¸ Search completed in {search_time:.2f} seconds\")\nprint(f\"ğŸ“Š Total sources found: {len(search_results)}\")\n\n# Display some results\nprint(\"\\nğŸ“š Sample Search Results:\")\nfor i, result in enumerate(search_results[:3], 1):\n    print(f\"\\n{i}. {result.get('title', 'N/A')}\")\n    print(f\"   ğŸ”— {result.get('url', 'N/A')}\")\n    print(f\"   ğŸ“ {result.get('snippet', 'N/A')[:100]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Part 3.4: Reflection and Gap Analysis\n",
    "\n",
    "Now comes the **key innovation**: the reflection agent analyzes our research results and identifies what's missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize reflection agent\n",
    "reflection_agent = ResearchReflectionAgent(research_llm, research_config)\n",
    "\n",
    "# Extract findings from search results\n",
    "findings = []\n",
    "for result in search_results:\n",
    "    if result.get('snippet'):\n",
    "        findings.append(result['snippet'])\n",
    "\n",
    "print(f\"ğŸ” Analyzing {len(findings)} research findings...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Perform reflection analysis\n",
    "reflection_result = reflection_agent.analyze_research_completeness(\n",
    "    original_question=research_question,\n",
    "    current_findings=findings,\n",
    "    current_sources=search_results,\n",
    "    research_iteration=1\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  Reflection Analysis Results:\")\n",
    "print(f\"\\nğŸ“Š Research Sufficient: {'âœ… Yes' if reflection_result.is_sufficient else 'âŒ No'}\")\n",
    "print(f\"ğŸ¯ Confidence Score: {reflection_result.confidence_score:.2f}/1.0\")\n",
    "\n",
    "print(f\"\\nğŸ” Knowledge Gap Identified:\")\n",
    "print(f\"   {reflection_result.knowledge_gap}\")\n",
    "\n",
    "if reflection_result.missing_aspects:\n",
    "    print(f\"\\nğŸ“‹ Missing Aspects ({len(reflection_result.missing_aspects)}):\")\n",
    "    for i, aspect in enumerate(reflection_result.missing_aspects, 1):\n",
    "        print(f\"   {i}. {aspect}\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Follow-up Queries ({len(reflection_result.follow_up_queries)}):\")\n",
    "for i, query in enumerate(reflection_result.follow_up_queries, 1):\n",
    "    print(f\"   {i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "- **Meta-Cognitive Assessment**: The reflection agent acts as a \"research supervisor\" evaluating the quality and completeness of findings\n",
    "- **Gap-Driven Iteration**: Instead of random additional searches, the system identifies specific knowledge gaps and generates targeted follow-up queries\n",
    "- **Confidence Quantification**: Provides measurable confidence scores to guide decision-making about when to stop researching\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Part 3.5: Iterative Research Loops\n",
    "\n",
    "If research is insufficient, we generate **follow-up queries** and conduct additional searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate follow-up query generation\n",
    "if not reflection_result.is_sufficient and reflection_result.follow_up_queries:\n",
    "    print(\"ğŸ”„ Conducting follow-up research...\")\n",
    "    \n",
    "    # Generate additional targeted queries\n",
    "    follow_up_queries = query_generator.generate_follow_up_queries(\n",
    "        original_question=research_question,\n",
    "        current_findings=findings[:5],  # Limit for demo\n",
    "        knowledge_gaps=reflection_result.missing_aspects\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Generated {len(follow_up_queries)} follow-up queries:\")\n",
    "    for i, query in enumerate(follow_up_queries, 1):\n",
    "        print(f\"   {i}. {query}\")\n",
    "    \n",
    "    # Execute one follow-up search (demo)\n",
    "    if follow_up_queries:\n",
    "        print(f\"\\nğŸ” Executing follow-up search: {follow_up_queries[0][:50]}...\")\n",
    "        try:\n",
    "            follow_up_results = web_searcher.execute_search(follow_up_queries[0], max_results=2)\n",
    "            print(f\"   âœ… Found {len(follow_up_results)} additional sources\")\n",
    "            \n",
    "            # Show improvement\n",
    "            total_sources = len(search_results) + len(follow_up_results)\n",
    "            print(f\"\\nğŸ“ˆ Research Progress:\")\n",
    "            print(f\"   Initial sources: {len(search_results)}\")\n",
    "            print(f\"   Follow-up sources: {len(follow_up_results)}\")\n",
    "            print(f\"   Total coverage: {total_sources} sources\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ Follow-up search failed: {e}\")\n",
    "            print(f\"   ğŸ“š In production, this would continue with more iterations\")\n",
    "else:\n",
    "    print(\"âœ… Research appears sufficient - no follow-up needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Part 3.6: Complete Research Workflow with LangGraph\n",
    "\n",
    "Now let's see the **complete research workflow** using LangGraph to orchestrate all components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the complete research workflow graph\n",
    "research_graph = ResearchWorkflowGraph(research_llm, research_config)\n",
    "\n",
    "print(\"ğŸ•¸ï¸ Research Workflow Graph initialized\")\n",
    "print(\"\\nğŸ“‹ Workflow Structure:\")\n",
    "workflow_steps = [\n",
    "    \"1. ğŸ¯ generate_queries: Create diverse search queries\",\n",
    "    \"2. ğŸŒ execute_search: Conduct parallel web searches\", \n",
    "    \"3. ğŸ§  reflect_on_research: Analyze completeness and gaps\",\n",
    "    \"4. ğŸ”„ Decision: Continue research or synthesize results\",\n",
    "    \"5. ğŸ“ synthesize_answer: Generate final comprehensive response\"\n",
    "]\n",
    "\n",
    "for step in workflow_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ Running complete research workflow...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Execute the complete workflow\n",
    "workflow_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Run the research workflow\n",
    "    research_result = research_graph.conduct_research(research_question)\n",
    "    \n",
    "    workflow_time = time.time() - workflow_start_time\n",
    "    \n",
    "    print(f\"\\nâ±ï¸ Complete workflow finished in {workflow_time:.2f} seconds\")\n",
    "    print(f\"\\nğŸ“Š Research Summary:\")\n",
    "    print(f\"   â€¢ Research iterations: {research_result.get('iterations_completed', 'N/A')}\")\n",
    "    print(f\"   â€¢ Total sources: {research_result.get('total_sources_found', 'N/A')}\")\n",
    "    print(f\"   â€¢ Final confidence: {research_result.get('confidence_score', 0):.2f}\")\n",
    "    \n",
    "    # Display final synthesized answer\n",
    "    if 'final_answer' in research_result:\n",
    "        print(f\"\\nğŸ“ Final Research Answer:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(research_result['final_answer'][:500] + \"...\" if len(research_result['final_answer']) > 500 else research_result['final_answer'])\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Workflow execution failed: {e}\")\n",
    "    print(\"\\nğŸ“š In this tutorial environment, some APIs may not be available.\")\n",
    "    print(\"The system includes demo modes for learning purposes.\")\n",
    "    \n",
    "    # Show demo workflow structure instead\n",
    "    print(\"\\nğŸ¯ Demo Workflow Execution:\")\n",
    "    demo_state = create_initial_research_state(research_question, research_config)\n",
    "    print(f\"   âœ… Initial state created: {demo_state['session_id']}\")\n",
    "    print(f\"   âœ… Max loops configured: {demo_state['max_research_loops']}\")\n",
    "    print(f\"   âœ… Ready for {demo_state['initial_search_query_count']} initial queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`\n",
    "- **State-Driven Workflow**: LangGraph manages complex state transitions between research phases, ensuring consistency and recoverability\n",
    "- **Conditional Logic**: The workflow automatically decides whether to continue researching or synthesize based on reflection results\n",
    "- **Scalable Architecture**: This pattern can handle any research complexity by adjusting iteration limits and quality thresholds\n",
    "`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Part 3.7: Comparing Approaches: Manual vs Agent-Based Research\n",
    "\n",
    "Let's compare traditional manual research with our agent-based approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š RESEARCH APPROACH COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_data = {\n",
    "    \"Manual Research\": {\n",
    "        \"Time per topic\": \"2-4 hours\",\n",
    "        \"Query diversity\": \"Limited by researcher bias\",\n",
    "        \"Completeness check\": \"Manual, subjective\",\n",
    "        \"Iteration strategy\": \"Ad-hoc follow-ups\",\n",
    "        \"Scalability\": \"Poor (human bottleneck)\",\n",
    "        \"Consistency\": \"Varies by researcher\",\n",
    "        \"Gap identification\": \"Relies on expertise\"\n",
    "    },\n",
    "    \"Agent-Based Research\": {\n",
    "        \"Time per topic\": \"5-15 minutes\",\n",
    "        \"Query diversity\": \"Multi-perspective, systematic\",\n",
    "        \"Completeness check\": \"Automated with confidence scores\",\n",
    "        \"Iteration strategy\": \"Gap-driven, targeted follow-ups\",\n",
    "        \"Scalability\": \"Excellent (parallel processing)\",\n",
    "        \"Consistency\": \"Reproducible methodology\",\n",
    "        \"Gap identification\": \"Systematic reflection analysis\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for approach, characteristics in comparison_data.items():\n",
    "    print(f\"\\nğŸ“‹ {approach}:\")\n",
    "    for aspect, value in characteristics.items():\n",
    "        print(f\"   â€¢ {aspect}: {value}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Key Advantages of Agent-Based Research:\")\n",
    "advantages = [\n",
    "    \"Systematic coverage of multiple perspectives\",\n",
    "    \"Objective gap identification and follow-up\",\n",
    "    \"Consistent methodology across research topics\",\n",
    "    \"Scalable to handle multiple research questions\",\n",
    "    \"Quantifiable confidence in research completeness\",\n",
    "    \"Traceable decision-making process\"\n",
    "]\n",
    "\n",
    "for i, advantage in enumerate(advantages, 1):\n",
    "    print(f\"   {i}. {advantage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Part 3.8: Key Takeaways and Next Steps\n",
    "\n",
    "This tutorial demonstrated the power of **reflection-based research agents**. Here are the key concepts we covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ PART 3 KEY TAKEAWAYS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "key_concepts = {\n",
    "    \"ğŸ§  Reflection in AI\": [\n",
    "        \"Meta-cognitive self-assessment capabilities\",\n",
    "        \"Systematic gap identification and follow-up\",\n",
    "        \"Confidence quantification for decision-making\"\n",
    "    ],\n",
    "    \"ğŸ”„ Iterative Workflows\": [\n",
    "        \"LangGraph state management for complex processes\",\n",
    "        \"Conditional logic for adaptive research strategies\",\n",
    "        \"Quality-driven stopping criteria\"\n",
    "    ],\n",
    "    \"ğŸŒ Research Integration\": [\n",
    "        \"Multi-provider LLM compatibility (from Part 1)\",\n",
    "        \"Real API integration with fallback strategies\",\n",
    "        \"Parallel processing for efficiency\"\n",
    "    ],\n",
    "    \"ğŸ“Š Quality Assurance\": [\n",
    "        \"Systematic completeness evaluation\",\n",
    "        \"Source diversity and credibility assessment\",\n",
    "        \"Measurable research quality metrics\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for concept, details in key_concepts.items():\n",
    "    print(f\"\\n{concept}:\")\n",
    "    for detail in details:\n",
    "        print(f\"   â€¢ {detail}\")\n",
    "\n",
    "print(\"\\nğŸš€ Ready for Part 4: DAG Architecture!\")\n",
    "print(\"\\nIn the next tutorial, we'll explore how to build\")\n",
    "print(\"complex decision trees and directed acyclic graphs\")\n",
    "print(\"for advanced research workflows and PHMGA integration.\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Tutorial completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Exercises for Practice\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "### Exercise 1: Custom Research Domain\n",
    "Modify the `query_generator.py` to add a new domain pattern for your research area (e.g., \"materials_science\", \"biomedical_engineering\"). Test with domain-specific research questions.\n",
    "\n",
    "### Exercise 2: Advanced Reflection Criteria\n",
    "Extend the `reflection_agent.py` to include:\n",
    "- Source recency requirements (e.g., only papers from last 2 years)\n",
    "- Citation count thresholds for credibility\n",
    "- Geographic diversity of research sources\n",
    "\n",
    "### Exercise 3: Multi-Language Research\n",
    "Adapt the system to conduct research in multiple languages by:\n",
    "- Generating queries in different languages\n",
    "- Using translation APIs for source processing\n",
    "- Implementing cross-language result synthesis\n",
    "\n",
    "### Exercise 4: Research Workflow Optimization\n",
    "Implement performance optimizations:\n",
    "- Caching of search results to avoid redundant API calls\n",
    "- Async/await patterns for truly parallel processing\n",
    "- Result ranking and filtering strategies\n",
    "\n",
    "### Exercise 5: Integration with Academic Databases\n",
    "Extend the web searcher to integrate with:\n",
    "- ArXiv API for preprints\n",
    "- PubMed for biomedical literature\n",
    "- IEEE Xplore for engineering papers\n",
    "\n",
    "## ğŸ“š Further Reading\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Google Research: Reflection and Self-Improvement in AI](https://research.google/)\n",
    "- [Meta-Learning and Few-Shot Learning Survey](https://arxiv.org/)\n",
    "- [Information Retrieval and Knowledge Discovery](https://link.springer.com/)\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: [Part 4: DAG Architecture](../Part4_DAG_Architecture/04_Tutorial.ipynb) - Building Complex Decision Trees and Graph-Based Workflows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}