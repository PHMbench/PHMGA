{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: PHM Case Study - Complete Bearing Fault Diagnosis System\n",
    "\n",
    "Welcome to the **final tutorial** in our series! This tutorial integrates **all concepts from Parts 1-4** into a complete **Prognostics and Health Management (PHM)** system using the PHMGA architecture.\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will understand:\n",
    "1. **System Integration**: How all tutorial components work together in production\n",
    "2. **PHMGA Architecture**: Complete understanding of the PHM Graph Agent system\n",
    "3. **Real-World Application**: Bearing fault diagnosis using integrated AI workflows\n",
    "4. **Research-to-Production**: Bridging academic research and industrial deployment\n",
    "5. **Performance Evaluation**: Comprehensive system assessment and validation\n",
    "\n",
    "## 🏭 Industrial Context\n",
    "\n",
    "**Scenario**: You're developing an AI system for a **manufacturing facility** that needs to:\n",
    "- Monitor rotating machinery health in real-time\n",
    "- Detect bearing faults before catastrophic failure\n",
    "- Continuously improve through research integration\n",
    "- Provide actionable maintenance recommendations\n",
    "\n",
    "This system combines:\n",
    "- **🤖 Part 1**: Multi-provider LLM foundation for intelligent reasoning\n",
    "- **🔀 Part 2**: Multi-agent router for task orchestration and tool integration\n",
    "- **🔄 Part 3**: Research integration for continuous knowledge updates\n",
    "- **🕸️ Part 4**: DAG-based signal processing for efficient parallel computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Environment Setup\n",
    "\n",
    "Let's set up our complete PHMGA environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
    "\n",
    "# Add module paths\n",
    "sys.path.append('modules')\n",
    "\n",
    "# Import the complete PHMGA system\n",
    "from phmga_system import PHMGASystem, PHMGAConfig\n",
    "\n",
    "print(\"🏭 COMPLETE PHMGA SYSTEM TUTORIAL\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🕒 Tutorial started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\n📚 This tutorial integrates all components from Parts 1-4:\")\n",
    "print(\"   • Part 1: Multi-provider LLM foundation\")\n",
    "print(\"   • Part 2: Multi-agent task routing\")\n",
    "print(\"   • Part 3: Research integration and reflection\")\n",
    "print(\"   • Part 4: DAG-based signal processing\")\n",
    "print(\"   • Part 5: Complete production system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Part 5.1: PHMGA System Architecture\n",
    "\n",
    "Let's explore the **complete system architecture** that integrates all our previous work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different system configurations for comparison\n",
    "print(\"⚙️ PHMGA SYSTEM CONFIGURATIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Tutorial configuration (simplified for learning)\n",
    "tutorial_config = PHMGAConfig.for_tutorial()\n",
    "print(\"\\n📚 Tutorial Configuration:\")\n",
    "print(f\"   • LLM Provider: {tutorial_config.llm_provider}\")\n",
    "print(f\"   • Research Enabled: {tutorial_config.research_enabled}\")\n",
    "print(f\"   • Max Research Loops: {tutorial_config.max_research_loops}\")\n",
    "print(f\"   • Parallel Processing: {tutorial_config.enable_parallel_processing}\")\n",
    "print(f\"   • Batch Size: {tutorial_config.batch_processing_size}\")\n",
    "print(f\"   • Logging Level: {tutorial_config.logging_level}\")\n",
    "\n",
    "# Research configuration (optimized for research tasks)\n",
    "research_config = PHMGAConfig.for_research()\n",
    "print(\"\\n🔬 Research Configuration:\")\n",
    "print(f\"   • Research Quality Threshold: {research_config.research_quality_threshold}\")\n",
    "print(f\"   • Max Research Loops: {research_config.max_research_loops}\")\n",
    "print(f\"   • LLM Temperature: {research_config.llm_temperature} (lower for consistency)\")\n",
    "print(f\"   • Research Enabled: {research_config.research_enabled}\")\n",
    "\n",
    "# Production configuration (optimized for performance)\n",
    "production_config = PHMGAConfig.for_production()\n",
    "print(\"\\n🏭 Production Configuration:\")\n",
    "print(f\"   • Real-time Mode: {production_config.real_time_mode}\")\n",
    "print(f\"   • Max Parallel Nodes: {production_config.max_parallel_nodes}\")\n",
    "print(f\"   • Confidence Threshold: {production_config.confidence_threshold}\")\n",
    "print(f\"   • Alert Threshold: {production_config.alert_threshold}\")\n",
    "print(f\"   • Logging Level: {production_config.logging_level}\")\n",
    "\n",
    "print(\"\\n💡 Configuration Selection:\")\n",
    "print(\"   • Tutorial: Simplified for learning and understanding\")\n",
    "print(\"   • Research: Optimized for thorough analysis and knowledge discovery\")\n",
    "print(\"   • Production: Optimized for speed, reliability, and real-time processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Part 5.2: System Initialization and Component Integration\n",
    "\n",
    "Let's initialize the complete PHMGA system and see how all components integrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PHMGA system with tutorial configuration\n",
    "print(\"🚀 INITIALIZING COMPLETE PHMGA SYSTEM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use tutorial configuration for easier understanding\n",
    "config = PHMGAConfig.for_tutorial()\n",
    "config.research_enabled = True  # Enable research for demonstration\n",
    "\n",
    "print(\"\\n⚙️ Creating PHMGA system with integrated components...\")\n",
    "phmga_system = PHMGASystem(config)\n",
    "\n",
    "# Get and display system status\n",
    "print(\"\\n📊 System Status Check:\")\n",
    "system_status = phmga_system.get_system_status()\n",
    "\n",
    "print(f\"   • Session ID: {system_status['session_id']}\")\n",
    "print(f\"   • System Status: {system_status['system_status']}\")\n",
    "print(f\"   • Uptime: {system_status['uptime_seconds']:.2f} seconds\")\n",
    "\n",
    "# Show component status\n",
    "component_status = system_status['component_status']\n",
    "print(f\"\\n🔧 Component Status:\")\n",
    "for component, status in component_status.items():\n",
    "    status_icon = \"✅\" if status == \"active\" else \"❌\"\n",
    "    component_name = component.replace('_', ' ').title()\n",
    "    print(f\"   {status_icon} {component_name}: {status}\")\n",
    "\n",
    "# Show processing statistics\n",
    "stats = system_status['processing_statistics']\n",
    "print(f\"\\n📈 Processing Statistics:\")\n",
    "print(f\"   • Signals Processed: {stats['total_signals_processed']}\")\n",
    "print(f\"   • Faults Detected: {stats['total_faults_detected']}\")\n",
    "print(f\"   • Average Processing Time: {stats['average_processing_time']:.3f}s\")\n",
    "print(f\"   • System Uptime: {stats['system_uptime']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`★ Insight ─────────────────────────────────────`\n",
    "- **Modular Integration**: Each component from Parts 1-4 operates independently but shares data through the unified PHMGA system interface\n",
    "- **Graceful Degradation**: If any component fails to initialize (e.g., due to missing API keys), the system continues operating with reduced functionality\n",
    "- **Status Monitoring**: The system provides real-time visibility into component health and processing statistics for production monitoring\n",
    "`─────────────────────────────────────────────────`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Part 5.3: Single Signal Analysis Walkthrough\n",
    "\n",
    "Let's walk through a **complete diagnosis** of a single bearing signal to understand the integrated workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single test signal for detailed analysis\n",
    "print(\"🔍 SINGLE SIGNAL ANALYSIS WALKTHROUGH\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a synthetic bearing fault signal\n",
    "print(\"\\n📡 Generating synthetic bearing fault signal...\")\n",
    "\n",
    "# Signal parameters\n",
    "fs = 10000  # 10 kHz sampling rate\n",
    "duration = 1.0  # 1 second\n",
    "t = np.linspace(0, duration, int(fs * duration))\n",
    "\n",
    "# Create inner race fault signal\n",
    "# Shaft frequency: 60 Hz\n",
    "# Inner race fault frequency: 157 Hz (typical for bearing geometry)\n",
    "signal = (np.sin(2 * np.pi * 60 * t) +           # Shaft rotation\n",
    "          0.5 * np.sin(2 * np.pi * 157 * t) +    # Inner race fault\n",
    "          0.1 * np.random.randn(len(t)))         # Noise\n",
    "\n",
    "# Signal metadata\n",
    "signal_metadata = {\n",
    "    \"fault_type\": \"inner_race\",\n",
    "    \"sampling_rate\": fs,\n",
    "    \"duration\": duration,\n",
    "    \"signal_length\": len(signal),\n",
    "    \"shaft_frequency\": 60,\n",
    "    \"fault_frequency\": 157,\n",
    "    \"description\": \"Synthetic inner race fault with 157 Hz characteristic frequency\"\n",
    "}\n",
    "\n",
    "print(f\"   📊 Signal Properties:\")\n",
    "print(f\"      • Type: {signal_metadata['fault_type']}\")\n",
    "print(f\"      • Length: {signal_metadata['signal_length']} samples\")\n",
    "print(f\"      • Duration: {signal_metadata['duration']} seconds\")\n",
    "print(f\"      • Sampling Rate: {signal_metadata['sampling_rate']} Hz\")\n",
    "print(f\"      • Fault Frequency: {signal_metadata['fault_frequency']} Hz\")\n",
    "\n",
    "# Visualize the signal\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t[:1000], signal[:1000])  # Show first 0.1 seconds\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Synthetic Inner Race Fault Signal (First 0.1 seconds)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Show frequency spectrum\n",
    "plt.figure(figsize=(12, 4))\n",
    "f = np.fft.fftfreq(len(signal), 1/fs)[:len(signal)//2]\n",
    "fft_signal = np.fft.fft(signal)\n",
    "plt.plot(f, np.abs(fft_signal[:len(signal)//2]))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Frequency Spectrum - Note peaks at 60 Hz (shaft) and 157 Hz (fault)')\n",
    "plt.xlim(0, 300)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete diagnosis on the single signal\n",
    "print(\"\\n🔬 Running Complete PHMGA Diagnosis...\")\n",
    "print(\"This demonstrates the integrated workflow from all tutorial parts.\\n\")\n",
    "\n",
    "# Execute the integrated diagnosis\n",
    "diagnosis_start = time.time()\n",
    "diagnosis_results = phmga_system.diagnose_bearing_faults(signal, signal_metadata)\n",
    "diagnosis_time = time.time() - diagnosis_start\n",
    "\n",
    "print(f\"\\n✅ Diagnosis completed in {diagnosis_time:.2f} seconds\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📋 DETAILED DIAGNOSIS RESULTS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze processing stages\n",
    "processing_stages = diagnosis_results.get(\"processing_stages\", {})\n",
    "print(f\"\\n🔄 Processing Stages Executed: {len(processing_stages)}\")\n",
    "\n",
    "for stage_name, stage_data in processing_stages.items():\n",
    "    stage_display_name = stage_name.replace('_', ' ').title()\n",
    "    execution_time = stage_data.get('execution_time', 0.0)\n",
    "    \n",
    "    if 'error' in stage_data:\n",
    "        print(f\"   ❌ {stage_display_name}: Failed ({execution_time:.2f}s) - {stage_data['error']}\")\n",
    "    else:\n",
    "        print(f\"   ✅ {stage_display_name}: Completed ({execution_time:.2f}s)\")\n",
    "        \n",
    "        # Show stage-specific details\n",
    "        if stage_name == \"dag_processing\":\n",
    "            nodes_executed = stage_data.get('nodes_executed', 0)\n",
    "            print(f\"      • Nodes Executed: {nodes_executed}\")\n",
    "            print(f\"      • Processing Successful: {stage_data.get('processing_successful', False)}\")\n",
    "        \n",
    "        elif stage_name == \"research_enhancement\":\n",
    "            research_question = stage_data.get('research_question', 'N/A')\n",
    "            knowledge_updates = stage_data.get('knowledge_updates', 0)\n",
    "            print(f\"      • Research Question: {research_question[:50]}...\")\n",
    "            print(f\"      • Knowledge Updates: {knowledge_updates}\")\n",
    "        \n",
    "        elif stage_name == \"agent_validation\":\n",
    "            agents_consulted = stage_data.get('agents_consulted', 0)\n",
    "            validation_successful = stage_data.get('validation_successful', False)\n",
    "            print(f\"      • Agents Consulted: {agents_consulted}\")\n",
    "            print(f\"      • Validation Successful: {validation_successful}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the primary diagnosis results\n",
    "print(\"\\n🎯 PRIMARY DIAGNOSIS RESULTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "primary_diagnosis = diagnosis_results.get(\"primary_diagnosis\", {})\n",
    "if \"diagnoses\" in primary_diagnosis and primary_diagnosis[\"diagnoses\"]:\n",
    "    diagnosis = primary_diagnosis[\"diagnoses\"][0]  # First diagnosis\n",
    "    \n",
    "    detected_fault = diagnosis.get(\"fault_type\", \"unknown\")\n",
    "    confidence = diagnosis.get(\"confidence\", 0.0)\n",
    "    severity = diagnosis.get(\"severity\", \"unknown\")\n",
    "    recommendation = diagnosis.get(\"recommendation\", \"N/A\")\n",
    "    \n",
    "    print(f\"🔍 Detected Fault Type: {detected_fault}\")\n",
    "    print(f\"📊 Confidence Score: {confidence:.3f}\")\n",
    "    print(f\"⚠️ Severity Level: {severity}\")\n",
    "    print(f\"💡 Recommendation: {recommendation}\")\n",
    "    \n",
    "    # Compare with ground truth\n",
    "    true_fault = signal_metadata[\"fault_type\"]\n",
    "    diagnosis_correct = detected_fault.lower() == true_fault.lower()\n",
    "    \n",
    "    print(f\"\\n✅ Ground Truth Comparison:\")\n",
    "    print(f\"   • True Fault Type: {true_fault}\")\n",
    "    print(f\"   • Detected Fault Type: {detected_fault}\")\n",
    "    print(f\"   • Diagnosis Accuracy: {'✅ Correct' if diagnosis_correct else '❌ Incorrect'}\")\n",
    "    \n",
    "    if diagnosis_correct:\n",
    "        print(f\"   🎉 Successfully identified {true_fault} fault with {confidence:.1%} confidence!\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Misclassification: Expected {true_fault}, got {detected_fault}\")\n",
    "else:\n",
    "    print(\"⚠️ No primary diagnosis available in results\")\n",
    "\n",
    "# Analyze final assessment\n",
    "print(\"\\n🎯 FINAL INTEGRATED ASSESSMENT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "final_assessment = diagnosis_results.get(\"final_assessment\", {})\n",
    "if final_assessment:\n",
    "    fault_detected = final_assessment.get(\"fault_detected\", False)\n",
    "    final_fault_type = final_assessment.get(\"fault_type\", \"unknown\")\n",
    "    final_confidence = final_assessment.get(\"confidence\", 0.0)\n",
    "    final_severity = final_assessment.get(\"severity\", \"unknown\")\n",
    "    integration_score = final_assessment.get(\"system_integration_score\", 0.0)\n",
    "    recommendations = final_assessment.get(\"recommendations\", [])\n",
    "    \n",
    "    print(f\"🚨 Fault Detected: {'Yes' if fault_detected else 'No'}\")\n",
    "    print(f\"🔍 Final Fault Type: {final_fault_type}\")\n",
    "    print(f\"📊 Final Confidence: {final_confidence:.3f}\")\n",
    "    print(f\"⚠️ Severity Assessment: {final_severity}\")\n",
    "    print(f\"🔧 System Integration Score: {integration_score:.3f}\")\n",
    "    \n",
    "    if recommendations:\n",
    "        print(f\"\\n💡 System Recommendations:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"   {i}. {rec}\")\n",
    "    \n",
    "    # Performance assessment\n",
    "    print(f\"\\n📈 Performance Assessment:\")\n",
    "    if integration_score >= 0.8:\n",
    "        print(f\"   ✅ Excellent system integration ({integration_score:.1%})\")\n",
    "    elif integration_score >= 0.6:\n",
    "        print(f\"   ✅ Good system integration ({integration_score:.1%})\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Limited system integration ({integration_score:.1%})\")\n",
    "        \n",
    "    if final_confidence >= 0.8:\n",
    "        print(f\"   ✅ High confidence diagnosis ({final_confidence:.1%})\")\n",
    "    elif final_confidence >= 0.6:\n",
    "        print(f\"   ✅ Moderate confidence diagnosis ({final_confidence:.1%})\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Low confidence diagnosis ({final_confidence:.1%})\")\n",
    "else:\n",
    "    print(\"⚠️ No final assessment available\")\n",
    "\n",
    "print(f\"\\n⏱️ Total Processing Time: {diagnosis_results.get('total_processing_time', 0.0):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`★ Insight ─────────────────────────────────────`\n",
    "- **End-to-End Integration**: The single signal analysis demonstrates how data flows through all system components, from raw signal input to actionable recommendations\n",
    "- **Multi-Level Validation**: The system provides both component-level results (DAG processing, research enhancement) and integrated final assessments\n",
    "- **Confidence Quantification**: Multiple confidence scores allow users to understand both individual component reliability and overall system confidence\n",
    "`─────────────────────────────────────────────────`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏭 Part 5.4: Complete Case Study Execution\n",
    "\n",
    "Now let's run the **complete case study** that processes multiple bearing fault types and evaluates overall system performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete case study\n",
    "print(\"🏭 COMPLETE PHM CASE STUDY EXECUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"This case study demonstrates the complete PHMGA system processing\")\n",
    "print(\"multiple bearing fault scenarios in a production-like environment.\\n\")\n",
    "\n",
    "# Execute the case study\n",
    "case_study_start = time.time()\n",
    "case_results = phmga_system.run_case_study(\"complete_bearing_diagnosis_demo\")\n",
    "case_study_time = time.time() - case_study_start\n",
    "\n",
    "print(f\"\\n\\n🎓 CASE STUDY COMPLETED in {case_study_time:.2f} seconds!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extract key results\n",
    "signal_analyses = case_results.get(\"signal_analyses\", [])\n",
    "system_performance = case_results.get(\"system_performance\", {})\n",
    "validation_results = case_results.get(\"validation_results\", {})\n",
    "\n",
    "print(f\"\\n📊 Case Study Overview:\")\n",
    "print(f\"   • Case Name: {case_results.get('case_name', 'N/A')}\")\n",
    "print(f\"   • Session ID: {case_results.get('session_id', 'N/A')}\")\n",
    "print(f\"   • Total Signals Processed: {len(signal_analyses)}\")\n",
    "print(f\"   • Total Execution Time: {case_results.get('total_case_time', 0.0):.2f} seconds\")\n",
    "print(f\"   • Start Time: {case_results.get('start_time', 'N/A')}\")\n",
    "print(f\"   • End Time: {case_results.get('end_time', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze individual signal results\n",
    "print(\"\\n🔍 INDIVIDUAL SIGNAL ANALYSIS RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if signal_analyses:\n",
    "    print(f\"Detailed results for {len(signal_analyses)} processed signals:\\n\")\n",
    "    \n",
    "    for i, analysis in enumerate(signal_analyses, 1):\n",
    "        true_fault = analysis.get(\"true_fault_type\", \"unknown\")\n",
    "        final_assessment = analysis.get(\"final_assessment\", {})\n",
    "        detected_fault = final_assessment.get(\"fault_type\", \"unknown\")\n",
    "        confidence = final_assessment.get(\"confidence\", 0.0)\n",
    "        processing_time = analysis.get(\"total_processing_time\", 0.0)\n",
    "        \n",
    "        # Determine accuracy\n",
    "        correct = detected_fault.lower() == true_fault.lower()\n",
    "        accuracy_icon = \"✅\" if correct else \"❌\"\n",
    "        \n",
    "        print(f\"   Signal {i}:\")\n",
    "        print(f\"      • True Fault: {true_fault}\")\n",
    "        print(f\"      • Detected: {detected_fault}\")\n",
    "        print(f\"      • Confidence: {confidence:.3f}\")\n",
    "        print(f\"      • Processing Time: {processing_time:.2f}s\")\n",
    "        print(f\"      • Accuracy: {accuracy_icon} {'Correct' if correct else 'Incorrect'}\")\n",
    "        \n",
    "        # Show processing stages summary\n",
    "        processing_stages = analysis.get(\"processing_stages\", {})\n",
    "        successful_stages = len([s for s in processing_stages.values() if \"error\" not in s])\n",
    "        total_stages = len(processing_stages)\n",
    "        \n",
    "        if total_stages > 0:\n",
    "            stage_success_rate = successful_stages / total_stages\n",
    "            print(f\"      • Stage Success: {successful_stages}/{total_stages} ({stage_success_rate:.1%})\")\n",
    "        \n",
    "        print()  # Empty line for readability\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ No individual signal analyses available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze overall system performance\n",
    "print(\"\\n📈 OVERALL SYSTEM PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if system_performance:\n",
    "    # Main performance metrics\n",
    "    accuracy = system_performance.get(\"accuracy\", 0.0)\n",
    "    avg_confidence = system_performance.get(\"average_confidence\", 0.0)\n",
    "    avg_processing_time = system_performance.get(\"average_processing_time\", 0.0)\n",
    "    integration_score = system_performance.get(\"integration_score\", 0.0)\n",
    "    total_samples = system_performance.get(\"total_samples\", 0)\n",
    "    correct_predictions = system_performance.get(\"correct_predictions\", 0)\n",
    "    \n",
    "    print(f\"🎯 Primary Performance Metrics:\")\n",
    "    print(f\"   • Overall Accuracy: {accuracy:.1%} ({correct_predictions}/{total_samples} correct)\")\n",
    "    print(f\"   • Average Confidence: {avg_confidence:.3f}\")\n",
    "    print(f\"   • Average Processing Time: {avg_processing_time:.2f} seconds\")\n",
    "    print(f\"   • System Integration Score: {integration_score:.3f}\")\n",
    "    \n",
    "    # Processing time analysis\n",
    "    processing_time_std = system_performance.get(\"processing_time_std\", 0.0)\n",
    "    print(f\"\\n⏱️ Processing Time Analysis:\")\n",
    "    print(f\"   • Average: {avg_processing_time:.2f}s\")\n",
    "    print(f\"   • Standard Deviation: {processing_time_std:.2f}s\")\n",
    "    print(f\"   • Consistency: {'High' if processing_time_std < 1.0 else 'Moderate' if processing_time_std < 2.0 else 'Variable'}\")\n",
    "    \n",
    "    # Fault-specific performance\n",
    "    fault_performance = system_performance.get(\"fault_specific_performance\", {})\n",
    "    if fault_performance:\n",
    "        print(f\"\\n🔍 Fault-Specific Performance:\")\n",
    "        for fault_type, metrics in fault_performance.items():\n",
    "            fault_accuracy = metrics.get(\"accuracy\", 0.0)\n",
    "            sample_count = metrics.get(\"sample_count\", 0)\n",
    "            correct_count = metrics.get(\"correct_predictions\", 0)\n",
    "            \n",
    "            print(f\"   • {fault_type.title()}: {fault_accuracy:.1%} ({correct_count}/{sample_count})\")\n",
    "    \n",
    "    # Performance assessment\n",
    "    print(f\"\\n✨ Performance Assessment:\")\n",
    "    if accuracy >= 0.9:\n",
    "        print(f\"   🏆 Excellent accuracy ({accuracy:.1%}) - Production ready\")\n",
    "    elif accuracy >= 0.8:\n",
    "        print(f\"   ✅ Good accuracy ({accuracy:.1%}) - Suitable for most applications\")\n",
    "    elif accuracy >= 0.7:\n",
    "        print(f\"   ⚠️ Moderate accuracy ({accuracy:.1%}) - May need improvement\")\n",
    "    else:\n",
    "        print(f\"   ❌ Low accuracy ({accuracy:.1%}) - Requires significant improvement\")\n",
    "    \n",
    "    if avg_confidence >= 0.8:\n",
    "        print(f\"   🎯 High average confidence ({avg_confidence:.3f}) - Reliable predictions\")\n",
    "    elif avg_confidence >= 0.6:\n",
    "        print(f\"   ✅ Moderate average confidence ({avg_confidence:.3f}) - Generally reliable\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Low average confidence ({avg_confidence:.3f}) - Uncertainty in predictions\")\n",
    "    \n",
    "    if avg_processing_time <= 2.0:\n",
    "        print(f\"   ⚡ Fast processing ({avg_processing_time:.2f}s) - Real-time capable\")\n",
    "    elif avg_processing_time <= 5.0:\n",
    "        print(f\"   ✅ Reasonable processing time ({avg_processing_time:.2f}s) - Near real-time\")\n",
    "    else:\n",
    "        print(f\"   ⏳ Slow processing ({avg_processing_time:.2f}s) - Batch processing suitable\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ No system performance data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze system validation results\n",
    "print(\"\\n✅ SYSTEM VALIDATION RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if validation_results:\n",
    "    overall_validation = validation_results.get(\"overall_validation\", {})\n",
    "    validation_passed = overall_validation.get(\"passed\", False)\n",
    "    passed_checks = overall_validation.get(\"passed_checks\", 0)\n",
    "    total_checks = overall_validation.get(\"total_checks\", 0)\n",
    "    \n",
    "    print(f\"🎯 Overall Validation: {'✅ PASSED' if validation_passed else '❌ FAILED'}\")\n",
    "    print(f\"📊 Validation Score: {passed_checks}/{total_checks} checks passed\\n\")\n",
    "    \n",
    "    # Individual validation checks\n",
    "    validation_checks = [\n",
    "        (\"accuracy_validation\", \"Accuracy Target\", \"≥80%\"),\n",
    "        (\"confidence_validation\", \"Confidence Target\", \"≥70%\"),\n",
    "        (\"processing_time_validation\", \"Processing Time Target\", \"≤5.0s\"),\n",
    "        (\"integration_validation\", \"Integration Target\", \"≥80%\")\n",
    "    ]\n",
    "    \n",
    "    for check_key, check_name, target_desc in validation_checks:\n",
    "        if check_key in validation_results:\n",
    "            check_result = validation_results[check_key]\n",
    "            achieved = check_result.get(\"achieved\", 0.0)\n",
    "            target = check_result.get(\"target\", 0.0)\n",
    "            passed = check_result.get(\"passed\", False)\n",
    "            margin = check_result.get(\"margin\", 0.0)\n",
    "            \n",
    "            status_icon = \"✅\" if passed else \"❌\"\n",
    "            \n",
    "            # Format values based on check type\n",
    "            if \"time\" in check_key:\n",
    "                achieved_str = f\"{achieved:.2f}s\"\n",
    "                target_str = f\"{target:.1f}s\"\n",
    "                margin_str = f\"{abs(margin):.2f}s {'under' if margin > 0 else 'over'} target\"\n",
    "            else:\n",
    "                achieved_str = f\"{achieved:.1%}\"\n",
    "                target_str = f\"{target:.1%}\"\n",
    "                margin_str = f\"{abs(margin):.1%} {'above' if margin > 0 else 'below'} target\"\n",
    "            \n",
    "            print(f\"{status_icon} {check_name}:\")\n",
    "            print(f\"   • Target: {target_desc}\")\n",
    "            print(f\"   • Achieved: {achieved_str}\")\n",
    "            print(f\"   • Margin: {margin_str}\")\n",
    "            print()\n",
    "    \n",
    "    # Final validation assessment\n",
    "    if validation_passed:\n",
    "        print(\"🎉 System meets all validation criteria and is ready for deployment!\")\n",
    "    else:\n",
    "        print(\"⚠️ System failed some validation checks. Review results for improvement areas.\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ No validation results available\")\n",
    "\n",
    "# Show research insights if available\n",
    "research_insights = case_results.get(\"research_insights\", {})\n",
    "if research_insights and \"message\" not in research_insights:\n",
    "    print(\"\\n🔬 RESEARCH INTEGRATION INSIGHTS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    queries_executed = research_insights.get(\"research_queries_executed\", 0)\n",
    "    avg_research_time = research_insights.get(\"average_research_time\", 0.0)\n",
    "    knowledge_updates = research_insights.get(\"total_knowledge_updates\", 0)\n",
    "    \n",
    "    print(f\"📚 Research Queries Executed: {queries_executed}\")\n",
    "    print(f\"⏱️ Average Research Time: {avg_research_time:.2f}s per query\")\n",
    "    print(f\"📖 Total Knowledge Updates: {knowledge_updates}\")\n",
    "    \n",
    "    research_topics = research_insights.get(\"research_topics\", [])\n",
    "    if research_topics:\n",
    "        print(f\"\\n🎯 Research Topics Explored:\")\n",
    "        for i, topic in enumerate(research_topics[:3], 1):\n",
    "            print(f\"   {i}. {topic[:60]}...\" if len(topic) > 60 else f\"   {i}. {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`★ Insight ─────────────────────────────────────`\n",
    "- **Production Readiness Assessment**: The validation framework provides objective criteria to determine if the system meets industrial deployment standards\n",
    "- **Multi-Dimensional Performance**: The system evaluates accuracy, confidence, speed, and integration quality to provide comprehensive performance insights\n",
    "- **Continuous Improvement Integration**: Research insights demonstrate how the system can automatically discover and integrate new knowledge for ongoing improvement\n",
    "`─────────────────────────────────────────────────`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Part 5.5: System Performance Visualization\n",
    "\n",
    "Let's create **visualizations** to better understand the system performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance visualizations\n",
    "print(\"📊 SYSTEM PERFORMANCE VISUALIZATION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if signal_analyses and system_performance:\n",
    "    # Extract data for visualization\n",
    "    fault_types = [analysis.get(\"true_fault_type\", \"unknown\") for analysis in signal_analyses]\n",
    "    detected_types = [analysis.get(\"final_assessment\", {}).get(\"fault_type\", \"unknown\") for analysis in signal_analyses]\n",
    "    confidences = [analysis.get(\"final_assessment\", {}).get(\"confidence\", 0.0) for analysis in signal_analyses]\n",
    "    processing_times = [analysis.get(\"total_processing_time\", 0.0) for analysis in signal_analyses]\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Accuracy by Fault Type\n",
    "    unique_faults = list(set(fault_types))\n",
    "    accuracy_by_fault = []\n",
    "    \n",
    "    for fault in unique_faults:\n",
    "        fault_indices = [i for i, f in enumerate(fault_types) if f == fault]\n",
    "        fault_detected = [detected_types[i] for i in fault_indices]\n",
    "        accuracy = sum(1 for d in fault_detected if d.lower() == fault.lower()) / len(fault_detected)\n",
    "        accuracy_by_fault.append(accuracy * 100)\n",
    "    \n",
    "    bars1 = ax1.bar(unique_faults, accuracy_by_fault, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
    "    ax1.set_title('Accuracy by Fault Type')\n",
    "    ax1.set_ylabel('Accuracy (%)')\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars1, accuracy_by_fault):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{acc:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Confidence Distribution\n",
    "    ax2.hist(confidences, bins=10, color='lightblue', alpha=0.7, edgecolor='black')\n",
    "    ax2.axvline(np.mean(confidences), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(confidences):.3f}')\n",
    "    ax2.set_title('Confidence Score Distribution')\n",
    "    ax2.set_xlabel('Confidence Score')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Processing Time Analysis\n",
    "    signal_numbers = list(range(1, len(processing_times) + 1))\n",
    "    ax3.plot(signal_numbers, processing_times, 'o-', color='green', markersize=8)\n",
    "    ax3.axhline(np.mean(processing_times), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(processing_times):.2f}s')\n",
    "    ax3.set_title('Processing Time per Signal')\n",
    "    ax3.set_xlabel('Signal Number')\n",
    "    ax3.set_ylabel('Processing Time (s)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. System Performance Summary\n",
    "    metrics = ['Accuracy', 'Avg Confidence', 'Integration Score']\n",
    "    values = [\n",
    "        system_performance.get('accuracy', 0.0) * 100,\n",
    "        system_performance.get('average_confidence', 0.0) * 100,\n",
    "        system_performance.get('integration_score', 0.0) * 100\n",
    "    ]\n",
    "    \n",
    "    bars4 = ax4.bar(metrics, values, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "    ax4.set_title('Overall System Performance')\n",
    "    ax4.set_ylabel('Score (%)')\n",
    "    ax4.set_ylim(0, 100)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars4, values):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{val:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n📈 Performance Summary Statistics:\")\n",
    "    print(f\"   • Mean Confidence: {np.mean(confidences):.3f} ± {np.std(confidences):.3f}\")\n",
    "    print(f\"   • Mean Processing Time: {np.mean(processing_times):.2f}s ± {np.std(processing_times):.2f}s\")\n",
    "    print(f\"   • Min/Max Processing Time: {np.min(processing_times):.2f}s / {np.max(processing_times):.2f}s\")\n",
    "    print(f\"   • Confidence Range: {np.min(confidences):.3f} - {np.max(confidences):.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Insufficient data for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Part 5.6: Key Takeaways and Production Insights\n",
    "\n",
    "Let's summarize the **complete tutorial series** and understand what we've accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎓 COMPLETE TUTORIAL SERIES SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tutorial_summary = {\n",
    "    \"📚 Part 1 - Foundation\": {\n",
    "        \"concept\": \"Multi-provider LLM integration\",\n",
    "        \"example\": \"Code-to-LaTeX conversion agents\",\n",
    "        \"key_learning\": \"LLM provider abstraction and intelligent reasoning\",\n",
    "        \"production_impact\": \"Flexible AI backend supporting multiple providers\"\n",
    "    },\n",
    "    \"🤖 Part 2 - Multi-Agent Router\": {\n",
    "        \"concept\": \"Intelligent task routing and agent orchestration\", \n",
    "        \"example\": \"Research tool integration (ArXiv, Semantic Scholar, CrossRef)\",\n",
    "        \"key_learning\": \"Agent specialization and parallel task execution\",\n",
    "        \"production_impact\": \"Scalable agent architecture for complex workflows\"\n",
    "    },\n",
    "    \"🔄 Part 3 - Research Integration\": {\n",
    "        \"concept\": \"Reflection-based research with iterative improvement\",\n",
    "        \"example\": \"Automated literature review with knowledge gap identification\",\n",
    "        \"key_learning\": \"Self-improving AI systems with research capabilities\",\n",
    "        \"production_impact\": \"Continuous knowledge updates and self-optimization\"\n",
    "    },\n",
    "    \"🕸️ Part 4 - DAG Architecture\": {\n",
    "        \"concept\": \"Directed acyclic graphs for complex workflows\",\n",
    "        \"example\": \"Parallel signal processing and systematic literature reviews\",\n",
    "        \"key_learning\": \"Workflow optimization and parallel execution\",\n",
    "        \"production_impact\": \"High-performance processing with resource optimization\"\n",
    "    },\n",
    "    \"🏭 Part 5 - Complete System\": {\n",
    "        \"concept\": \"Integrated PHMGA system for industrial applications\",\n",
    "        \"example\": \"End-to-end bearing fault diagnosis\",\n",
    "        \"key_learning\": \"Production deployment and system validation\",\n",
    "        \"production_impact\": \"Complete industrial AI system ready for deployment\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n📋 Tutorial Series Overview:\")\n",
    "for part, details in tutorial_summary.items():\n",
    "    print(f\"\\n{part}:\")\n",
    "    print(f\"   • Concept: {details['concept']}\")\n",
    "    print(f\"   • Example: {details['example']}\")\n",
    "    print(f\"   • Key Learning: {details['key_learning']}\")\n",
    "    print(f\"   • Production Impact: {details['production_impact']}\")\n",
    "\n",
    "# Integration achievements\n",
    "print(\"\\n🔗 Integration Achievements:\")\n",
    "achievements = [\n",
    "    \"Seamless data flow between all system components\",\n",
    "    \"Unified configuration management across all parts\",\n",
    "    \"Comprehensive error handling and graceful degradation\",\n",
    "    \"Real-time performance monitoring and validation\",\n",
    "    \"Scalable architecture supporting production deployment\",\n",
    "    \"Research-driven continuous improvement capabilities\"\n",
    "]\n",
    "\n",
    "for i, achievement in enumerate(achievements, 1):\n",
    "    print(f\"   {i}. {achievement}\")\n",
    "\n",
    "# Production readiness assessment\n",
    "print(\"\\n🏭 Production Readiness Assessment:\")\n",
    "if validation_results and validation_results.get(\"overall_validation\", {}).get(\"passed\", False):\n",
    "    print(\"   ✅ System passed all validation criteria\")\n",
    "    print(\"   ✅ Performance metrics meet industrial standards\")\n",
    "    print(\"   ✅ Error handling and recovery mechanisms in place\")\n",
    "    print(\"   ✅ Comprehensive monitoring and logging implemented\")\n",
    "    print(\"   \\n   🎉 System is ready for production deployment!\")\n",
    "else:\n",
    "    print(\"   ⚠️ Some validation criteria need attention\")\n",
    "    print(\"   ✅ Core functionality demonstrated successfully\")\n",
    "    print(\"   ✅ System architecture is production-viable\")\n",
    "    print(\"   \\n   📝 System shows strong potential with minor improvements needed\")\n",
    "\n",
    "# Show final system statistics\n",
    "final_status = phmga_system.get_system_status()\n",
    "print(f\"\\n📊 Final System Statistics:\")\n",
    "stats = final_status['processing_statistics']\n",
    "print(f\"   • Total Signals Processed: {stats['total_signals_processed']}\")\n",
    "print(f\"   • Total Faults Detected: {stats['total_faults_detected']}\")\n",
    "print(f\"   • Average Processing Time: {stats['average_processing_time']:.3f}s\")\n",
    "print(f\"   • Session Duration: {final_status['uptime_seconds']:.2f}s\")\n",
    "\n",
    "if case_results:\n",
    "    print(f\"   • Case Study Accuracy: {system_performance.get('accuracy', 0.0):.1%}\")\n",
    "    print(f\"   • System Integration Score: {system_performance.get('integration_score', 0.0):.3f}\")\n",
    "\n",
    "print(f\"\\n🎓 Tutorial completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\n🚀 Congratulations! You have successfully built and deployed\")\n",
    "print(\"   a complete industrial AI system using the PHMGA architecture!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`★ Insight ─────────────────────────────────────`\n",
    "- **System Architecture Mastery**: You've learned to build complex AI systems by composing specialized components, each solving a specific aspect of the overall problem\n",
    "- **Production-Grade Implementation**: The tutorial demonstrates real-world considerations including validation, monitoring, error handling, and performance optimization\n",
    "- **Research-Production Bridge**: The integrated system shows how to maintain continuous improvement through automated research integration while serving production workloads\n",
    "`─────────────────────────────────────────────────`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔬 Exercises for Advanced Practice\n",
    "\n",
    "Now that you've mastered the complete PHMGA system, try these advanced exercises:\n",
    "\n",
    "### Exercise 1: Domain Adaptation\n",
    "Adapt the PHMGA system for a different industrial domain:\n",
    "- **Motor Current Analysis**: Modify for electrical motor fault diagnosis\n",
    "- **Pump Vibration Monitoring**: Adapt for centrifugal pump health monitoring\n",
    "- **Gearbox Condition Assessment**: Extend for gearbox wear detection\n",
    "\n",
    "### Exercise 2: Real-Time Deployment\n",
    "Implement real-time capabilities:\n",
    "- **Streaming Data Processing**: Integrate with Apache Kafka or similar\n",
    "- **Real-Time Alerting**: Implement immediate notification systems\n",
    "- **Dashboard Development**: Create web-based monitoring dashboards\n",
    "- **Edge Computing**: Deploy lightweight versions for edge devices\n",
    "\n",
    "### Exercise 3: Advanced Research Integration\n",
    "Enhance the research capabilities:\n",
    "- **Automated Paper Analysis**: Implement PDF parsing and analysis\n",
    "- **Method Benchmarking**: Compare new methods against current implementation\n",
    "- **Automatic Code Generation**: Generate signal processing operators from research papers\n",
    "- **Knowledge Graph**: Build knowledge graphs from research findings\n",
    "\n",
    "### Exercise 4: Production Scaling\n",
    "Scale the system for enterprise deployment:\n",
    "- **Microservices Architecture**: Break down into containerized microservices\n",
    "- **Load Balancing**: Implement intelligent load distribution\n",
    "- **Database Integration**: Add persistent storage for historical analysis\n",
    "- **Multi-Tenant Support**: Enable multiple client organizations\n",
    "\n",
    "### Exercise 5: Advanced Validation\n",
    "Implement comprehensive validation frameworks:\n",
    "- **Cross-Validation**: Implement k-fold cross-validation for model assessment\n",
    "- **Uncertainty Quantification**: Add Bayesian uncertainty estimation\n",
    "- **Explainable AI**: Implement feature importance and decision explanations\n",
    "- **Regulatory Compliance**: Add audit trails and compliance reporting\n",
    "\n",
    "## 🌟 Next Steps and Career Applications\n",
    "\n",
    "With this comprehensive knowledge, you can:\n",
    "\n",
    "### 🏢 Industrial Applications\n",
    "- **Manufacturing**: Predictive maintenance for production lines\n",
    "- **Energy**: Wind turbine and power plant monitoring\n",
    "- **Transportation**: Railway and automotive component monitoring\n",
    "- **Aerospace**: Aircraft component health monitoring\n",
    "\n",
    "### 🔬 Research Directions\n",
    "- **Federated Learning**: Distributed learning across multiple sites\n",
    "- **Transfer Learning**: Adaptation to new equipment types\n",
    "- **Multimodal Analysis**: Combining vibration, thermal, and acoustic data\n",
    "- **Digital Twins**: Creating comprehensive system models\n",
    "\n",
    "### 💼 Career Opportunities\n",
    "- **AI/ML Engineer**: Specialized in industrial AI systems\n",
    "- **Research Scientist**: Academic or industrial research roles\n",
    "- **Solutions Architect**: Designing enterprise AI solutions\n",
    "- **Technical Consultant**: Helping companies implement AI systems\n",
    "\n",
    "## 📚 Recommended Further Reading\n",
    "\n",
    "- [Industrial AI Implementation Guide](https://example.com/) \n",
    "- [Prognostics and Health Management Handbook](https://example.com/)\n",
    "- [Multi-Agent Systems in Practice](https://example.com/)\n",
    "- [Graph-Based Workflow Orchestration](https://example.com/)\n",
    "- [Research-Driven AI Development](https://example.com/)\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 Congratulations on completing the complete PHMGA Tutorial Series!**\n",
    "\n",
    "You have successfully mastered:\n",
    "- Multi-provider LLM integration\n",
    "- Intelligent multi-agent systems\n",
    "- Research-driven AI development\n",
    "- DAG-based workflow optimization\n",
    "- Production-ready system deployment\n",
    "\n",
    "You're now equipped to build sophisticated AI systems for industrial applications and contribute to the future of intelligent manufacturing and predictive maintenance!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}