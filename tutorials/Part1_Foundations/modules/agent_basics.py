"""
AgentåŸºç¡€æ¦‚å¿µæ¨¡å—

æœ¬æ¨¡å—å®ç°äº†ä»ç®€å•è§„åˆ™Agentåˆ°LLMå¢å¼ºAgentçš„æ¼”è¿›è¿‡ç¨‹ï¼Œ
å¸®åŠ©ç†è§£Agentçš„æ ¸å¿ƒæ¦‚å¿µå’Œå‘å±•å†ç¨‹ã€‚
"""

from typing import Dict, List, Any, Optional
from abc import ABC, abstractmethod
import time
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BaseAgent(ABC):
    """AgentåŸºç¡€æŠ½è±¡ç±»"""
    
    def __init__(self, name: str):
        self.name = name
        self.memory: List[Dict[str, Any]] = []
        self.step_count = 0
        
    @abstractmethod
    def perceive(self, input_data: Any) -> Any:
        """æ„ŸçŸ¥ç¯å¢ƒ"""
        pass
    
    @abstractmethod
    def think(self, perception: Any) -> Any:
        """æ€è€ƒå’Œå†³ç­–"""
        pass
    
    @abstractmethod
    def act(self, decision: Any) -> Any:
        """æ‰§è¡Œè¡ŒåŠ¨"""
        pass
    
    def run_cycle(self, input_data: Any) -> Any:
        """å®Œæ•´çš„Agentè¿è¡Œå¾ªç¯"""
        self.step_count += 1
        
        # æ„ŸçŸ¥ -> æ€è€ƒ -> è¡ŒåŠ¨
        perception = self.perceive(input_data)
        decision = self.think(perception)
        action = self.act(decision)
        
        # è®°å½•åˆ°è®°å¿†
        self.memory.append({
            "step": self.step_count,
            "input": input_data,
            "perception": perception,
            "decision": decision,
            "action": action,
            "timestamp": time.time()
        })
        
        return action


class SimpleRuleAgent(BaseAgent):
    """ç®€å•è§„åˆ™åŸºç¡€çš„Agent
    
    è¿™æ˜¯æœ€åŸºæœ¬çš„Agentå®ç°ï¼Œä½¿ç”¨é¢„å®šä¹‰çš„è§„åˆ™è¿›è¡Œå†³ç­–ã€‚
    é€‚åˆç”¨æ¥ç†è§£Agentçš„åŸºæœ¬æ¦‚å¿µå’Œå·¥ä½œæµç¨‹ã€‚
    """
    
    def __init__(self, name: str, rules: Optional[Dict[str, str]] = None):
        super().__init__(name)
        self.rules = rules or {
            "error": "fix_error",
            "warning": "investigate", 
            "normal": "continue",
            "unknown": "ask_for_help"
        }
    
    def perceive(self, input_data: str) -> Dict[str, Any]:
        """æ„ŸçŸ¥è¾“å…¥å¹¶æå–å…³é”®ä¿¡æ¯"""
        perception = {
            "raw_input": input_data,
            "input_lower": input_data.lower(),
            "keywords": [],
            "severity": "normal"
        }
        
        # å…³é”®è¯æå–
        keywords = ["error", "warning", "fault", "alarm", "critical", "normal"]
        perception["keywords"] = [kw for kw in keywords if kw in perception["input_lower"]]
        
        # ä¸¥é‡ç¨‹åº¦åˆ¤æ–­
        if "error" in perception["input_lower"] or "critical" in perception["input_lower"]:
            perception["severity"] = "error"
        elif "warning" in perception["input_lower"] or "fault" in perception["input_lower"]:
            perception["severity"] = "warning"
        
        logger.info(f"ğŸ” {self.name} æ„ŸçŸ¥åˆ°: {input_data} -> ä¸¥é‡ç¨‹åº¦: {perception['severity']}")
        return perception
    
    def think(self, perception: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºè§„åˆ™è¿›è¡Œå†³ç­–"""
        severity = perception["severity"]
        action = self.rules.get(severity, self.rules["unknown"])
        
        decision = {
            "severity": severity,
            "action": action,
            "confidence": 0.8 if action != self.rules["unknown"] else 0.3,
            "reasoning": f"æ ¹æ®ä¸¥é‡ç¨‹åº¦'{severity}'é€‰æ‹©è¡ŒåŠ¨'{action}'"
        }
        
        logger.info(f"ğŸ’­ {self.name} å†³ç­–: {decision['action']} (ç½®ä¿¡åº¦: {decision['confidence']})")
        return decision
    
    def act(self, decision: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå†³ç­–"""
        action_map = {
            "fix_error": "å¯åŠ¨é”™è¯¯ä¿®å¤æµç¨‹ï¼Œé€šçŸ¥ç»´æŠ¤å›¢é˜Ÿ",
            "investigate": "æ·±å…¥åˆ†æé—®é¢˜ï¼Œæ”¶é›†æ›´å¤šæ•°æ®", 
            "continue": "ç»§ç»­æ­£å¸¸è¿è¡Œï¼Œä¿æŒç›‘æ§",
            "ask_for_help": "è¯·æ±‚äººå·¥ä»‹å…¥ï¼Œå¯»æ±‚ä¸“å®¶æ„è§"
        }
        
        action_description = action_map.get(decision["action"], "æœªçŸ¥æ“ä½œ")
        
        result = {
            "action": decision["action"],
            "description": action_description,
            "status": "completed",
            "timestamp": time.time()
        }
        
        logger.info(f"ğŸ¬ {self.name} æ‰§è¡Œ: {action_description}")
        return result


class ReactiveAgent(BaseAgent):
    """ååº”å¼Agent
    
    èƒ½å¤Ÿæ ¹æ®ç¯å¢ƒå˜åŒ–åšå‡ºå¿«é€Ÿå“åº”çš„Agentã€‚
    å…·æœ‰æ›´å¤æ‚çš„æ„ŸçŸ¥å’Œå†³ç­–èƒ½åŠ›ã€‚
    """
    
    def __init__(self, name: str, response_threshold: float = 0.5):
        super().__init__(name)
        self.response_threshold = response_threshold
        self.environmental_state = {"temperature": 0.5, "pressure": 0.5, "vibration": 0.5}
    
    def perceive(self, input_data: Dict[str, float]) -> Dict[str, Any]:
        """æ„ŸçŸ¥å¤šç»´ç¯å¢ƒæ•°æ®"""
        # æ›´æ–°ç¯å¢ƒçŠ¶æ€
        for key, value in input_data.items():
            if key in self.environmental_state:
                self.environmental_state[key] = value
        
        # è®¡ç®—å¼‚å¸¸ç¨‹åº¦
        anomaly_score = max(abs(v - 0.5) for v in self.environmental_state.values())
        
        perception = {
            "environmental_state": self.environmental_state.copy(),
            "anomaly_score": anomaly_score,
            "requires_action": anomaly_score > self.response_threshold,
            "most_abnormal": max(self.environmental_state.items(), key=lambda x: abs(x[1] - 0.5))
        }
        
        logger.info(f"ğŸ” {self.name} ç¯å¢ƒæ„ŸçŸ¥: å¼‚å¸¸åˆ†æ•°={anomaly_score:.3f}")
        return perception
    
    def think(self, perception: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºç¯å¢ƒçŠ¶æ€è¿›è¡Œé€‚åº”æ€§å†³ç­–"""
        if not perception["requires_action"]:
            decision = {
                "action": "monitor",
                "priority": "low",
                "reasoning": "ç³»ç»ŸçŠ¶æ€æ­£å¸¸ï¼Œç»§ç»­ç›‘æ§"
            }
        else:
            abnormal_param, abnormal_value = perception["most_abnormal"]
            
            if abnormal_value > 0.8:
                action, priority = "emergency_shutdown", "critical"
                reasoning = f"{abnormal_param}ä¸¥é‡è¶…æ ‡({abnormal_value:.3f})ï¼Œéœ€è¦ç´§æ€¥åœæœº"
            elif abnormal_value > 0.7:
                action, priority = "reduce_load", "high"
                reasoning = f"{abnormal_param}è¶…æ ‡({abnormal_value:.3f})ï¼Œé™ä½è´Ÿè½½"
            else:
                action, priority = "adjust_parameters", "medium"
                reasoning = f"{abnormal_param}è½»å¾®å¼‚å¸¸({abnormal_value:.3f})ï¼Œè°ƒæ•´å‚æ•°"
            
            decision = {
                "action": action,
                "priority": priority,
                "target_parameter": abnormal_param,
                "abnormal_value": abnormal_value,
                "reasoning": reasoning
            }
        
        logger.info(f"ğŸ’­ {self.name} å†³ç­–: {decision['action']} ({decision['priority']}ä¼˜å…ˆçº§)")
        return decision
    
    def act(self, decision: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé€‚åº”æ€§è¡ŒåŠ¨"""
        action_effects = {
            "monitor": lambda: "ç»§ç»­ç›‘æ§ç³»ç»ŸçŠ¶æ€",
            "adjust_parameters": lambda: f"è°ƒæ•´{decision.get('target_parameter', 'å‚æ•°')}",
            "reduce_load": lambda: f"é™ä½{decision.get('target_parameter', 'ç³»ç»Ÿ')}è´Ÿè½½",
            "emergency_shutdown": lambda: "æ‰§è¡Œç´§æ€¥åœæœºç¨‹åº"
        }
        
        action = decision["action"]
        effect = action_effects.get(action, lambda: "æœªçŸ¥æ“ä½œ")()
        
        result = {
            "action": action,
            "effect": effect,
            "priority": decision["priority"],
            "success": True,
            "timestamp": time.time()
        }
        
        logger.info(f"ğŸ¬ {self.name} æ‰§è¡Œ: {effect}")
        return result


class LearningAgent(BaseAgent):
    """å­¦ä¹ å‹Agent
    
    èƒ½å¤Ÿä»ç»éªŒä¸­å­¦ä¹ å¹¶æ”¹è¿›å†³ç­–çš„Agentã€‚
    å…·æœ‰ç®€å•çš„å­¦ä¹ å’Œé€‚åº”èƒ½åŠ›ã€‚
    """
    
    def __init__(self, name: str, learning_rate: float = 0.1):
        super().__init__(name)
        self.learning_rate = learning_rate
        self.knowledge_base = {}
        self.success_history = []
    
    def perceive(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ„ŸçŸ¥å¹¶åŸºäºå†å²ç»éªŒè§£é‡Š"""
        # åŸºç¡€æ„ŸçŸ¥
        situation_key = self._extract_situation_key(input_data)
        
        perception = {
            "raw_input": input_data,
            "situation_key": situation_key,
            "historical_context": self.knowledge_base.get(situation_key, {}),
            "confidence": self._calculate_perception_confidence(situation_key)
        }
        
        logger.info(f"ğŸ” {self.name} æ„ŸçŸ¥æƒ…å†µ: {situation_key} (ç½®ä¿¡åº¦: {perception['confidence']:.3f})")
        return perception
    
    def think(self, perception: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºå­¦ä¹ ç»éªŒè¿›è¡Œå†³ç­–"""
        situation_key = perception["situation_key"]
        historical_context = perception["historical_context"]
        
        if historical_context and "best_action" in historical_context:
            # ä½¿ç”¨å­¦ä¹ åˆ°çš„æœ€ä½³è¡ŒåŠ¨
            action = historical_context["best_action"]
            confidence = historical_context.get("success_rate", 0.5)
            reasoning = f"åŸºäºå†å²ç»éªŒï¼Œ{action}åœ¨ç±»ä¼¼æƒ…å†µä¸‹æˆåŠŸç‡{confidence:.1%}"
        else:
            # æ¢ç´¢æ€§å†³ç­–
            action = self._explore_action(perception)
            confidence = 0.3
            reasoning = "æ–°æƒ…å†µï¼Œé‡‡ç”¨æ¢ç´¢æ€§ç­–ç•¥"
        
        decision = {
            "action": action,
            "confidence": confidence,
            "reasoning": reasoning,
            "situation_key": situation_key,
            "is_exploration": "best_action" not in historical_context
        }
        
        logger.info(f"ğŸ’­ {self.name} å†³ç­–: {action} (ç½®ä¿¡åº¦: {confidence:.3f})")
        return decision
    
    def act(self, decision: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè¡ŒåŠ¨å¹¶å­¦ä¹ ç»“æœ"""
        action = decision["action"]
        
        # æ¨¡æ‹Ÿè¡ŒåŠ¨æ‰§è¡Œå’Œç»“æœ
        success = self._simulate_action_result(action)
        
        result = {
            "action": action,
            "success": success,
            "timestamp": time.time()
        }
        
        # å­¦ä¹ æ›´æ–°
        self._update_knowledge(decision["situation_key"], action, success)
        
        logger.info(f"ğŸ¬ {self.name} æ‰§è¡Œ: {action} -> {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        return result
    
    def _extract_situation_key(self, input_data: Dict[str, Any]) -> str:
        """æå–æƒ…å†µç‰¹å¾é”®"""
        # ç®€åŒ–çš„ç‰¹å¾æå–
        if isinstance(input_data, dict) and "type" in input_data:
            return input_data["type"]
        else:
            return "general"
    
    def _calculate_perception_confidence(self, situation_key: str) -> float:
        """è®¡ç®—æ„ŸçŸ¥ç½®ä¿¡åº¦"""
        if situation_key in self.knowledge_base:
            experience_count = self.knowledge_base[situation_key].get("count", 0)
            return min(1.0, 0.3 + experience_count * 0.1)
        return 0.3
    
    def _explore_action(self, perception: Dict[str, Any]) -> str:
        """æ¢ç´¢æ€§è¡ŒåŠ¨é€‰æ‹©"""
        possible_actions = ["analyze", "wait", "intervene", "escalate"]
        return possible_actions[len(self.memory) % len(possible_actions)]
    
    def _simulate_action_result(self, action: str) -> bool:
        """æ¨¡æ‹Ÿè¡ŒåŠ¨ç»“æœ"""
        # ç®€å•çš„æˆåŠŸæ¦‚ç‡æ¨¡æ‹Ÿ
        success_probs = {
            "analyze": 0.8,
            "wait": 0.6,
            "intervene": 0.7,
            "escalate": 0.9
        }
        import random
        return random.random() < success_probs.get(action, 0.5)
    
    def _update_knowledge(self, situation_key: str, action: str, success: bool):
        """æ›´æ–°çŸ¥è¯†åº“"""
        if situation_key not in self.knowledge_base:
            self.knowledge_base[situation_key] = {"actions": {}, "count": 0}
        
        kb_entry = self.knowledge_base[situation_key]
        kb_entry["count"] += 1
        
        if action not in kb_entry["actions"]:
            kb_entry["actions"][action] = {"attempts": 0, "successes": 0}
        
        action_stats = kb_entry["actions"][action]
        action_stats["attempts"] += 1
        if success:
            action_stats["successes"] += 1
        
        # æ›´æ–°æœ€ä½³è¡ŒåŠ¨
        best_action = max(
            kb_entry["actions"].items(),
            key=lambda x: x[1]["successes"] / max(x[1]["attempts"], 1)
        )
        
        kb_entry["best_action"] = best_action[0]
        kb_entry["success_rate"] = best_action[1]["successes"] / max(best_action[1]["attempts"], 1)


def demonstrate_agent_evolution():
    """æ¼”ç¤ºAgentçš„æ¼”è¿›è¿‡ç¨‹"""
    print("ğŸ¤– Agentæ¼”è¿›æ¼”ç¤º")
    print("=" * 50)
    
    # 1. ç®€å•è§„åˆ™Agent
    print("\n1ï¸âƒ£ ç®€å•è§„åˆ™Agent:")
    rule_agent = SimpleRuleAgent("è§„åˆ™ç›‘æ§Agent")
    
    test_inputs = [
        "System running normally",
        "Warning: temperature high", 
        "Critical error in pump system",
        "Unknown sensor reading"
    ]
    
    for inp in test_inputs:
        result = rule_agent.run_cycle(inp)
        print(f"  è¾“å…¥: '{inp}' -> è¡ŒåŠ¨: {result['action']}")
    
    # 2. ååº”å¼Agent
    print("\n2ï¸âƒ£ ååº”å¼Agent:")
    reactive_agent = ReactiveAgent("ç¯å¢ƒååº”Agent")
    
    env_inputs = [
        {"temperature": 0.3, "pressure": 0.4},
        {"temperature": 0.8, "vibration": 0.9},
        {"pressure": 0.95, "temperature": 0.7}
    ]
    
    for env in env_inputs:
        result = reactive_agent.run_cycle(env)
        print(f"  ç¯å¢ƒ: {env} -> è¡ŒåŠ¨: {result['action']}")
    
    # 3. å­¦ä¹ å‹Agent
    print("\n3ï¸âƒ£ å­¦ä¹ å‹Agent:")
    learning_agent = LearningAgent("è‡ªé€‚åº”å­¦ä¹ Agent")
    
    learning_inputs = [
        {"type": "sensor_fault", "severity": 0.6},
        {"type": "sensor_fault", "severity": 0.8},
        {"type": "network_issue", "severity": 0.5}
    ]
    
    for inp in learning_inputs:
        result = learning_agent.run_cycle(inp)
        print(f"  å­¦ä¹ : {inp} -> è¡ŒåŠ¨: {result['action']} ({'æˆåŠŸ' if result['success'] else 'å¤±è´¥'})")
    
    print(f"\nğŸ“š å­¦ä¹ AgentçŸ¥è¯†åº“: {learning_agent.knowledge_base}")
    
    return rule_agent, reactive_agent, learning_agent


if __name__ == "__main__":
    demonstrate_agent_evolution()