"""
LangGraphå·¥ä½œæµæ¨¡å—

æœ¬æ¨¡å—å±•ç¤ºå¦‚ä½•ä½¿ç”¨LangGraphåˆ›å»ºå¤æ‚çš„å·¥ä½œæµï¼ŒåŒ…æ‹¬ï¼š
- å¤šèŠ‚ç‚¹å·¥ä½œæµ
- æ¡ä»¶åˆ†æ”¯å’Œè·¯ç”±
- å¹¶è¡Œå¤„ç†
- é”™è¯¯å¤„ç†å’Œé‡è¯•
"""

from typing import Dict, Any, List, TypedDict, Annotated
import operator
import time

# ä¾èµ–æ£€æŸ¥å’Œå›é€€å¤„ç†
try:
    from langgraph.graph import StateGraph, END
    LANGGRAPH_AVAILABLE = True
    print("âœ… LangGraphæ¨¡å—å¯ç”¨")
except ImportError:
    print("âš ï¸ LangGraphæ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå®ç°")
    LANGGRAPH_AVAILABLE = False
    
    # æ¨¡æ‹ŸLangGraphç±»
    class MockStateGraph:
        def __init__(self, state_schema):
            self.state_schema = state_schema
            self.nodes = {}
            self.edges = []
        
        def add_node(self, name, func):
            self.nodes[name] = func
        
        def add_edge(self, from_node, to_node):
            self.edges.append((from_node, to_node))
        
        def set_entry_point(self, node_name):
            self.entry_point = node_name
        
        def compile(self):
            return MockCompiledGraph(self)
    
    class MockCompiledGraph:
        def __init__(self, graph):
            self.graph = graph
        
        def invoke(self, input_data):
            # ç®€å•çš„æ¨¡æ‹Ÿæ‰§è¡Œ
            return {
                "result": "æ¨¡æ‹ŸLangGraphæ‰§è¡Œç»“æœ",
                "steps": list(self.graph.nodes.keys()),
                "mock": True
            }
    
    StateGraph = MockStateGraph
    END = "END"


class WorkflowState(TypedDict):
    """å·¥ä½œæµçŠ¶æ€å®šä¹‰"""
    input_data: Dict[str, Any]
    processing_history: Annotated[List[str], operator.add]
    current_node: str
    results: Dict[str, Any]
    should_continue: bool


class AdvancedWorkflowState(TypedDict):
    """é«˜çº§å·¥ä½œæµçŠ¶æ€"""
    sensor_readings: Dict[str, float]
    analysis_path: str
    processing_steps: Annotated[List[str], operator.add]
    parallel_results: Dict[str, Any]
    final_decision: str
    confidence_level: float


class PHMAnalysisWorkflow:
    """PHMåˆ†æå·¥ä½œæµ"""
    
    def __init__(self):
        self.workflow = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºå·¥ä½œæµå›¾"""
        
        def preprocessing_node(state: WorkflowState) -> Dict[str, Any]:
            """æ•°æ®é¢„å¤„ç†èŠ‚ç‚¹"""
            print("ğŸ”„ æ‰§è¡Œæ•°æ®é¢„å¤„ç†...")
            
            # æ¨¡æ‹Ÿé¢„å¤„ç†é€»è¾‘
            raw_data = state["input_data"].get("sensor_data", {})
            processed_data = {k: v * 1.1 for k, v in raw_data.items() if isinstance(v, (int, float))}
            
            return {
                "processing_history": ["æ•°æ®é¢„å¤„ç†å®Œæˆ"],
                "current_node": "preprocessing",
                "results": {"processed_data": processed_data}
            }
        
        def feature_extraction_node(state: WorkflowState) -> Dict[str, Any]:
            """ç‰¹å¾æå–èŠ‚ç‚¹"""
            print("ğŸ” æ‰§è¡Œç‰¹å¾æå–...")
            
            processed_data = state["results"].get("processed_data", {})
            features = {
                "mean_value": sum(processed_data.values()) / len(processed_data) if processed_data else 0,
                "max_value": max(processed_data.values()) if processed_data else 0,
                "feature_count": len(processed_data)
            }
            
            return {
                "processing_history": ["ç‰¹å¾æå–å®Œæˆ"],
                "current_node": "feature_extraction",
                "results": {**state["results"], "features": features}
            }
        
        def classification_node(state: WorkflowState) -> Dict[str, Any]:
            """åˆ†ç±»è¯Šæ–­èŠ‚ç‚¹"""
            print("ğŸ¯ æ‰§è¡Œæ•…éšœè¯Šæ–­...")
            
            features = state["results"].get("features", {})
            mean_val = features.get("mean_value", 0)
            
            # ç®€å•çš„åˆ†ç±»é€»è¾‘
            if mean_val > 80:
                diagnosis = "ä¸¥é‡æ•…éšœ"
                confidence = 0.9
            elif mean_val > 60:
                diagnosis = "è½»å¾®å¼‚å¸¸"
                confidence = 0.7
            else:
                diagnosis = "æ­£å¸¸çŠ¶æ€"
                confidence = 0.95
            
            return {
                "processing_history": [f"è¯Šæ–­å®Œæˆ: {diagnosis} (ç½®ä¿¡åº¦: {confidence:.2f})"],
                "current_node": "classification",
                "results": {**state["results"], "diagnosis": diagnosis, "confidence": confidence},
                "should_continue": False
            }
        
        # æ„å»ºå›¾
        workflow = StateGraph(WorkflowState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("preprocess", preprocessing_node)
        workflow.add_node("extract_features", feature_extraction_node)
        workflow.add_node("classify", classification_node)
        
        # å®šä¹‰æ‰§è¡Œé¡ºåº
        workflow.set_entry_point("preprocess")
        workflow.add_edge("preprocess", "extract_features")
        workflow.add_edge("extract_features", "classify")
        workflow.add_edge("classify", END)
        
        return workflow.compile()
    
    def analyze(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ†æ"""
        initial_state = {
            "input_data": input_data,
            "processing_history": ["å·¥ä½œæµå¯åŠ¨"],
            "current_node": "start",
            "results": {},
            "should_continue": True
        }
        
        result = self.workflow.invoke(initial_state)
        return result


class AdvancedPHMWorkflow:
    """é«˜çº§PHMå·¥ä½œæµï¼Œæ”¯æŒæ¡ä»¶åˆ†æ”¯å’Œå¹¶è¡Œå¤„ç†"""
    
    def __init__(self):
        self.workflow = self._build_advanced_workflow()
    
    def _build_advanced_workflow(self) -> StateGraph:
        """æ„å»ºé«˜çº§å·¥ä½œæµ"""
        
        def data_validation_node(state: AdvancedWorkflowState) -> Dict[str, Any]:
            """æ•°æ®éªŒè¯èŠ‚ç‚¹"""
            readings = state["sensor_readings"]
            
            # æ£€æŸ¥æ•°æ®è´¨é‡
            missing_sensors = []
            required_sensors = ["temperature", "vibration", "pressure"]
            
            for sensor in required_sensors:
                if sensor not in readings or readings[sensor] is None:
                    missing_sensors.append(sensor)
            
            if missing_sensors:
                analysis_path = "simple_analysis"
                step_msg = f"æ•°æ®ä¸å®Œæ•´ï¼ˆç¼ºå°‘: {missing_sensors}ï¼‰ï¼Œä½¿ç”¨ç®€å•åˆ†æ"
            else:
                analysis_path = "full_analysis"
                step_msg = "æ•°æ®å®Œæ•´ï¼Œä½¿ç”¨å®Œæ•´åˆ†ææµç¨‹"
            
            return {
                "analysis_path": analysis_path,
                "processing_steps": [step_msg]
            }
        
        def simple_analysis_node(state: AdvancedWorkflowState) -> Dict[str, Any]:
            """ç®€å•åˆ†æèŠ‚ç‚¹"""
            readings = state["sensor_readings"]
            
            avg_value = sum(v for v in readings.values() if v is not None) / len(readings)
            
            if avg_value > 70:
                decision = "éœ€è¦æ³¨æ„ï¼šä¼ æ„Ÿå™¨è¯»æ•°åé«˜"
                confidence = 0.6
            else:
                decision = "çŠ¶æ€æ­£å¸¸"
                confidence = 0.8
            
            return {
                "processing_steps": ["æ‰§è¡Œç®€å•åˆ†æ"],
                "final_decision": decision,
                "confidence_level": confidence
            }
        
        def parallel_analysis_node(state: AdvancedWorkflowState) -> Dict[str, Any]:
            """å¹¶è¡Œåˆ†æèŠ‚ç‚¹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
            readings = state["sensor_readings"]
            
            # æ¨¡æ‹Ÿå¹¶è¡Œå¤„ç†çš„å¤šä¸ªåˆ†æ
            temp_analysis = {
                "result": "æ­£å¸¸" if readings.get("temperature", 0) < 80 else "å¼‚å¸¸",
                "score": 0.9 if readings.get("temperature", 0) < 80 else 0.3
            }
            
            vibration_analysis = {
                "result": "æ­£å¸¸" if readings.get("vibration", 0) < 5 else "å¼‚å¸¸",
                "score": 0.85 if readings.get("vibration", 0) < 5 else 0.2
            }
            
            pressure_analysis = {
                "result": "æ­£å¸¸" if readings.get("pressure", 0) > 1.5 else "å¼‚å¸¸",
                "score": 0.9 if readings.get("pressure", 0) > 1.5 else 0.4
            }
            
            parallel_results = {
                "temperature": temp_analysis,
                "vibration": vibration_analysis,
                "pressure": pressure_analysis
            }
            
            return {
                "processing_steps": ["æ‰§è¡Œå¹¶è¡Œåˆ†æï¼ˆæ¸©åº¦ã€æŒ¯åŠ¨ã€å‹åŠ›ï¼‰"],
                "parallel_results": parallel_results
            }
        
        def decision_fusion_node(state: AdvancedWorkflowState) -> Dict[str, Any]:
            """å†³ç­–èåˆèŠ‚ç‚¹"""
            parallel_results = state["parallel_results"]
            
            total_score = 0
            abnormal_count = 0
            
            for sensor, analysis in parallel_results.items():
                total_score += analysis["score"]
                if analysis["result"] == "å¼‚å¸¸":
                    abnormal_count += 1
            
            avg_confidence = total_score / len(parallel_results)
            
            if abnormal_count >= 2:
                decision = "å¤šä¸ªä¼ æ„Ÿå™¨å¼‚å¸¸ï¼Œå»ºè®®ç«‹å³æ£€ä¿®"
            elif abnormal_count == 1:
                decision = "å•ä¸ªä¼ æ„Ÿå™¨å¼‚å¸¸ï¼Œå»ºè®®å¯†åˆ‡ç›‘æ§"
            else:
                decision = "æ‰€æœ‰ä¼ æ„Ÿå™¨æ­£å¸¸"
            
            return {
                "processing_steps": [f"å†³ç­–èåˆå®Œæˆï¼Œå¼‚å¸¸ä¼ æ„Ÿå™¨æ•°é‡: {abnormal_count}"],
                "final_decision": decision,
                "confidence_level": avg_confidence
            }
        
        # è·¯ç”±å†³ç­–å‡½æ•°
        def route_analysis(state: AdvancedWorkflowState) -> str:
            """æ ¹æ®æ•°æ®è´¨é‡é€‰æ‹©åˆ†æè·¯å¾„"""
            return state["analysis_path"]
        
        def should_fuse_results(state: AdvancedWorkflowState) -> str:
            """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»“æœèåˆ"""
            if state.get("parallel_results"):
                return "fusion"
            else:
                return "end"
        
        # æ„å»ºå›¾
        workflow = StateGraph(AdvancedWorkflowState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("validate", data_validation_node)
        workflow.add_node("simple_analysis", simple_analysis_node)
        workflow.add_node("parallel_analysis", parallel_analysis_node)
        workflow.add_node("fusion", decision_fusion_node)
        
        # è®¾ç½®å…¥å£
        workflow.set_entry_point("validate")
        
        # æ¡ä»¶è·¯ç”±
        workflow.add_conditional_edges(
            "validate",
            route_analysis,
            {
                "simple_analysis": "simple_analysis",
                "full_analysis": "parallel_analysis"
            }
        )
        
        # ç®€å•åˆ†æç›´æ¥ç»“æŸ
        workflow.add_edge("simple_analysis", END)
        
        # å¹¶è¡Œåˆ†æåè¿›è¡Œèåˆ
        workflow.add_conditional_edges(
            "parallel_analysis",
            should_fuse_results,
            {
                "fusion": "fusion",
                "end": END
            }
        )
        
        workflow.add_edge("fusion", END)
        
        return workflow.compile()
    
    def run_analysis(self, sensor_readings: Dict[str, float]) -> Dict[str, Any]:
        """è¿è¡Œé«˜çº§åˆ†æ"""
        initial_state = {
            "sensor_readings": sensor_readings,
            "analysis_path": "",
            "processing_steps": ["é«˜çº§å·¥ä½œæµå¯åŠ¨"],
            "parallel_results": {},
            "final_decision": "",
            "confidence_level": 0.0
        }
        
        result = self.workflow.invoke(initial_state)
        return result


def demo_basic_workflow():
    """æ¼”ç¤ºåŸºç¡€å·¥ä½œæµ"""
    print("ğŸ­ åŸºç¡€PHMåˆ†æå·¥ä½œæµæ¼”ç¤º")
    
    phm_workflow = PHMAnalysisWorkflow()
    
    test_data = {
        "sensor_data": {
            "temperature": 75.5,
            "vibration": 4.2,
            "pressure": 2.3
        },
        "timestamp": "2024-01-15 10:30:00"
    }
    
    print(f"è¾“å…¥æ•°æ®: {test_data}")
    result = phm_workflow.analyze(test_data)
    
    print(f"\nâœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
    print(f"æ‰§è¡Œå†å²: {result['processing_history']}")
    print(f"æœ€ç»ˆè¯Šæ–­: {result['results'].get('diagnosis', 'N/A')}")
    print(f"ç½®ä¿¡åº¦: {result['results'].get('confidence', 0):.2f}")
    
    return result


def demo_advanced_workflow():
    """æ¼”ç¤ºé«˜çº§å·¥ä½œæµ"""
    print("\nğŸš€ é«˜çº§PHMå·¥ä½œæµæ¼”ç¤º")
    
    advanced_workflow = AdvancedPHMWorkflow()
    
    test_scenarios = [
        {
            "name": "å®Œæ•´æ•°æ® - æ­£å¸¸çŠ¶æ€",
            "data": {"temperature": 70, "vibration": 3.0, "pressure": 2.2}
        },
        {
            "name": "å®Œæ•´æ•°æ® - å¤šé¡¹å¼‚å¸¸",
            "data": {"temperature": 85, "vibration": 6.5, "pressure": 1.0}
        },
        {
            "name": "ä¸å®Œæ•´æ•°æ®",
            "data": {"temperature": 75, "pressure": 2.1}  # ç¼ºå°‘æŒ¯åŠ¨æ•°æ®
        }
    ]
    
    results = []
    for scenario in test_scenarios:
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æµ‹è¯•åœºæ™¯: {scenario['name']}")
        print(f"ğŸ“Š è¾“å…¥æ•°æ®: {scenario['data']}")
        
        result = advanced_workflow.run_analysis(scenario['data'])
        results.append(result)
        
        print(f"ğŸ”„ å¤„ç†è·¯å¾„: {result['analysis_path']}")
        print(f"ğŸ“ å¤„ç†æ­¥éª¤: {result['processing_steps']}")
        print(f"ğŸ¯ æœ€ç»ˆå†³ç­–: {result['final_decision']}")
        print(f"ğŸ“ˆ ç½®ä¿¡åº¦: {result['confidence_level']:.2f}")
        
        if result.get('parallel_results'):
            print(f"ğŸ”„ å¹¶è¡Œåˆ†æç»“æœ:")
            for sensor, analysis in result['parallel_results'].items():
                print(f"  {sensor}: {analysis['result']} (å¾—åˆ†: {analysis['score']:.2f})")
    
    return results


if __name__ == "__main__":
    demo_basic_workflow()
    demo_advanced_workflow()