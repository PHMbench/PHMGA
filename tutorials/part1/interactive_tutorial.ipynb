{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHMGA Tutorial Part 1: Interactive Foundation Tutorial\n",
    "\n",
    "Welcome to the interactive tutorial for PHMGA Part 1! This notebook provides hands-on experience with genetic algorithms and their LLM-enhanced variants.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand genetic algorithm fundamentals\n",
    "- Implement traditional and LLM-enhanced GAs\n",
    "- Compare performance characteristics\n",
    "- Experiment with parameter tuning\n",
    "\n",
    "## Prerequisites\n",
    "- Basic Python knowledge\n",
    "- Understanding of optimization concepts\n",
    "- Familiarity with NumPy and Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import our GA implementations\n",
    "from traditional_ga import TraditionalGA, GAConfig, Individual\n",
    "from llm_enhanced_ga import LLMEnhancedGA, LLMConfig\n",
    "from benchmark_comparison import BenchmarkSuite, BenchmarkConfig\n",
    "from exercises import ExerciseFramework\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "print(\"📚 Ready to start the interactive tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Understanding the Problem\n",
    "\n",
    "We'll start with a simple quadratic function optimization problem:\n",
    "\n",
    "**Function**: `f(x, y) = (x - 3)² + (y + 1)² + 5`\n",
    "\n",
    "**Objective**: Find the minimum value\n",
    "\n",
    "**Expected Solution**: `x = 3, y = -1` with minimum value `f(3, -1) = 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our objective function\n",
    "def quadratic_function(x, y):\n",
    "    \"\"\"The quadratic function we want to minimize\"\"\"\n",
    "    return (x - 3)**2 + (y + 1)**2 + 5\n",
    "\n",
    "# Visualize the function\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = np.linspace(-10, 10, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = quadratic_function(X, Y)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 3D surface plot\n",
    "ax1 = plt.subplot(1, 2, 1, projection='3d')\n",
    "surf = ax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n",
    "ax1.scatter([3], [-1], [5], color='red', s=100, label='Global Minimum')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('f(x, y)')\n",
    "ax1.set_title('3D Surface Plot')\n",
    "ax1.legend()\n",
    "\n",
    "# Contour plot\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "contour = ax2.contour(X, Y, Z, levels=20)\n",
    "ax2.clabel(contour, inline=True, fontsize=8)\n",
    "ax2.scatter([3], [-1], color='red', s=100, marker='*', label='Global Minimum')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_title('Contour Plot')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Global minimum: f(3, -1) = {quadratic_function(3, -1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Traditional Genetic Algorithm\n",
    "\n",
    "Let's implement and run a traditional genetic algorithm to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the traditional GA\n",
    "ga_config = GAConfig(\n",
    "    population_size=50,\n",
    "    mutation_rate=0.1,\n",
    "    crossover_rate=0.8,\n",
    "    max_generations=100,\n",
    "    gene_bounds=(-10.0, 10.0),\n",
    "    elitism_count=2\n",
    ")\n",
    "\n",
    "print(\"🔧 GA Configuration:\")\n",
    "print(f\"   Population Size: {ga_config.population_size}\")\n",
    "print(f\"   Mutation Rate: {ga_config.mutation_rate}\")\n",
    "print(f\"   Crossover Rate: {ga_config.crossover_rate}\")\n",
    "print(f\"   Max Generations: {ga_config.max_generations}\")\n",
    "print(f\"   Search Bounds: {ga_config.gene_bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the traditional GA\n",
    "print(\"🚀 Running Traditional Genetic Algorithm...\")\n",
    "\n",
    "traditional_ga = TraditionalGA(ga_config)\n",
    "traditional_results = traditional_ga.run(verbose=True)\n",
    "\n",
    "print(\"\\n✅ Traditional GA completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize traditional GA results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Convergence plot\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "# Convert fitness back to objective values\n",
    "objective_history = [-f for f in traditional_results['fitness_history']]\n",
    "plt.plot(objective_history, 'b-', linewidth=2, label='Best Objective Value')\n",
    "plt.axhline(y=5.0, color='red', linestyle='--', label='Global Optimum')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Objective Value')\n",
    "plt.title('Traditional GA Convergence')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Population diversity\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plt.plot(traditional_results['diversity_history'], 'g-', linewidth=2)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Population Diversity')\n",
    "plt.title('Population Diversity Evolution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Solution visualization\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "# Plot contour of the function\n",
    "x_range = np.linspace(-5, 8, 50)\n",
    "y_range = np.linspace(-6, 4, 50)\n",
    "X_zoom, Y_zoom = np.meshgrid(x_range, y_range)\n",
    "Z_zoom = quadratic_function(X_zoom, Y_zoom)\n",
    "contour = plt.contour(X_zoom, Y_zoom, Z_zoom, levels=15, alpha=0.6)\n",
    "\n",
    "# Plot solution\n",
    "solution = traditional_results['best_solution']\n",
    "plt.scatter([3], [-1], color='red', s=150, marker='*', label='True Optimum', zorder=5)\n",
    "plt.scatter(solution[0], solution[1], color='blue', s=100, marker='o', label='GA Solution', zorder=5)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Solution Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results\n",
    "print(f\"📊 Traditional GA Results:\")\n",
    "print(f\"   Best Solution: x = {solution[0]:.6f}, y = {solution[1]:.6f}\")\n",
    "print(f\"   Best Objective Value: {traditional_results['best_objective_value']:.6f}\")\n",
    "print(f\"   Error from Optimum: {abs(traditional_results['best_objective_value'] - 5.0):.6f}\")\n",
    "print(f\"   Execution Time: {traditional_results['execution_time']:.3f} seconds\")\n",
    "print(f\"   Function Evaluations: {traditional_results['function_evaluations']}\")\n",
    "print(f\"   Solution Quality: {traditional_results['solution_quality']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: LLM-Enhanced Genetic Algorithm\n",
    "\n",
    "Now let's run the LLM-enhanced version and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the LLM-enhanced GA\n",
    "llm_config = LLMConfig(\n",
    "    provider=\"mock\",  # Using mock for consistent results\n",
    "    enable_parameter_tuning=True,\n",
    "    enable_fitness_analysis=True\n",
    ")\n",
    "\n",
    "print(\"🤖 LLM Configuration:\")\n",
    "print(f\"   Provider: {llm_config.provider}\")\n",
    "print(f\"   Parameter Tuning: {llm_config.enable_parameter_tuning}\")\n",
    "print(f\"   Fitness Analysis: {llm_config.enable_fitness_analysis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LLM-enhanced GA\n",
    "print(\"🚀 Running LLM-Enhanced Genetic Algorithm...\")\n",
    "\n",
    "llm_ga = LLMEnhancedGA(ga_config, llm_config)\n",
    "llm_results = llm_ga.run(verbose=True)\n",
    "\n",
    "print(\"\\n✅ LLM-Enhanced GA completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both implementations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Convergence comparison\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "trad_objective = [-f for f in traditional_results['fitness_history']]\n",
    "llm_objective = [-f for f in llm_results['fitness_history']]\n",
    "\n",
    "plt.plot(trad_objective, 'b-', linewidth=2, label='Traditional GA')\n",
    "plt.plot(llm_objective, 'r-', linewidth=2, label='LLM-Enhanced GA')\n",
    "plt.axhline(y=5.0, color='green', linestyle='--', label='Global Optimum')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Objective Value')\n",
    "plt.title('Convergence Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Diversity comparison\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "plt.plot(traditional_results['diversity_history'], 'b-', linewidth=2, label='Traditional GA')\n",
    "plt.plot(llm_results['diversity_history'], 'r-', linewidth=2, label='LLM-Enhanced GA')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Population Diversity')\n",
    "plt.title('Diversity Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Performance metrics\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "metrics = ['Final Error', 'Execution Time', 'Function Evals']\n",
    "trad_values = [\n",
    "    abs(traditional_results['best_objective_value'] - 5.0),\n",
    "    traditional_results['execution_time'],\n",
    "    traditional_results['function_evaluations'] / 1000  # Scale for visibility\n",
    "]\n",
    "llm_values = [\n",
    "    abs(llm_results['best_objective_value'] - 5.0),\n",
    "    llm_results['execution_time'],\n",
    "    llm_results['function_evaluations'] / 1000\n",
    "]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, trad_values, width, label='Traditional GA', alpha=0.8)\n",
    "plt.bar(x + width/2, llm_values, width, label='LLM-Enhanced GA', alpha=0.8)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Performance Metrics')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "\n",
    "# Solution comparison\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "contour = plt.contour(X_zoom, Y_zoom, Z_zoom, levels=15, alpha=0.6)\n",
    "plt.scatter([3], [-1], color='green', s=150, marker='*', label='True Optimum', zorder=5)\n",
    "plt.scatter(traditional_results['best_solution'][0], traditional_results['best_solution'][1], \n",
    "           color='blue', s=100, marker='o', label='Traditional GA', zorder=5)\n",
    "plt.scatter(llm_results['best_solution'][0], llm_results['best_solution'][1], \n",
    "           color='red', s=100, marker='s', label='LLM-Enhanced GA', zorder=5)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Solution Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# LLM interactions (if available)\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "if 'llm_interactions' in llm_results and llm_results['llm_interactions']:\n",
    "    interaction_gens = [int(interaction['generation']) for interaction in llm_results['llm_interactions']]\n",
    "    plt.hist(interaction_gens, bins=10, alpha=0.7, color='orange')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Number of LLM Interactions')\n",
    "    plt.title('LLM Interaction Distribution')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No LLM Interactions\\nRecorded', \n",
    "             horizontalalignment='center', verticalalignment='center',\n",
    "             transform=ax5.transAxes, fontsize=12)\n",
    "    plt.title('LLM Interactions')\n",
    "\n",
    "# Summary table\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.axis('tight')\n",
    "ax6.axis('off')\n",
    "\n",
    "summary_data = [\n",
    "    ['Metric', 'Traditional GA', 'LLM-Enhanced GA'],\n",
    "    ['Final Error', f\"{abs(traditional_results['best_objective_value'] - 5.0):.6f}\", \n",
    "     f\"{abs(llm_results['best_objective_value'] - 5.0):.6f}\"],\n",
    "    ['Execution Time', f\"{traditional_results['execution_time']:.3f}s\", \n",
    "     f\"{llm_results['execution_time']:.3f}s\"],\n",
    "    ['Function Evals', f\"{traditional_results['function_evaluations']}\", \n",
    "     f\"{llm_results['function_evaluations']}\"],\n",
    "    ['Solution Quality', traditional_results['solution_quality'], \n",
    "     llm_results['solution_quality']],\n",
    "    ['LLM Calls', '0', f\"{llm_results.get('llm_calls', 0)}\"]\n",
    "]\n",
    "\n",
    "table = ax6.table(cellText=summary_data, cellLoc='center', loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1.2, 1.5)\n",
    "ax6.set_title('Performance Summary', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Interactive Parameter Exploration\n",
    "\n",
    "Let's explore how different parameters affect GA performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive parameter exploration\n",
    "def explore_parameters(population_size=50, mutation_rate=0.1, crossover_rate=0.8, max_generations=100):\n",
    "    \"\"\"Explore GA performance with different parameters\"\"\"\n",
    "    \n",
    "    config = GAConfig(\n",
    "        population_size=population_size,\n",
    "        mutation_rate=mutation_rate,\n",
    "        crossover_rate=crossover_rate,\n",
    "        max_generations=max_generations,\n",
    "        gene_bounds=(-10.0, 10.0),\n",
    "        elitism_count=2\n",
    "    )\n",
    "    \n",
    "    ga = TraditionalGA(config)\n",
    "    results = ga.run(verbose=False)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Convergence\n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    objective_history = [-f for f in results['fitness_history']]\n",
    "    plt.plot(objective_history, 'b-', linewidth=2)\n",
    "    plt.axhline(y=5.0, color='red', linestyle='--', alpha=0.7)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Objective Value')\n",
    "    plt.title('Convergence')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Diversity\n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    plt.plot(results['diversity_history'], 'g-', linewidth=2)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Diversity')\n",
    "    plt.title('Population Diversity')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Solution\n",
    "    ax3 = plt.subplot(1, 3, 3)\n",
    "    solution = results['best_solution']\n",
    "    plt.scatter([3], [-1], color='red', s=100, marker='*', label='True Optimum')\n",
    "    plt.scatter(solution[0], solution[1], color='blue', s=80, marker='o', label='GA Solution')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Solution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"📊 Results with parameters:\")\n",
    "    print(f\"   Population Size: {population_size}, Mutation Rate: {mutation_rate}\")\n",
    "    print(f\"   Crossover Rate: {crossover_rate}, Max Generations: {max_generations}\")\n",
    "    print(f\"   Final Error: {abs(results['best_objective_value'] - 5.0):.6f}\")\n",
    "    print(f\"   Solution Quality: {results['solution_quality']}\")\n",
    "    print(f\"   Execution Time: {results['execution_time']:.3f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Try different parameter combinations\n",
    "print(\"🔬 Parameter Exploration\")\n",
    "print(\"Try different parameter values to see how they affect performance:\")\n",
    "\n",
    "# Example: High mutation rate\n",
    "print(\"\\n1. High Mutation Rate (0.3):\")\n",
    "high_mut_results = explore_parameters(mutation_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Large population\n",
    "print(\"\\n2. Large Population (100):\")\n",
    "large_pop_results = explore_parameters(population_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Low crossover rate\n",
    "print(\"\\n3. Low Crossover Rate (0.3):\")\n",
    "low_cross_results = explore_parameters(crossover_rate=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Hands-on Exercises\n",
    "\n",
    "Now it's your turn! Try these exercises to deepen your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Optimize the Rosenbrock function\n",
    "print(\"🎯 Exercise 1: Rosenbrock Function\")\n",
    "print(\"The Rosenbrock function is a classic optimization benchmark:\")\n",
    "print(\"f(x, y) = (a - x)² + b(y - x²)² where a=1, b=100\")\n",
    "print(\"Global minimum at (1, 1) with f(1, 1) = 0\")\n",
    "\n",
    "def rosenbrock_function(x, y):\n",
    "    a, b = 1, 100\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "\n",
    "# Visualize the Rosenbrock function\n",
    "x_ros = np.linspace(-2, 2, 100)\n",
    "y_ros = np.linspace(-1, 3, 100)\n",
    "X_ros, Y_ros = np.meshgrid(x_ros, y_ros)\n",
    "Z_ros = rosenbrock_function(X_ros, Y_ros)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1, projection='3d')\n",
    "surf = ax1.plot_surface(X_ros, Y_ros, Z_ros, cmap='viridis', alpha=0.8)\n",
    "ax1.scatter([1], [1], [0], color='red', s=100, label='Global Minimum')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('f(x, y)')\n",
    "ax1.set_title('Rosenbrock Function 3D')\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "contour = ax2.contour(X_ros, Y_ros, Z_ros, levels=20)\n",
    "ax2.clabel(contour, inline=True, fontsize=8)\n",
    "ax2.scatter([1], [1], color='red', s=100, marker='*', label='Global Minimum')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_title('Rosenbrock Function Contour')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📝 Your task: Modify the fitness function in the GA to optimize the Rosenbrock function\")\n",
    "print(\"Hint: You'll need to create a custom Individual class with a new evaluate_fitness method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution Template\n",
    "class RosenbrockIndividual(Individual):\n",
    "    \"\"\"Individual for Rosenbrock function optimization\"\"\"\n",
    "    \n",
    "    def evaluate_fitness(self):\n",
    "        \"\"\"Evaluate fitness for Rosenbrock function\"\"\"\n",
    "        x, y = self.genes\n",
    "        a, b = 1, 100\n",
    "        objective = (a - x)**2 + b * (y - x**2)**2\n",
    "        self.fitness = -objective  # Negative for maximization\n",
    "        return self.fitness\n",
    "\n",
    "# TODO: Implement and run GA with RosenbrockIndividual\n",
    "# Your code here...\n",
    "\n",
    "print(\"💡 Implement your solution above and run it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Performance Analysis and Insights\n",
    "\n",
    "Let's analyze what we've learned and draw insights about GA performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis summary\n",
    "print(\"📈 Performance Analysis Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare our results\n",
    "comparison_data = {\n",
    "    'Implementation': ['Traditional GA', 'LLM-Enhanced GA'],\n",
    "    'Final Error': [\n",
    "        abs(traditional_results['best_objective_value'] - 5.0),\n",
    "        abs(llm_results['best_objective_value'] - 5.0)\n",
    "    ],\n",
    "    'Execution Time': [\n",
    "        traditional_results['execution_time'],\n",
    "        llm_results['execution_time']\n",
    "    ],\n",
    "    'Function Evaluations': [\n",
    "        traditional_results['function_evaluations'],\n",
    "        llm_results['function_evaluations']\n",
    "    ],\n",
    "    'Solution Quality': [\n",
    "        traditional_results['solution_quality'],\n",
    "        llm_results['solution_quality']\n",
    "    ]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\n🔍 Key Insights:\")\n",
    "print(\"1. Parameter tuning significantly affects GA performance\")\n",
    "print(\"2. LLM enhancement can provide adaptive parameter adjustment\")\n",
    "print(\"3. Population diversity is crucial for avoiding premature convergence\")\n",
    "print(\"4. The balance between exploration and exploitation is critical\")\n",
    "\n",
    "print(\"\\n🎯 When to use each approach:\")\n",
    "print(\"Traditional GA:\")\n",
    "print(\"  ✓ Simple, well-understood problems\")\n",
    "print(\"  ✓ When computational resources are limited\")\n",
    "print(\"  ✓ When you have domain expertise for parameter tuning\")\n",
    "\n",
    "print(\"\\nLLM-Enhanced GA:\")\n",
    "print(\"  ✓ Complex, poorly understood problems\")\n",
    "print(\"  ✓ When adaptive parameter tuning is beneficial\")\n",
    "print(\"  ✓ When natural language interfaces are valuable\")\n",
    "print(\"  ✓ For automated algorithm configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Next Steps and Advanced Topics\n",
    "\n",
    "Congratulations! You've completed Part 1 of the PHMGA tutorial. Here's what you've learned and what comes next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎓 What You've Learned:\")\n",
    "print(\"=\" * 30)\n",
    "print(\"✅ Genetic algorithm fundamentals\")\n",
    "print(\"✅ Traditional GA implementation\")\n",
    "print(\"✅ LLM-enhanced GA concepts\")\n",
    "print(\"✅ Parameter sensitivity analysis\")\n",
    "print(\"✅ Performance comparison techniques\")\n",
    "print(\"✅ Hands-on optimization experience\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"=\" * 15)\n",
    "print(\"📚 Part 2: Core Components Architecture\")\n",
    "print(\"   - Router Component implementation\")\n",
    "print(\"   - Graph Component for population structures\")\n",
    "print(\"   - State Management systems\")\n",
    "print(\"   - Integration patterns\")\n",
    "\n",
    "print(\"\\n📚 Part 3: Advanced Integration and Real-World Applications\")\n",
    "print(\"   - Enhanced Case 1 implementation\")\n",
    "print(\"   - Autonomous Signal Processing DAG\")\n",
    "print(\"   - Production deployment strategies\")\n",
    "print(\"   - Custom operator development\")\n",
    "\n",
    "print(\"\\n🔬 Additional Challenges:\")\n",
    "print(\"1. Implement different selection methods (roulette wheel, rank-based)\")\n",
    "print(\"2. Add new crossover operators (arithmetic, blend crossover)\")\n",
    "print(\"3. Create adaptive mutation strategies\")\n",
    "print(\"4. Implement multi-objective optimization\")\n",
    "print(\"5. Add constraint handling mechanisms\")\n",
    "\n",
    "print(\"\\n📖 Recommended Reading:\")\n",
    "print(\"- 'Introduction to Evolutionary Computing' by Eiben & Smith\")\n",
    "print(\"- 'Genetic Algorithms in Search, Optimization, and Machine Learning' by Goldberg\")\n",
    "print(\"- LangGraph documentation for workflow orchestration\")\n",
    "\n",
    "print(\"\\n🤝 Community:\")\n",
    "print(\"- Join the PHMGA GitHub Discussions\")\n",
    "print(\"- Share your implementations and improvements\")\n",
    "print(\"- Help other learners in the community\")\n",
    "\n",
    "print(\"\\n🎉 Great job completing Part 1! Ready for Part 2?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
