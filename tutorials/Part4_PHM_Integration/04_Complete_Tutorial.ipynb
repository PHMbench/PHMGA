{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: PHM Integration - å®é™…ç»„ä»¶é›†æˆ ğŸ­\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæ‚¨å°†æŒæ¡ï¼š\n",
    "- ğŸ­ **çœŸå®PHMç»„ä»¶** - ä½¿ç”¨é¡¹ç›®ä¸­çš„å®é™…DataAnalystAgentã€PlanAgentç­‰\n",
    "- ğŸ“Š **ä¿¡å·å¤„ç†é›†æˆ** - ç»“åˆçœŸå®çš„ä¿¡å·å¤„ç†æ“ä½œç¬¦\n",
    "- ğŸ”„ **å®Œæ•´å·¥ä½œæµ** - ä»åŸå§‹ä¿¡å·åˆ°è¯Šæ–­æŠ¥å‘Šçš„ç«¯åˆ°ç«¯æµç¨‹\n",
    "- âš™ï¸ **æ€§èƒ½ç›‘æ§** - ç³»ç»Ÿæ€§èƒ½å’Œèµ„æºä½¿ç”¨ç›‘æ§\n",
    "\n",
    "## ğŸ“‹ é¢„è®¡æ—¶é•¿ï¼š3-4å°æ—¶\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "# è®¾ç½®é¡¹ç›®è·¯å¾„\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "# å¯¼å…¥PHMæ¡†æ¶ä½¿ç”¨æ¨¡å—\n",
    "from modules.phm_framework_usage import PHMFrameworkDemo, run_comprehensive_demo\n",
    "\n",
    "# å°è¯•å¯¼å…¥çœŸå®é¡¹ç›®ç»„ä»¶\n",
    "try:\n",
    "    from src.agents.data_analyst_agent import DataAnalystAgent\n",
    "    from src.agents.plan_agent import PlanAgent  \n",
    "    from src.states.phm_states import PHMState, DAGState, InputData\n",
    "    from src.states.research_states import ResearchPHMState\n",
    "    from src.model import get_llm\n",
    "    from src.tools.signal_processing_schemas import OP_REGISTRY, get_operator\n",
    "    PROJECT_AVAILABLE = True\n",
    "    print(\"âœ… çœŸå®PHMç»„ä»¶å¯ç”¨\")\n",
    "    print(f\"ğŸ“Š å¯ç”¨ä¿¡å·å¤„ç†æ“ä½œç¬¦: {len(OP_REGISTRY)}ä¸ª\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ é¡¹ç›®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "    PROJECT_AVAILABLE = False\n",
    "    print(\"ğŸ”§ å°†ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶æ¼”ç¤º\")\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. çœŸå®PHMç»„ä»¶ä»‹ç» ğŸ­\n",
    "\n",
    "### 1.1 é¡¹ç›®æ¶æ„æ¦‚è§ˆ\n",
    "\n",
    "è®©æˆ‘ä»¬äº†è§£PHMGAé¡¹ç›®çš„çœŸå®æ¶æ„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å±•ç¤ºé¡¹ç›®æ¶æ„\n",
    "def show_project_architecture():\n",
    "    \"\"\"å±•ç¤ºPHMGAé¡¹ç›®æ¶æ„\"\"\"\n",
    "    print(\"ğŸ—ï¸ PHMGAé¡¹ç›®æ¶æ„\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    architecture = {\n",
    "        \"ğŸ§  Agentå±‚\": [\n",
    "            \"DataAnalystAgent - æ•°æ®åˆ†æä¸“å®¶\",\n",
    "            \"PlanAgent - ç»´æŠ¤è®¡åˆ’åˆ¶å®š\",\n",
    "            \"ExecuteAgent - æ‰§è¡Œå¼•æ“\",\n",
    "            \"ReflectAgent - è´¨é‡è¯„ä¼°\",\n",
    "            \"ReportAgent - æŠ¥å‘Šç”Ÿæˆ\"\n",
    "        ],\n",
    "        \"ğŸ“Š çŠ¶æ€ç®¡ç†\": [\n",
    "            \"PHMState - ä¸»çŠ¶æ€å®¹å™¨\",\n",
    "            \"DAGState - è®¡ç®—å›¾çŠ¶æ€\",\n",
    "            \"ResearchPHMState - ç ”ç©¶çŠ¶æ€\"\n",
    "        ],\n",
    "        \"ğŸ”§ ä¿¡å·å¤„ç†\": [\n",
    "            \"60+ ä¿¡å·å¤„ç†æ“ä½œç¬¦\",\n",
    "            \"è‡ªåŠ¨æ“ä½œç¬¦æ³¨å†Œç³»ç»Ÿ\",\n",
    "            \"åŠ¨æ€è®¡ç®—å›¾(DAG)æ„å»º\"\n",
    "        ],\n",
    "        \"ğŸ¤– LLMé›†æˆ\": [\n",
    "            \"å¤šProvideræ”¯æŒ (Google/OpenAI)\",\n",
    "            \"ç»“æ„åŒ–è¾“å‡º\",\n",
    "            \"æç¤ºæ¨¡æ¿ç³»ç»Ÿ\"\n",
    "        ],\n",
    "        \"ğŸ”„ å·¥ä½œæµ\": [\n",
    "            \"LangGraphå·¥ä½œæµç¼–æ’\",\n",
    "            \"START â†’ Plan â†’ Execute â†’ Reflect â†’ Report â†’ END\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, components in architecture.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for component in components:\n",
    "            print(f\"  â€¢ {component}\")\n",
    "    \n",
    "    if PROJECT_AVAILABLE:\n",
    "        print(f\"\\nğŸ“ˆ ç³»ç»Ÿç»Ÿè®¡:\")\n",
    "        print(f\"  ä¿¡å·å¤„ç†æ“ä½œç¬¦: {len(OP_REGISTRY)}ä¸ª\")\n",
    "        print(f\"  æ“ä½œç¬¦ç±»åˆ«: {len(set(op.category for op in OP_REGISTRY.values()))}ç§\")\n",
    "        \n",
    "        # æ˜¾ç¤ºæ“ä½œç¬¦ç±»åˆ«\n",
    "        categories = {}\n",
    "        for name, op in OP_REGISTRY.items():\n",
    "            cat = op.category\n",
    "            if cat not in categories:\n",
    "                categories[cat] = []\n",
    "            categories[cat].append(name)\n",
    "        \n",
    "        print(f\"\\nğŸ”§ æ“ä½œç¬¦åˆ†ç±»:\")\n",
    "        for cat, ops in categories.items():\n",
    "            print(f\"  {cat}: {len(ops)}ä¸ª ({', '.join(ops[:3])}{'...' if len(ops) > 3 else ''})\")\n",
    "\n",
    "show_project_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 æ ¸å¿ƒAgentç»„ä»¶\n",
    "\n",
    "è®©æˆ‘ä»¬æ·±å…¥äº†è§£ä¸»è¦çš„Agentç»„ä»¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¼”ç¤ºæ ¸å¿ƒAgentç»„ä»¶\n",
    "if PROJECT_AVAILABLE:\n",
    "    print(\"ğŸ¤– çœŸå®Agentç»„ä»¶æ¼”ç¤º\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. åˆ›å»ºDataAnalystAgent\n",
    "    print(\"\\n1. ğŸ“Š DataAnalystAgent:\")\n",
    "    try:\n",
    "        analyst_config = {\n",
    "            \"quick_mode\": False,\n",
    "            \"enable_advanced_features\": True,\n",
    "            \"use_parallel\": True,\n",
    "            \"use_cache\": True\n",
    "        }\n",
    "        \n",
    "        data_analyst = DataAnalystAgent(config=analyst_config)\n",
    "        print(f\"   Agentåç§°: {data_analyst.agent_name}\")\n",
    "        print(f\"   é…ç½®: {analyst_config}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡\n",
    "        if hasattr(data_analyst, 'get_performance_metrics'):\n",
    "            metrics = data_analyst.get_performance_metrics()\n",
    "            if not metrics.get(\"no_executions\"):\n",
    "                print(f\"   æ€§èƒ½æŒ‡æ ‡: {metrics}\")\n",
    "            else:\n",
    "                print(\"   æ€§èƒ½æŒ‡æ ‡: æš‚æ— æ‰§è¡Œè®°å½•\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ åˆ›å»ºå¤±è´¥: {e}\")\n",
    "    \n",
    "    # 2. åˆ›å»ºPlanAgent\n",
    "    print(\"\\n2. ğŸ“‹ PlanAgent:\")\n",
    "    try:\n",
    "        plan_agent = PlanAgent()\n",
    "        print(f\"   Agentåç§°: {plan_agent.agent_name}\")\n",
    "        print(f\"   åŠŸèƒ½: åŸºäºåˆ†æç»“æœåˆ¶å®šç»´æŠ¤è®¡åˆ’\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ åˆ›å»ºå¤±è´¥: {e}\")\n",
    "    \n",
    "    # 3. å±•ç¤ºLLMé…ç½®\n",
    "    print(\"\\n3. ğŸ¤– LLMé›†æˆ:\")\n",
    "    try:\n",
    "        llm = get_llm(temperature=0.7)\n",
    "        print(f\"   LLMç±»å‹: {type(llm).__name__}\")\n",
    "        print(f\"   é…ç½®: æ¸©åº¦=0.7\")\n",
    "        \n",
    "        # æµ‹è¯•LLMè°ƒç”¨\n",
    "        test_query = \"ç®€è¿°é¢„æµ‹æ€§ç»´æŠ¤çš„æ ¸å¿ƒæ¦‚å¿µ\"\n",
    "        response = llm.invoke(test_query)\n",
    "        content = response.content if hasattr(response, 'content') else str(response)\n",
    "        print(f\"   æµ‹è¯•å“åº”: {content[:100]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
    "    \n",
    "    # 4. ä¿¡å·å¤„ç†æ“ä½œç¬¦æ¼”ç¤º\n",
    "    print(\"\\n4. ğŸ”§ ä¿¡å·å¤„ç†æ“ä½œç¬¦:\")\n",
    "    \n",
    "    # å±•ç¤ºå¸¸ç”¨æ“ä½œç¬¦\n",
    "    common_operators = ['fft', 'filter_butterworth', 'pca', 'envelope', 'stft']\n",
    "    \n",
    "    for op_name in common_operators:\n",
    "        if op_name in OP_REGISTRY:\n",
    "            op_class = get_operator(op_name)\n",
    "            op_info = OP_REGISTRY[op_name]\n",
    "            print(f\"   â€¢ {op_name}: {op_info.category} - {op_info.description[:50]}...\")\n",
    "        else:\n",
    "            print(f\"   â€¢ {op_name}: æœªæ‰¾åˆ°\")\n",
    "\nelse:\n",
    "    print(\"ğŸ”§ ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶æ¼”ç¤º\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # æ¨¡æ‹Ÿç»„ä»¶ä¿¡æ¯\n",
    "    mock_components = {\n",
    "        \"MockDataAnalyst\": \"æ¨¡æ‹Ÿæ•°æ®åˆ†æAgent\",\n",
    "        \"MockPlanAgent\": \"æ¨¡æ‹Ÿè®¡åˆ’åˆ¶å®šAgent\",\n",
    "        \"MockLLM\": \"æ¨¡æ‹Ÿè¯­è¨€æ¨¡å‹\",\n",
    "        \"MockSignalProcessor\": \"æ¨¡æ‹Ÿä¿¡å·å¤„ç†å™¨\"\n",
    "    }\n",
    "    \n",
    "    for component, description in mock_components.items():\n",
    "        print(f\"â€¢ {component}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. å®Œæ•´PHMè¯Šæ–­æµç¨‹ ğŸ”„\n",
    "\n",
    "### 2.1 è½´æ‰¿æ•…éšœè¯Šæ–­æ¡ˆä¾‹\n",
    "\n",
    "è®©æˆ‘ä»¬è¿è¡Œä¸€ä¸ªå®Œæ•´çš„è½´æ‰¿æ•…éšœè¯Šæ–­æµç¨‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œå®Œæ•´çš„PHMè¯Šæ–­æµç¨‹\n",
    "print(\"ğŸ­ å®Œæ•´PHMè¯Šæ–­æµç¨‹æ¼”ç¤º\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# åˆ›å»ºPHMæ¡†æ¶æ¼”ç¤ºå®ä¾‹\n",
    "phm_demo = PHMFrameworkDemo()\n",
    "\n",
    "print(f\"ğŸ“‹ æ¼”ç¤ºé…ç½®:\")\n",
    "if PROJECT_AVAILABLE:\n",
    "    print(f\"   ä½¿ç”¨çœŸå®ç»„ä»¶: æ˜¯\")\n",
    "    print(f\"   DataAnalyst: {phm_demo.data_analyst.agent_name if hasattr(phm_demo.data_analyst, 'agent_name') else 'Available'}\")\n",
    "    print(f\"   PlanAgent: {phm_demo.plan_agent.agent_name if hasattr(phm_demo.plan_agent, 'agent_name') else 'Available'}\")\nelse:\n",
    "    print(f\"   ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶: æ˜¯\")\n",
    "    print(f\"   DataAnalyst: MockDataAnalyst\")\n",
    "    print(f\"   PlanAgent: MockPlanAgent\")\n",
    "\n",
    "print(\"\\nğŸš€ å¼€å§‹è¯Šæ–­æµç¨‹...\")\n",
    "diagnosis_result = phm_demo.run_complete_diagnosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 è¯Šæ–­ç»“æœåˆ†æ\n",
    "\n",
    "è®©æˆ‘ä»¬è¯¦ç»†åˆ†æè¯Šæ–­ç»“æœï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯¦ç»†åˆ†æè¯Šæ–­ç»“æœ\n",
    "print(\"ğŸ“Š è¯Šæ–­ç»“æœè¯¦ç»†åˆ†æ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. æ¡ˆä¾‹ä¿¡æ¯\n",
    "case_info = diagnosis_result[\"case_info\"]\nprint(f\"\\n1. ğŸ“‹ æ¡ˆä¾‹ä¿¡æ¯:\")\nprint(f\"   æ¡ˆä¾‹åç§°: {case_info['case_name']}\")\nprint(f\"   ä¿¡å·é•¿åº¦: {case_info['signal_length']:,} ç‚¹\")\nprint(f\"   é‡‡æ ·é¢‘ç‡: {case_info['sampling_frequency']:,} Hz\")\nprint(f\"   ä¿¡å·æ—¶é•¿: {case_info['signal_length'] / case_info['sampling_frequency']:.2f} ç§’\")\n",
    "\n",
    "# 2. åˆ†æç»“æœ\n",
    "analysis = diagnosis_result[\"analysis\"]\nprint(f\"\\n2. ğŸ” åˆ†æç»“æœ:\")\nprint(f\"   åˆ†æAgent: {analysis['agent']}\")\nprint(f\"   æ‰§è¡Œæ—¶é—´: {analysis['execution_time']:.3f} ç§’\")\nprint(f\"   åˆ†ææˆåŠŸ: {'æ˜¯' if analysis['success'] else 'å¦'}\")\nprint(f\"   ç½®ä¿¡åº¦: {analysis['confidence']:.1%}\")\n\nif 'results' in analysis:\n    print(f\"   è¯¦ç»†ç»“æœ:\")\n    for key, value in analysis['results'].items():\n        if isinstance(value, str) and len(value) > 50:\n            print(f\"     {key}: {value[:50]}...\")\n        else:\n            print(f\"     {key}: {value}\")\n",
    "\n",
    "# 3. ç»´æŠ¤è®¡åˆ’\n",
    "maintenance_plan = diagnosis_result[\"maintenance_plan\"]\nprint(f\"\\n3. ğŸ› ï¸ ç»´æŠ¤è®¡åˆ’:\")\nif isinstance(maintenance_plan, dict):\n    for category, content in maintenance_plan.items():\n        if isinstance(content, list):\n            print(f\"   {category}:\")\n            for item in content:\n                print(f\"     â€¢ {item}\")\n        else:\n            print(f\"   {category}: {content}\")\nelse:\n    print(f\"   {maintenance_plan}\")\n",
    "\n",
    "# 4. ç»¼åˆè¯„ä¼°\n",
    "assessment = diagnosis_result[\"overall_assessment\"]\nprint(f\"\\n4. âš ï¸ ç»¼åˆè¯„ä¼°:\")\nprint(f\"   é£é™©ç­‰çº§: {assessment['risk_level']}\")\nprint(f\"   ç´§æ€¥ç¨‹åº¦: {assessment['urgency']}\")\nprint(f\"   è¯„ä¼°ç½®ä¿¡åº¦: {assessment['confidence']:.1%}\")\nprint(f\"   å¤„ç†å»ºè®®: {assessment['recommendation']}\")\n",
    "\n",
    "# 5. æ€§èƒ½ç»Ÿè®¡\nprint(f\"\\n5. ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:\")\nif 'analysis' in diagnosis_result and 'execution_time' in diagnosis_result['analysis']:\n    exec_time = diagnosis_result['analysis']['execution_time']\n    signal_length = case_info['signal_length']\n    throughput = signal_length / exec_time if exec_time > 0 else 0\n    print(f\"   å¤„ç†é€Ÿåº¦: {throughput:,.0f} æ ·æœ¬/ç§’\")\n    print(f\"   å®æ—¶å¤„ç†èƒ½åŠ›: {'æ˜¯' if exec_time < 1.0 else 'å¦'}\")\nelse:\n    print(f\"   æš‚æ— è¯¦ç»†æ€§èƒ½æ•°æ®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. ä¿¡å·å¤„ç†æ“ä½œç¬¦é›†æˆ ğŸ“Š\n",
    "\n",
    "### 3.1 æ“ä½œç¬¦æ³¨å†Œç³»ç»Ÿ\n",
    "\n",
    "äº†è§£PHMGAçš„ä¿¡å·å¤„ç†æ“ä½œç¬¦ç³»ç»Ÿï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¢ç´¢ä¿¡å·å¤„ç†æ“ä½œç¬¦ç³»ç»Ÿ\n",
    "if PROJECT_AVAILABLE:\n",
    "    print(\"ğŸ”§ ä¿¡å·å¤„ç†æ“ä½œç¬¦ç³»ç»Ÿ\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # æŒ‰ç±»åˆ«ç»Ÿè®¡æ“ä½œç¬¦\n",
    "    categories = {}\n",
    "    for name, op_info in OP_REGISTRY.items():\n",
    "        category = op_info.category\n",
    "        if category not in categories:\n",
    "            categories[category] = []\n",
    "        categories[category].append((name, op_info))\n",
    "    \n",
    "    print(f\"ğŸ“Š æ“ä½œç¬¦åˆ†ç±»ç»Ÿè®¡ (å…±{len(OP_REGISTRY)}ä¸ª):\")\n",
    "    for category, ops in sorted(categories.items()):\n",
    "        print(f\"\\n{category} ({len(ops)}ä¸ª):\")\n",
    "        for name, op_info in sorted(ops):\n",
    "            # è·å–æ“ä½œç¬¦ç±»\n",
    "            try:\n",
    "                op_class = get_operator(name)\n",
    "                print(f\"   â€¢ {name}: {op_info.description}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   â€¢ {name}: {op_info.description} (åŠ è½½å¤±è´¥: {e})\")\n",
    "    \n",
    "    # æ¼”ç¤ºæ“ä½œç¬¦ä½¿ç”¨\n",
    "    print(f\"\\nğŸ§ª æ“ä½œç¬¦ä½¿ç”¨æ¼”ç¤º:\")\n",
    "    \n",
    "    # ç”Ÿæˆæµ‹è¯•ä¿¡å·\n",
    "    fs = 1000  # é‡‡æ ·é¢‘ç‡\n",
    "    t = np.linspace(0, 1, fs)\n",
    "    test_signal = np.sin(2 * np.pi * 50 * t) + 0.1 * np.random.randn(len(t))\n",
    "    test_signal = test_signal.reshape(1, -1, 1)  # (B, L, C) æ ¼å¼\n",
    "    \n",
    "    print(f\"   æµ‹è¯•ä¿¡å·: å½¢çŠ¶{test_signal.shape}, é‡‡æ ·ç‡{fs}Hz\")\n",
    "    \n",
    "    # æµ‹è¯•å‡ ä¸ªå¸¸ç”¨æ“ä½œç¬¦\n",
    "    test_operators = ['fft', 'filter_butterworth', 'envelope']\n",
    "    \n",
    "    for op_name in test_operators:\n",
    "        if op_name in OP_REGISTRY:\n",
    "            try:\n",
    "                op_class = get_operator(op_name)\n",
    "                operator = op_class()\n",
    "                \n",
    "                # æ‰§è¡Œæ“ä½œ\n",
    "                start_time = time.time()\n",
    "                \n",
    "                if op_name == 'fft':\n",
    "                    result = operator.forward(test_signal, fs=fs)\n",
    "                elif op_name == 'filter_butterworth':\n",
    "                    result = operator.forward(test_signal, fs=fs, lowcut=10, highcut=100, order=4)\n",
    "                elif op_name == 'envelope':\n",
    "                    result = operator.forward(test_signal)\n",
    "                else:\n",
    "                    result = operator.forward(test_signal)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                \n",
    "                print(f\"   âœ… {op_name}: {test_signal.shape} -> {result.shape if hasattr(result, 'shape') else 'N/A'} ({end_time-start_time:.3f}s)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ {op_name}: æ‰§è¡Œå¤±è´¥ - {e}\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ {op_name}: æœªæ‰¾åˆ°æ“ä½œç¬¦\")\nelse:\n    print(\"ğŸ”§ æ¨¡æ‹Ÿä¿¡å·å¤„ç†æ“ä½œç¬¦\")\n    print(\"=\"*30)\n    \n    mock_operators = {\n        \"æ—¶åŸŸåˆ†æ\": [\"mean\", \"std\", \"rms\", \"peak\", \"crest_factor\"],\n        \"é¢‘åŸŸåˆ†æ\": [\"fft\", \"psd\", \"spectral_centroid\", \"bandwidth\"],\n        \"æ—¶é¢‘åˆ†æ\": [\"stft\", \"wavelet\", \"hilbert_envelope\"],\n        \"æ»¤æ³¢å¤„ç†\": [\"butterworth\", \"chebyshev\", \"elliptic\", \"bessel\"],\n        \"ç‰¹å¾æå–\": [\"pca\", \"ica\", \"envelope\", \"instantaneous_freq\"]\n    }\n    \n    for category, operators in mock_operators.items():\n        print(f\"\\n{category} ({len(operators)}ä¸ª):\")\n        for op in operators:\n            print(f\"   â€¢ {op}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 åŠ¨æ€è®¡ç®—å›¾(DAG)æ„å»º\n",
    "\n",
    "PHMGAä½¿ç”¨åŠ¨æ€è®¡ç®—å›¾æ¥ç»„ç»‡ä¿¡å·å¤„ç†æµç¨‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¼”ç¤ºåŠ¨æ€è®¡ç®—å›¾æ„å»º\n",
    "if PROJECT_AVAILABLE:\n",
    "    print(\"ğŸ•¸ï¸ åŠ¨æ€è®¡ç®—å›¾(DAG)æ¼”ç¤º\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # åˆ›å»ºç¤ºä¾‹æ•°æ®\n",
    "    fs = 2000\n",
    "    signal_length = 2048\n",
    "    t = np.linspace(0, signal_length/fs, signal_length)\n",
    "    \n",
    "    # æ¨¡æ‹Ÿè½´æ‰¿æ•…éšœä¿¡å·\n",
    "    bearing_signal = (\n",
    "        np.sin(2 * np.pi * 30 * t) +  # 30Hz åŸºé¢‘\n",
    "        0.3 * np.sin(2 * np.pi * 157 * t) +  # 157Hz è½´æ‰¿æ•…éšœé¢‘ç‡\n",
    "        0.1 * np.random.randn(len(t))  # å™ªå£°\n",
    "    )\n",
    "    bearing_signal = bearing_signal.reshape(1, -1, 1)\n",
    "    \n",
    "    print(f\"ğŸ“Š è¾“å…¥ä¿¡å·: å½¢çŠ¶{bearing_signal.shape}, é‡‡æ ·ç‡{fs}Hz\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºInputDataèŠ‚ç‚¹\n",
    "        input_data = InputData(\n",
    "            node_id=\"bearing_sensor\",\n",
    "            parents=[],\n",
    "            shape=bearing_signal.shape,\n",
    "            results={\"signal\": bearing_signal},\n",
    "            meta={\"fs\": fs, \"sensor_type\": \"accelerometer\"}\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… InputDataèŠ‚ç‚¹åˆ›å»ºæˆåŠŸ\")\n",
    "        print(f\"   èŠ‚ç‚¹ID: {input_data['node_id']}\")\n",
    "        print(f\"   å½¢çŠ¶: {input_data['shape']}\")\n",
    "        print(f\"   å…ƒæ•°æ®: {input_data['meta']}\")\n",
    "        \n",
    "        # åˆ›å»ºDAGState\n",
    "        dag_state = DAGState(\n",
    "            user_instruction=\"åˆ†æè½´æ‰¿æŒ¯åŠ¨ä¿¡å·ï¼Œæ£€æµ‹æ•…éšœç‰¹å¾\",\n",
    "            channels=[\"vibration_x\"],\n",
    "            nodes={\"input\": input_data},\n",
    "            leaves=[\"input\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… DAGStateåˆ›å»ºæˆåŠŸ\")\n",
    "        print(f\"   ç”¨æˆ·æŒ‡ä»¤: {dag_state['user_instruction']}\")\n",
    "        print(f\"   é€šé“æ•°: {len(dag_state['channels'])}\")\n",
    "        print(f\"   èŠ‚ç‚¹æ•°: {len(dag_state['nodes'])}\")\n",
    "        print(f\"   å¶èŠ‚ç‚¹: {dag_state['leaves']}\")\n",
    "        \n",
    "        # æ¨¡æ‹ŸDAGæ‰©å±•ï¼ˆæ·»åŠ å¤„ç†èŠ‚ç‚¹ï¼‰\n",
    "        print(f\"\\nğŸ”„ æ¨¡æ‹ŸDAGæ‰©å±•:\")\n",
    "        processing_steps = [\n",
    "            (\"preprocess\", \"æ•°æ®é¢„å¤„ç†\", \"å»å™ªå’Œå½’ä¸€åŒ–\"),\n",
    "            (\"fft_analysis\", \"é¢‘è°±åˆ†æ\", \"FFTå˜æ¢æå–é¢‘åŸŸç‰¹å¾\"),\n",
    "            (\"envelope_analysis\", \"åŒ…ç»œåˆ†æ\", \"æå–åŒ…ç»œä¿¡å·\"),\n",
    "            (\"feature_extraction\", \"ç‰¹å¾æå–\", \"è®¡ç®—ç»Ÿè®¡ç‰¹å¾\")\n",
    "        ]\n",
    "        \n",
    "        for step_id, step_name, description in processing_steps:\n",
    "            print(f\"   â€¢ {step_id}: {step_name} - {description}\")\n",
    "        \n",
    "        # åˆ›å»ºç ”ç©¶çŠ¶æ€\n",
    "        research_state = ResearchPHMState(\n",
    "            case_name=\"bearing_fault_detection\",\n",
    "            user_instruction=\"åˆ†æè½´æ‰¿æŒ¯åŠ¨ä¿¡å·ï¼Œè¯†åˆ«æ•…éšœæ¨¡å¼\",\n",
    "            reference_signal=input_data,\n",
    "            test_signal=input_data,  # ç®€åŒ–æ¼”ç¤ºï¼Œä½¿ç”¨ç›¸åŒä¿¡å·\n",
    "            dag_state=dag_state,\n",
    "            fs=fs\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ… ResearchPHMStateåˆ›å»ºæˆåŠŸ\")\n",
    "        print(f\"   æ¡ˆä¾‹åç§°: {research_state['case_name']}\")\n",
    "        print(f\"   é‡‡æ ·ç‡: {research_state['fs']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DAGåˆ›å»ºå¤±è´¥: {e}\")\n        print(f\"   è¿™é€šå¸¸æ˜¯å› ä¸ºç¼ºå°‘æŸäº›ä¾èµ–æˆ–é…ç½®\")\n\nelse:\n    print(\"ğŸ•¸ï¸ æ¨¡æ‹ŸåŠ¨æ€è®¡ç®—å›¾(DAG)\")\n    print(\"=\"*30)\n    \n    mock_dag = {\n        \"input_node\": \"åŸå§‹ä¿¡å·è¾“å…¥\",\n        \"preprocessing\": \"ä¿¡å·é¢„å¤„ç†(å»å™ªã€å½’ä¸€åŒ–)\",\n        \"fft_node\": \"FFTé¢‘è°±åˆ†æ\",\n        \"filtering\": \"å¸¦é€šæ»¤æ³¢\",\n        \"envelope\": \"åŒ…ç»œæ£€æµ‹\",\n        \"feature_extraction\": \"ç‰¹å¾æå–\",\n        \"classification\": \"æ•…éšœåˆ†ç±»\"\n    }\n    \n    print(\"æ¨¡æ‹Ÿå¤„ç†æµç¨‹:\")\n    nodes = list(mock_dag.items())\n    for i, (node_id, description) in enumerate(nodes):\n        arrow = \" -> \" if i < len(nodes) - 1 else \"\"\n        print(f\"   {node_id}: {description}{arrow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ– âš™ï¸\n",
    "\n",
    "### 4.1 ç³»ç»Ÿæ€§èƒ½ç›‘æ§\n",
    "\n",
    "åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ€§èƒ½ç›‘æ§æ˜¯å…³é”®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€§èƒ½ç›‘æ§æ¼”ç¤º\n",
    "import psutil\n",
    "import threading\n",
    "from datetime import datetime\n",
    "\n",
    "class PHMPerformanceMonitor:\n",
    "    \"\"\"PHMç³»ç»Ÿæ€§èƒ½ç›‘æ§å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"processing_times\": [],\n",
    "            \"memory_usage\": [],\n",
    "            \"cpu_usage\": [],\n",
    "            \"throughput\": [],\n",
    "            \"error_count\": 0,\n",
    "            \"success_count\": 0\n",
    "        }\n",
    "        self.monitoring = False\n",
    "    \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"å¼€å§‹ç›‘æ§\"\"\"\n",
    "        self.monitoring = True\n",
    "        self.monitor_thread = threading.Thread(target=self._monitor_loop)\n",
    "        self.monitor_thread.daemon = True\n",
    "        self.monitor_thread.start()\n",
    "        print(\"ğŸ“Š æ€§èƒ½ç›‘æ§å·²å¯åŠ¨\")\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"åœæ­¢ç›‘æ§\"\"\"\n",
    "        self.monitoring = False\n",
    "        print(\"ğŸ“Š æ€§èƒ½ç›‘æ§å·²åœæ­¢\")\n",
    "    \n",
    "    def _monitor_loop(self):\n",
    "        \"\"\"ç›‘æ§å¾ªç¯\"\"\"\n",
    "        while self.monitoring:\n",
    "            try:\n",
    "                # è·å–ç³»ç»ŸæŒ‡æ ‡\n",
    "                cpu_percent = psutil.cpu_percent(interval=1)\n",
    "                memory = psutil.virtual_memory()\n",
    "                \n",
    "                self.metrics[\"cpu_usage\"].append(cpu_percent)\n",
    "                self.metrics[\"memory_usage\"].append(memory.percent)\n",
    "                \n",
    "                # ä¿æŒæœ€è¿‘100ä¸ªæ•°æ®ç‚¹\n",
    "                for key in [\"cpu_usage\", \"memory_usage\"]:\n",
    "                    if len(self.metrics[key]) > 100:\n",
    "                        self.metrics[key] = self.metrics[key][-100:]\n",
    "                \n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            time.sleep(1)  # æ¯ç§’é‡‡æ ·ä¸€æ¬¡\n",
    "    \n",
    "    def record_processing(self, processing_time: float, signal_length: int, success: bool = True):\n",
    "        \"\"\"è®°å½•å¤„ç†æ€§èƒ½\"\"\"\n",
    "        self.metrics[\"processing_times\"].append(processing_time)\n",
    "        \n",
    "        if signal_length > 0 and processing_time > 0:\n",
    "            throughput = signal_length / processing_time\n",
    "            self.metrics[\"throughput\"].append(throughput)\n",
    "        \n",
    "        if success:\n",
    "            self.metrics[\"success_count\"] += 1\n",
    "        else:\n",
    "            self.metrics[\"error_count\"] += 1\n",
    "    \n",
    "    def get_performance_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æ€§èƒ½æ‘˜è¦\"\"\"\n",
    "        summary = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"total_processed\": self.metrics[\"success_count\"] + self.metrics[\"error_count\"],\n",
    "            \"success_rate\": 0,\n",
    "            \"average_processing_time\": 0,\n",
    "            \"average_throughput\": 0,\n",
    "            \"current_cpu_usage\": 0,\n",
    "            \"current_memory_usage\": 0,\n",
    "            \"peak_memory_usage\": 0\n",
    "        }\n",
    "        \n",
    "        total = self.metrics[\"success_count\"] + self.metrics[\"error_count\"]\n",
    "        if total > 0:\n",
    "            summary[\"success_rate\"] = self.metrics[\"success_count\"] / total\n",
    "        \n",
    "        if self.metrics[\"processing_times\"]:\n",
    "            summary[\"average_processing_time\"] = np.mean(self.metrics[\"processing_times\"])\n",
    "        \n",
    "        if self.metrics[\"throughput\"]:\n",
    "            summary[\"average_throughput\"] = np.mean(self.metrics[\"throughput\"])\n",
    "        \n",
    "        if self.metrics[\"cpu_usage\"]:\n",
    "            summary[\"current_cpu_usage\"] = self.metrics[\"cpu_usage\"][-1]\n",
    "        \n",
    "        if self.metrics[\"memory_usage\"]:\n",
    "            summary[\"current_memory_usage\"] = self.metrics[\"memory_usage\"][-1]\n",
    "            summary[\"peak_memory_usage\"] = max(self.metrics[\"memory_usage\"])\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# æ¼”ç¤ºæ€§èƒ½ç›‘æ§\n",
    "print(\"âš™ï¸ PHMç³»ç»Ÿæ€§èƒ½ç›‘æ§æ¼”ç¤º\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# åˆ›å»ºç›‘æ§å™¨\n",
    "monitor = PHMPerformanceMonitor()\n",
    "monitor.start_monitoring()\n",
    "\n",
    "# æ¨¡æ‹Ÿå¤„ç†ä»»åŠ¡\n",
    "print(\"\\nğŸ”„ æ¨¡æ‹Ÿå¤„ç†ä»»åŠ¡:\")\n",
    "for i in range(5):\n",
    "    print(f\"   ä»»åŠ¡ {i+1}/5 æ‰§è¡Œä¸­...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # æ¨¡æ‹Ÿä¿¡å·å¤„ç†ï¼ˆåˆ›å»ºéšæœºæ•°æ®å’Œè®¡ç®—ï¼‰\n",
    "    signal_length = 1000 + np.random.randint(0, 1000)\n",
    "    dummy_signal = np.random.randn(signal_length)\n",
    "    \n",
    "    # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—\n",
    "    _ = np.fft.fft(dummy_signal)\n",
    "    _ = np.mean(dummy_signal)\n",
    "    _ = np.std(dummy_signal)\n",
    "    \n",
    "    # éšæœºä¼‘çœ æ¨¡æ‹Ÿä¸åŒçš„å¤„ç†æ—¶é—´\n",
    "    time.sleep(0.1 + np.random.random() * 0.2)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    # è®°å½•æ€§èƒ½\n",
    "    success = np.random.random() > 0.1  # 90% æˆåŠŸç‡\n",
    "    monitor.record_processing(processing_time, signal_length, success)\n",
    "    \n",
    "    print(f\"   ä»»åŠ¡ {i+1} å®Œæˆ: {processing_time:.3f}s, {signal_length}æ ·æœ¬, {'æˆåŠŸ' if success else 'å¤±è´¥'}\")\n",
    "\n",
    "# ç­‰å¾…ä¸€ä¸‹æ”¶é›†æ›´å¤šç³»ç»ŸæŒ‡æ ‡\n",
    "time.sleep(2)\n",
    "\n",
    "# åœæ­¢ç›‘æ§\n",
    "monitor.stop_monitoring()\n",
    "\n",
    "# è·å–æ€§èƒ½æ‘˜è¦\n",
    "summary = monitor.get_performance_summary()\n",
    "\n",
    "print(f\"\\nğŸ“Š æ€§èƒ½æ‘˜è¦æŠ¥å‘Š:\")\n",
    "print(f\"   å¤„ç†æ€»æ•°: {summary['total_processed']}\")\n",
    "print(f\"   æˆåŠŸç‡: {summary['success_rate']:.1%}\")\n",
    "print(f\"   å¹³å‡å¤„ç†æ—¶é—´: {summary['average_processing_time']:.3f}ç§’\")\n",
    "print(f\"   å¹³å‡ååé‡: {summary['average_throughput']:.0f} æ ·æœ¬/ç§’\")\n",
    "print(f\"   å½“å‰CPUä½¿ç”¨ç‡: {summary['current_cpu_usage']:.1f}%\")\n",
    "print(f\"   å½“å‰å†…å­˜ä½¿ç”¨ç‡: {summary['current_memory_usage']:.1f}%\")\n",
    "print(f\"   å³°å€¼å†…å­˜ä½¿ç”¨ç‡: {summary['peak_memory_usage']:.1f}%\")\n",
    "\n",
    "# æ€§èƒ½è¯„ä¼°\n",
    "print(f\"\\nğŸ“ˆ æ€§èƒ½è¯„ä¼°:\")\n",
    "if summary['average_processing_time'] < 0.5:\n",
    "    print(f\"   âœ… å¤„ç†é€Ÿåº¦: ä¼˜ç§€ (<0.5s)\")\nelif summary['average_processing_time'] < 1.0:\n",
    "    print(f\"   âš ï¸ å¤„ç†é€Ÿåº¦: è‰¯å¥½ (<1.0s)\")\nelse:\n",
    "    print(f\"   âŒ å¤„ç†é€Ÿåº¦: éœ€ä¼˜åŒ– (>1.0s)\")\n\nif summary['success_rate'] > 0.95:\n    print(f\"   âœ… å¯é æ€§: ä¼˜ç§€ (>95%)\")\nelif summary['success_rate'] > 0.90:\n    print(f\"   âš ï¸ å¯é æ€§: è‰¯å¥½ (>90%)\")\nelse:\n    print(f\"   âŒ å¯é æ€§: éœ€æ”¹è¿› (<90%)\")\n\nif summary['peak_memory_usage'] < 80:\n    print(f\"   âœ… å†…å­˜ä½¿ç”¨: æ­£å¸¸ (<80%)\")\nelse:\n    print(f\"   âš ï¸ å†…å­˜ä½¿ç”¨: éœ€å…³æ³¨ (>80%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 é«˜çº§åŠŸèƒ½æ¼”ç¤º\n",
    "\n",
    "å±•ç¤ºPHMç³»ç»Ÿçš„é«˜çº§åŠŸèƒ½ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é«˜çº§åŠŸèƒ½æ¼”ç¤º\n",
    "print(\"ğŸš€ PHMç³»ç»Ÿé«˜çº§åŠŸèƒ½æ¼”ç¤º\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# å¦‚æœæœ‰çœŸå®ç»„ä»¶ï¼Œæ¼”ç¤ºé«˜çº§åŠŸèƒ½\n",
    "if PROJECT_AVAILABLE:\n",
    "    phm_demo.demonstrate_real_components()\nelse:\n    print(\"ğŸ”§ æ¨¡æ‹Ÿé«˜çº§åŠŸèƒ½\")\n    \n    advanced_features = {\n        \"æ‰¹é‡å¤„ç†\": \"åŒæ—¶å¤„ç†å¤šä¸ªè®¾å¤‡çš„ä¿¡å·\",\n        \"å®æ—¶ç›‘æ§\": \"è¿ç»­ç›‘æ§è®¾å¤‡çŠ¶æ€å˜åŒ–\",\n        \"é¢„æµ‹åˆ†æ\": \"åŸºäºå†å²æ•°æ®é¢„æµ‹æ•…éšœ\",\n        \"è‡ªé€‚åº”é˜ˆå€¼\": \"åŠ¨æ€è°ƒæ•´è­¦æŠ¥é˜ˆå€¼\",\n        \"å¤šæ¨¡æ€èåˆ\": \"ç»“åˆæŒ¯åŠ¨ã€æ¸©åº¦ã€å£°éŸ³ç­‰å¤šç§ä¿¡å·\",\n        \"äº‘ç«¯éƒ¨ç½²\": \"æ”¯æŒåˆ†å¸ƒå¼è®¡ç®—å’Œå­˜å‚¨\",\n        \"APIæ¥å£\": \"RESTful APIå’ŒgRPCæ¥å£\",\n        \"å¯è§†åŒ–é¢æ¿\": \"å®æ—¶æ•°æ®å¯è§†åŒ–å’ŒæŠ¥è¡¨ç”Ÿæˆ\"\n    }\n    \n    for feature, description in advanced_features.items():\n        print(f\"   â€¢ {feature}: {description}\")\n\n# æ€»ç»“é¡¹ç›®ç‰¹ç‚¹\nprint(f\"\\nğŸ¯ PHMGAé¡¹ç›®ç‰¹ç‚¹æ€»ç»“:\")\nfeatures = [\n    \"åŒå±‚æ¶æ„è®¾è®¡ (LangGraph + ä¿¡å·å¤„ç†DAG)\",\n    \"å¤šAgentåä½œç³»ç»Ÿ\",\n    \"60+ ä¿¡å·å¤„ç†æ“ä½œç¬¦\",\n    \"è‡ªåŠ¨æ³¨å†Œå’Œå‘ç°æœºåˆ¶\",\n    \"å¤šLLM Provideræ”¯æŒ\",\n    \"ç»“æ„åŒ–çŠ¶æ€ç®¡ç†\",\n    \"æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–\",\n    \"å¯æ‰©å±•çš„æ¨¡å—åŒ–è®¾è®¡\"\n]\n\nfor i, feature in enumerate(features, 1):\n    print(f\"   {i}. {feature}\")\n\nprint(f\"\\nâœ… Part 4 æ¼”ç¤ºå®Œæˆ\")\nprint(f\"æ‚¨ç°åœ¨å·²ç»äº†è§£äº†å¦‚ä½•ä½¿ç”¨PHMGAçš„çœŸå®ç»„ä»¶æ„å»ºå®Œæ•´çš„PHMç³»ç»Ÿï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. å®è·µç»ƒä¹  ğŸ“\n",
    "\n",
    "### ç»ƒä¹ ï¼šæ„å»ºç”Ÿäº§çº§PHMç›‘æ§ç³»ç»Ÿ\n",
    "\n",
    "ç»“åˆçœŸå®ç»„ä»¶ï¼Œè®¾è®¡ä¸€ä¸ªç”Ÿäº§çº§çš„PHMç›‘æ§ç³»ç»Ÿï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹ ï¼šæ„å»ºç”Ÿäº§çº§PHMç³»ç»Ÿ\n",
    "class ProductionPHMSystem:\n",
    "    \"\"\"ç”Ÿäº§çº§PHMç³»ç»Ÿ - è¯·å®Œå–„å®ç°\"\"\"\n",
    "    \n",
    "    def __init__(self, enable_monitoring=True):\n",
    "        # TODO: è®¾è®¡æ‚¨çš„ç”Ÿäº§ç³»ç»Ÿæ¶æ„\n",
    "        self.components = {}\n",
    "        self.monitor = PHMPerformanceMonitor() if enable_monitoring else None\n",
    "        self.equipment_registry = {}\n",
    "        self.alert_thresholds = {}\n",
    "        \n",
    "        # åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶\n",
    "        self._initialize_components()\n",
    "        \n",
    "        if self.monitor:\n",
    "            self.monitor.start_monitoring()\n",
    "    \n",
    "    def _initialize_components(self):\n",
    "        \"\"\"åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶ - è¯·å®ç°\"\"\"\n",
    "        # TODO: åˆå§‹åŒ–çœŸå®æˆ–æ¨¡æ‹Ÿçš„PHMç»„ä»¶\n",
    "        \n",
    "        if PROJECT_AVAILABLE:\n",
    "            try:\n",
    "                # ä½¿ç”¨çœŸå®ç»„ä»¶\n",
    "                self.components[\"data_analyst\"] = DataAnalystAgent({\n",
    "                    \"quick_mode\": False,\n",
    "                    \"use_parallel\": True,\n",
    "                    \"use_cache\": True\n",
    "                })\n",
    "                self.components[\"plan_agent\"] = PlanAgent()\n",
    "                self.components[\"llm\"] = get_llm(temperature=0.3)\n",
    "                print(\"âœ… ä½¿ç”¨çœŸå®PHMç»„ä»¶\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ çœŸå®ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶\")\n",
    "                self._setup_mock_components()\n",
    "        else:\n",
    "            self._setup_mock_components()\n",
    "    \n",
    "    def _setup_mock_components(self):\n",
    "        \"\"\"è®¾ç½®æ¨¡æ‹Ÿç»„ä»¶\"\"\"\n",
    "        # TODO: å®ç°æ¨¡æ‹Ÿç»„ä»¶\n",
    "        class MockAnalyst:\n",
    "            def analyze(self, state):\n",
    "                return {\"status\": \"completed\", \"confidence\": 0.85}\n",
    "        \n",
    "        class MockPlanner:\n",
    "            def plan(self, state, analysis):\n",
    "                return {\"actions\": [\"æ£€æŸ¥è®¾å¤‡\", \"æ›´æ¢éƒ¨ä»¶\"], \"cost\": 1500}\n",
    "        \n",
    "        self.components[\"data_analyst\"] = MockAnalyst()\n",
    "        self.components[\"plan_agent\"] = MockPlanner()\n",
    "        print(\"ğŸ”§ ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶\")\n",
    "    \n",
    "    def register_equipment(self, equipment_id: str, equipment_type: str, thresholds: Dict[str, float]):\n",
    "        \"\"\"æ³¨å†Œè®¾å¤‡ - è¯·å®ç°\"\"\"\n",
    "        # TODO: å®ç°è®¾å¤‡æ³¨å†Œé€»è¾‘\n",
    "        self.equipment_registry[equipment_id] = {\n",
    "            \"type\": equipment_type,\n",
    "            \"registration_time\": time.time(),\n",
    "            \"status\": \"active\"\n",
    "        }\n",
    "        self.alert_thresholds[equipment_id] = thresholds\n",
    "        print(f\"ğŸ“‹ è®¾å¤‡å·²æ³¨å†Œ: {equipment_id} ({equipment_type})\")\n",
    "    \n",
    "    def process_realtime_data(self, equipment_id: str, sensor_data: Dict[str, float]) -> Dict[str, Any]:\n",
    "        \"\"\"å¤„ç†å®æ—¶æ•°æ® - è¯·å®Œå–„\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # TODO: å®ç°å®Œæ•´çš„å®æ—¶å¤„ç†æµç¨‹\n",
    "            \n",
    "            # 1. æ•°æ®éªŒè¯\n",
    "            if not self._validate_sensor_data(sensor_data):\n",
    "                raise ValueError(\"ä¼ æ„Ÿå™¨æ•°æ®æ— æ•ˆ\")\n",
    "            \n",
    "            # 2. å¼‚å¸¸æ£€æµ‹\n",
    "            alerts = self._detect_anomalies(equipment_id, sensor_data)\n",
    "            \n",
    "            # 3. æ•°æ®åˆ†æ\n",
    "            analysis_result = self.components[\"data_analyst\"].analyze({\n",
    "                \"equipment_id\": equipment_id,\n",
    "                \"sensor_data\": sensor_data\n",
    "            })\n",
    "            \n",
    "            # 4. ç”Ÿæˆå»ºè®®ï¼ˆå¦‚æœæœ‰å¼‚å¸¸ï¼‰\n",
    "            recommendations = []\n",
    "            if alerts:\n",
    "                plan = self.components[\"plan_agent\"].plan(\n",
    "                    {\"equipment_id\": equipment_id}, \n",
    "                    analysis_result\n",
    "                )\n",
    "                recommendations = plan.get(\"actions\", [])\n",
    "            \n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            # è®°å½•æ€§èƒ½\n",
    "            if self.monitor:\n",
    "                signal_length = sum(1 for v in sensor_data.values() if isinstance(v, (int, float)))\n",
    "                self.monitor.record_processing(processing_time, signal_length, True)\n",
    "            \n",
    "            return {\n",
    "                \"equipment_id\": equipment_id,\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"processing_time\": processing_time,\n",
    "                \"alerts\": alerts,\n",
    "                \"analysis\": analysis_result,\n",
    "                \"recommendations\": recommendations,\n",
    "                \"status\": \"success\"\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            if self.monitor:\n",
    "                self.monitor.record_processing(end_time - start_time, 0, False)\n",
    "            \n",
    "            return {\n",
    "                \"equipment_id\": equipment_id,\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "    \n",
    "    def _validate_sensor_data(self, sensor_data: Dict[str, float]) -> bool:\n",
    "        \"\"\"éªŒè¯ä¼ æ„Ÿå™¨æ•°æ®\"\"\"\n",
    "        required_sensors = ['temperature', 'vibration']\n",
    "        return all(sensor in sensor_data for sensor in required_sensors)\n",
    "    \n",
    "    def _detect_anomalies(self, equipment_id: str, sensor_data: Dict[str, float]) -> List[str]:\n",
    "        \"\"\"æ£€æµ‹å¼‚å¸¸\"\"\"\n",
    "        alerts = []\n",
    "        thresholds = self.alert_thresholds.get(equipment_id, {})\n",
    "        \n",
    "        for sensor, value in sensor_data.items():\n",
    "            if sensor in thresholds:\n",
    "                threshold = thresholds[sensor]\n",
    "                if (sensor == 'pressure' and value < threshold) or \\\n",
    "                   (sensor != 'pressure' and value > threshold):\n",
    "                    alerts.append(f\"{sensor}å¼‚å¸¸: {value}\")\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def get_system_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–ç³»ç»ŸçŠ¶æ€ - è¯·å®ç°\"\"\"\n",
    "        # TODO: å®ç°ç³»ç»ŸçŠ¶æ€æ±‡æ€»\n",
    "        status = {\n",
    "            \"registered_equipment\": len(self.equipment_registry),\n",
    "            \"active_components\": len(self.components),\n",
    "            \"system_health\": \"healthy\"\n",
    "        }\n",
    "        \n",
    "        if self.monitor:\n",
    "            performance = self.monitor.get_performance_summary()\n",
    "            status[\"performance\"] = performance\n",
    "        \n",
    "        return status\n",
    "    \n",
    "    def shutdown(self):\n",
    "        \"\"\"å…³é—­ç³»ç»Ÿ\"\"\"\n",
    "        if self.monitor:\n",
    "            self.monitor.stop_monitoring()\n",
    "        print(\"ğŸ”Œ ç³»ç»Ÿå·²å…³é—­\")\n",
    "\n",
    "# æµ‹è¯•ç”Ÿäº§çº§ç³»ç»Ÿ\n",
    "print(\"ğŸ­ æµ‹è¯•ç”Ÿäº§çº§PHMç³»ç»Ÿ\")\n",
    "production_system = ProductionPHMSystem(enable_monitoring=True)\n",
    "\n",
    "# æ³¨å†Œè®¾å¤‡\n",
    "equipment_configs = [\n",
    "    (\"PUMP-A001\", \"ç¦»å¿ƒæ³µ\", {\"temperature\": 85, \"vibration\": 6.0, \"pressure\": 1.5}),\n",
    "    (\"MOTOR-B002\", \"ç”µæœº\", {\"temperature\": 80, \"vibration\": 5.5, \"current\": 15.0}),\n",
    "    (\"BEARING-C003\", \"è½´æ‰¿\", {\"temperature\": 75, \"vibration\": 5.0})\n",
    "]\n",
    "\n",
    "for eq_id, eq_type, thresholds in equipment_configs:\n",
    "    production_system.register_equipment(eq_id, eq_type, thresholds)\n",
    "\n",
    "# æ¨¡æ‹Ÿå®æ—¶æ•°æ®å¤„ç†\n",
    "print(f\"\\nğŸ”„ æ¨¡æ‹Ÿå®æ—¶æ•°æ®å¤„ç†:\")\n",
    "test_scenarios = [\n",
    "    (\"PUMP-A001\", {\"temperature\": 70, \"vibration\": 4.2, \"pressure\": 2.0}),  # æ­£å¸¸\n",
    "    (\"MOTOR-B002\", {\"temperature\": 88, \"vibration\": 7.1, \"current\": 12.5}),  # å¼‚å¸¸\n",
    "    (\"BEARING-C003\", {\"temperature\": 77, \"vibration\": 5.8}),  # è½»å¾®å¼‚å¸¸\n",
    "]\n",
    "\n",
    "for equipment_id, sensor_data in test_scenarios:\n",
    "    print(f\"\\nğŸ“Š å¤„ç† {equipment_id}: {sensor_data}\")\n",
    "    result = production_system.process_realtime_data(equipment_id, sensor_data)\n",
    "    \n",
    "    if result[\"status\"] == \"success\":\n",
    "        print(f\"   âœ… å¤„ç†æˆåŠŸ ({result['processing_time']:.3f}s)\")\n",
    "        if result[\"alerts\"]:\n",
    "            print(f\"   ğŸš¨ è­¦æŠ¥: {result['alerts']}\")\n",
    "        if result[\"recommendations\"]:\n",
    "            print(f\"   ğŸ’¡ å»ºè®®: {result['recommendations']}\")\n",
    "    else:\n",
    "        print(f\"   âŒ å¤„ç†å¤±è´¥: {result['error']}\")\n",
    "\n",
    "# ç³»ç»ŸçŠ¶æ€æ£€æŸ¥\n",
    "time.sleep(1)  # ç­‰å¾…æ”¶é›†æ€§èƒ½æ•°æ®\n",
    "system_status = production_system.get_system_status()\n",
    "print(f\"\\nğŸ“Š ç³»ç»ŸçŠ¶æ€:\")\n",
    "print(f\"   æ³¨å†Œè®¾å¤‡: {system_status['registered_equipment']}å°\")\n",
    "print(f\"   æ´»åŠ¨ç»„ä»¶: {system_status['active_components']}ä¸ª\")\n",
    "print(f\"   ç³»ç»Ÿå¥åº·: {system_status['system_health']}\")\n",
    "\n",
    "if \"performance\" in system_status:\n",
    "    perf = system_status[\"performance\"]\n",
    "    print(f\"   å¤„ç†æˆåŠŸç‡: {perf.get('success_rate', 0):.1%}\")\n",
    "    print(f\"   å¹³å‡å¤„ç†æ—¶é—´: {perf.get('average_processing_time', 0):.3f}s\")\n",
    "\n",
    "# å…³é—­ç³»ç»Ÿ\n",
    "production_system.shutdown()\n",
    "\n",
    "print(\"\\nğŸ’¡ æŒ‘æˆ˜: å°è¯•æ·»åŠ æ•°æ®åº“å­˜å‚¨ã€Web APIæ¥å£ã€å®æ—¶å¯è§†åŒ–ç­‰åŠŸèƒ½ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. æœ¬ç« æ€»ç»“ ğŸ¯\n",
    "\n",
    "### æ‚¨å·²ç»å­¦ä¼šäº†ï¼š\n",
    "\n",
    "âœ… **çœŸå®PHMç»„ä»¶ä½¿ç”¨** - DataAnalystAgentã€PlanAgentç­‰çš„å®é™…åº”ç”¨  \n",
    "âœ… **ä¿¡å·å¤„ç†é›†æˆ** - 60+æ“ä½œç¬¦çš„åŠ¨æ€ç»„åˆå’ŒDAGæ„å»º  \n",
    "âœ… **å®Œæ•´å·¥ä½œæµå®ç°** - ä»ä¿¡å·è¾“å…¥åˆ°è¯Šæ–­æŠ¥å‘Šçš„ç«¯åˆ°ç«¯æµç¨‹  \n",
    "âœ… **æ€§èƒ½ç›‘æ§ç³»ç»Ÿ** - ç”Ÿäº§ç¯å¢ƒçš„æ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§  \n",
    "\n",
    "### å…³é”®æŠ€æœ¯ç‚¹ï¼š\n",
    "\n",
    "- **åŒå±‚æ¶æ„** - LangGraphå·¥ä½œæµ + ä¿¡å·å¤„ç†DAG\n",
    "- **ç»„ä»¶é›†æˆ** - çœŸå®Agentä¸æ¨¡æ‹Ÿç»„ä»¶çš„æ— ç¼åˆ‡æ¢\n",
    "- **åŠ¨æ€è®¡ç®—å›¾** - åŸºäºéœ€æ±‚çš„è‡ªåŠ¨DAGæ„å»º\n",
    "- **æ€§èƒ½ä¼˜åŒ–** - å®æ—¶ç›‘æ§å’Œèµ„æºç®¡ç†\n",
    "\n",
    "### ç”Ÿäº§çº§ç‰¹æ€§ï¼š\n",
    "\n",
    "- **å®¹é”™è®¾è®¡** - ç»„ä»¶å¤±è´¥æ—¶çš„ä¼˜é›…é™çº§\n",
    "- **æ€§èƒ½ç›‘æ§** - CPUã€å†…å­˜ã€ååé‡çš„å®æ—¶ç›‘æ§\n",
    "- **å¯æ‰©å±•æ€§** - æ”¯æŒå¤šè®¾å¤‡ã€å¤šç±»å‹çš„ç›‘æ§\n",
    "- **æ¨¡å—åŒ–è®¾è®¡** - ç»„ä»¶å¯æ’æ‹”å’Œæ›¿æ¢\n",
    "\n",
    "### ä¸‹ä¸€æ­¥ï¼š\n",
    "\n",
    "åœ¨ **Part 5** ä¸­ï¼Œæ‚¨å°†å­¦ä¹ ï¼š\n",
    "- ğŸš€ **å®Œæ•´PHMGAç³»ç»Ÿ** - é›†æˆæ‰€æœ‰å­¦åˆ°çš„æ¦‚å¿µ\n",
    "- ğŸ“ˆ **é«˜çº§ç”¨ä¾‹** - å¤æ‚çš„å·¥ä¸šåº”ç”¨åœºæ™¯\n",
    "- ğŸ”§ **éƒ¨ç½²å’Œç»´æŠ¤** - ç”Ÿäº§ç¯å¢ƒçš„æœ€ä½³å®è·µ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ å‡†å¤‡ç»§ç»­ï¼Ÿ\n",
    "\n",
    "<div style=\"text-align: center; margin: 20px;\">\n",
    "    <a href=\"../Part5_PHMGA_Complete/05_Complete_Tutorial.ipynb\" \n",
    "       style=\"background: #4CAF50; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px;\">\n",
    "       ğŸš€ ç»§ç»­ Part 5: PHMGA Complete System\n",
    "    </a>\n",
    "</div>"
   ]
  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.5\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}