{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae939a9",
   "metadata": {},
   "source": [
    "# case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59655a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/lq/LQcode/2_project/PHMBench/PHMGA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lq/.conda/envs/PA/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "os.chdir('/home/lq/LQcode/2_project/PHMBench/PHMGA/')\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "\n",
    "from src.agents.dataset_preparer_agent import dataset_preparer_agent\n",
    "from src.agents.execute_agent import execute_agent\n",
    "from src.agents.inquirer_agent import inquirer_agent\n",
    "from src.agents.plan_agent import plan_agent\n",
    "from src.agents.reflect_agent import reflect_agent_node\n",
    "from src.agents.report_agent import report_agent_node\n",
    "from src.agents.shallow_ml_agent import shallow_ml_agent\n",
    "from src.states.phm_states import PHMState\n",
    "import yaml\n",
    "import os\n",
    "from src.utils import load_state, save_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2f6d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading configuration from config/case1.yaml ---\n",
      "\n",
      "--- Found existing state file at /home/lq/LQcode/2_project/PHMBench/PHMGA/save/case1/case1_built_state.pkl. Skipping builder workflow. ---\n",
      "\n",
      "--- Loading state from /home/lq/LQcode/2_project/PHMBench/PHMGA/save/case1/case1_built_state.pkl ---\n",
      "...done.\n",
      "Successfully loaded state with 4 nodes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "config_path = \"config/case1.yaml\"\n",
    "print(f\"--- Loading configuration from {config_path} ---\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "state_save_path = config['state_save_path']\n",
    "builder_cfg = config.get('builder', {})\n",
    "min_depth = builder_cfg.get('min_depth', 0)\n",
    "max_depth = builder_cfg.get('max_depth', float('inf'))\n",
    "\n",
    "# --- Check for existing state ---\n",
    "if os.path.exists(state_save_path):\n",
    "    print(f\"\\n--- Found existing state file at {state_save_path}. Skipping builder workflow. ---\")\n",
    "    state = load_state(state_save_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b52e4",
   "metadata": {},
   "source": [
    "## 1 inquiring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b02f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Inquiring - Performing similarity analysis...\n",
      "Output: Updated state with similarity_results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5013/2378391913.py:3: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  state = state.copy(update=inquirer_updates)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 1: Inquiring - Performing similarity analysis...\")\n",
    "inquirer_updates = inquirer_agent(state, metrics=[\"cosine\", \"euclidean\"])\n",
    "state = state.copy(update=inquirer_updates)\n",
    "print(f\"Output: Updated state with similarity_results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a5e70c",
   "metadata": {},
   "source": [
    "## 2 data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1e805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for IDs: [47050, 47044, 47047, 47053, 47056]\n",
      "Loading data for IDs: [47051, 47045, 47048, 47054, 47057]\n"
     ]
    }
   ],
   "source": [
    "from src.utils import load_signal_data\n",
    "metadata_path, h5_path, ref_ids,test_ids = config['metadata_path'], config['h5_path'], config['ref_ids'], config['test_ids']\n",
    "ref_signals, ref_labels = load_signal_data(metadata_path, h5_path, ref_ids)\n",
    "test_signals, test_labels = load_signal_data(metadata_path, h5_path, test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3fcb579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'47051': array([[[  -2.6200001 , -102.4000015 ],\n",
       "         [  -2.6200001 , -102.4000015 ],\n",
       "         [  -2.6200001 , -102.4000015 ],\n",
       "         ...,\n",
       "         [  -0.44000003,  -19.2000008 ],\n",
       "         [  -0.54000002,  -24.        ],\n",
       "         [  -0.48000002,  -28.80000114]]], shape=(1, 1249999, 2)),\n",
       " '47045': array([[[  -2.6200001 , -102.4000015 ],\n",
       "         [  -2.6200001 , -102.4000015 ],\n",
       "         [  -2.6200001 , -102.4000015 ],\n",
       "         ...,\n",
       "         [  -0.46000004,    9.60000038],\n",
       "         [  -0.56000006,    2.4000001 ],\n",
       "         [  -0.50000006,   -4.80000019]]], shape=(1, 1249999, 2)),\n",
       " '47048': array([[[  -2.6200001 , -102.4000015 ],\n",
       "         [  -2.6200001 , -102.4000015 ],\n",
       "         [  -2.6200001 , -102.4000015 ],\n",
       "         ...,\n",
       "         [  -0.40000004,  -11.1999998 ],\n",
       "         [  -0.42000002,  -17.6000004 ],\n",
       "         [  -0.48000002,  -23.20000076]]], shape=(1, 1249999, 2)),\n",
       " '47054': array([[[  -2.6200001 , -102.4000015 ],\n",
       "         [  -2.6200001 , -102.4000015 ],\n",
       "         [  -2.6200001 , -102.4000015 ],\n",
       "         ...,\n",
       "         [   0.64000005,   35.20000076],\n",
       "         [   0.56000006,   29.60000038],\n",
       "         [   0.56000006,   23.20000076]]], shape=(1, 1249999, 2)),\n",
       " '47057': array([[[  -2.4000001 , -102.4000015 ],\n",
       "         [  -2.4000001 , -102.4000015 ],\n",
       "         [  -2.4000001 , -102.4000015 ],\n",
       "         ...,\n",
       "         [   1.1400001 ,   -4.80000019],\n",
       "         [   1.5200001 ,  -12.        ],\n",
       "         [   1.3600001 ,  -19.2000008 ]]], shape=(1, 1249999, 2))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a048dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Preparing - Creating datasets for ML model...\n",
      "Output: Updated state with datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5013/1584315041.py:4: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  state = state.copy(update=preparer_updates)\n"
     ]
    }
   ],
   "source": [
    "# 2. Dataset Preparer Agent: Prepare datasets for ML\n",
    "print(\"\\nStep 2: Preparing - Creating datasets for ML model...\")\n",
    "preparer_updates = dataset_preparer_agent(state)\n",
    "state = state.copy(update=preparer_updates)\n",
    "print(f\"Output: Updated state with datasets.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7be7d076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 625000), (5,), (5, 625000), (5,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.datasets['fft_01_ch1']['X_train'].shape, state.datasets['fft_01_ch1']['y_train'].shape, state.datasets['fft_01_ch1']['X_test'].shape, state.datasets['fft_01_ch1']['y_test'].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bd3f6",
   "metadata": {},
   "source": [
    "## 3  train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f07cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Training - Running shallow ML model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lq/.conda/envs/PA/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Updated state with ml_results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lq/.conda/envs/PA/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/tmp/ipykernel_5013/3994341950.py:5: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  state = state.copy(update=ml_updates)\n"
     ]
    }
   ],
   "source": [
    "# 3. Shallow ML Agent: Train and evaluate a simple ML model\n",
    "print(\"\\nStep 3: Training - Running shallow ML model...\")\n",
    "# Note: shallow_ml_agent directly takes the datasets, not the full state\n",
    "ml_updates = {\"ml_results\": shallow_ml_agent(datasets=state.datasets)}\n",
    "state = state.copy(update=ml_updates)\n",
    "print(f\"Output: Updated state with ml_results.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc6d9e",
   "metadata": {},
   "source": [
    "## 4 reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e42b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Reporting - Generating final analysis report...\n",
      "\n",
      "--- Report Agent LLM Response ---\n",
      "```markdown\n",
      "# Bearing Fault Diagnosis Report\n",
      "\n",
      "## 流程概览\n",
      "\n",
      "The diagnostic process, as illustrated by the DAG (`/home/lq/LQcode/2_project/PHMBench/PHMGA/save/case1/graphs/dag_20250804_161125.png`), consists of 6 nodes. The process begins with signal acquisition and preprocessing. This is followed by feature extraction using FFT on two channels: `ds_fft_01_ch1` and `ds_fft_02_ch2`. The extracted features are then fed into machine learning models for classification, ultimately aiming to identify potential bearing faults.\n",
      "\n",
      "## 特征/相似度洞察\n",
      "\n",
      "Similarity statistics are currently unavailable. A detailed analysis of channel similarities and reasons behind high/low scores is not possible without this data.\n",
      "\n",
      "## 模型评估\n",
      "\n",
      "The following table summarizes the performance metrics of the individual models and the ensemble model:\n",
      "\n",
      "| model      |   accuracy |   f1 |   cv_accuracy |   cv_f1 |\n",
      "|:-----------|-----------:|-----:|--------------:|--------:|\n",
      "| fft_01_ch1 |          1 |    0 |             0 |       0 |\n",
      "| fft_02_ch2 |          0 |    0 |             0 |       0 |\n",
      "| ensemble   |          1 |    0 |           nan |     nan |\n",
      "\n",
      "The ensemble model achieves an accuracy of 1.0 and an F1-score of 0.0. The `fft_01_ch1` model also achieved perfect accuracy on the training dataset. However, given that the F1 score is 0 and cross validation metrics are not available, there is a high likelihood of overfitting.  The `fft_02_ch2` model had a 0.0 accuracy, suggesting significant issues either with the data or the model training itself.\n",
      "\n",
      "## 结论与建议\n",
      "\n",
      "Based on the analysis, the bearing signals exhibit characteristics indicative of potential faults. Although the ensemble model achieved 100% accuracy on the training dataset, the f1-score, together with lack of cross validation data, suggests potential overfitting and makes it difficult to provide definitive conclusions. It is recommended that the following actions be taken:\n",
      "\n",
      "1. **Investigate FFT_02_CH2**: Determine the root cause for the zero accuracy. Data preprocessing errors or training issues could be the cause.\n",
      "2. **Gather More Training Data**: Insufficient data can lead to overfitting.\n",
      "3. **Tune Model Hyperparameters**: Optimize the model's configuration to improve generalization.\n",
      "4. **Evaluate on a separate test dataset**: It will provide the true performance for deployment.\n",
      "\n",
      "## Code\n",
      "\n",
      "This code snippet demonstrates how to potentially improve the DAG by including an anomaly detection step to highlight potential issues during the signal acquisition phase.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from sklearn.ensemble import IsolationForest\n",
      "\n",
      "def detect_anomalies(signal, contamination=0.05):\n",
      "    \"\"\"\n",
      "    Detects anomalies in a signal using Isolation Forest.\n",
      "\n",
      "    Args:\n",
      "        signal (np.ndarray): The input signal.\n",
      "        contamination (float): The expected proportion of outliers in the signal.\n",
      "\n",
      "    Returns:\n",
      "        np.ndarray: An array of booleans indicating whether each point is an anomaly.\n",
      "    \"\"\"\n",
      "    model = IsolationForest(contamination=contamination, random_state=42)\n",
      "    model.fit(signal.reshape(-1, 1))\n",
      "    predictions = model.predict(signal.reshape(-1, 1))\n",
      "    return predictions == -1  # Anomalies are labeled as -1\n",
      "\n",
      "# Example usage (assuming 'bearing_signal' is your bearing signal data):\n",
      "# anomalies = detect_anomalies(bearing_signal)\n",
      "# print(f\"Number of anomalies detected: {np.sum(anomalies)}\")\n",
      "```\n",
      "This code adds an anomaly detection step before the FFT calculation. The anomaly detection step can detect obvious errors during signal capturing. If the anomaly detection returns too many anomalies, it should be determined if re-capturing signal data is necessary.\n",
      "--------------------------------\n",
      "\n",
      "Output: Updated state with the final report.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5013/1608283778.py:4: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  state = state.copy(update=report_updates)\n"
     ]
    }
   ],
   "source": [
    "# 4. Report Agent: Generate the final report\n",
    "print(\"\\nStep 4: Reporting - Generating final analysis report...\")\n",
    "report_updates = report_agent_node(state)\n",
    "state = state.copy(update=report_updates)\n",
    "print(\"Output: Updated state with the final report.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
