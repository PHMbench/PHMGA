from __future__ import annotations

from langchain_core.prompts import ChatPromptTemplate
from ..model import get_llm

from ..states.phm_states import PHMState
from pydantic import BaseModel, Field


class Reflection(BaseModel):
    """Structured decision from the reflector agent."""

    is_sufficient: bool = Field(
        ..., description="Are the provided insights sufficient to conclude the analysis?"
    )
    reason: str


def reflect_agent(state: PHMState) -> dict:
    """Evaluate generated insights to decide if further planning is required."""
    if not state.insights:
        return {"needs_revision": True, "reflection_history": ["No insights were generated. Returning to planner."]}

    llm = get_llm()
    try:
        structured_llm = llm.with_structured_output(Reflection)
    except NotImplementedError:
        structured_llm = None

    insights_summary = "\n".join([f"- {i.content}" for i in state.insights])

    prompt = f"""
    You are a project manager reviewing an analysis.
    The goal is: "{state.user_instruction}"
    The following insights have been generated by your analyst team:
    {insights_summary}

    Based *only* on these insights, is the analysis sufficient to answer the user's goal?
    Provide a boolean decision and your reasoning.
    """

    if structured_llm:
        reflection = structured_llm.invoke(prompt)
    else:
        # Simple fallback: parse yes/no from raw text
        resp = (llm.invoke(prompt)).content.lower()
        sufficient = "yes" in resp or "sufficient" in resp
        reflection = Reflection(is_sufficient=sufficient, reason=resp)

    return {
        "needs_revision": not reflection.is_sufficient,
        "reflection_history": state.reflection_history + [reflection.reason],
    }

